# autogenerated from AMD ISA PDF - do not edit
# ruff: noqa: E501
from tinygrad.runtime.autogen.amd.rdna2.enum import DSOp, FLATOp, GLOBALOp, MIMGOp, MUBUFOp, SCRATCHOp, SOP1Op, SOP2Op, SOPCOp, SOPKOp, SOPPOp, VINTRPOp, VOP1Op, VOP2Op, VOP3Op, VOP3POp, VOP3SDOp, VOPCOp

PCODE = {
  DSOp.DS_ADD_U32: 'tmp = MEM[ADDR];\nMEM[ADDR] += DATA;\nRETURN_DATA = tmp.\n// 32bit',
  DSOp.DS_SUB_U32: 'tmp = MEM[ADDR];\nMEM[ADDR] -= DATA;\nRETURN_DATA = tmp.',
  DSOp.DS_RSUB_U32: '// 32bit\naddr = VGPR[ADDR]+{INST1,INST0};\ntmp = DS[addr].u32;\nDS[addr].u32 = VGPR[DATA0].u32-DS[addr].u32;\nVGPR[VDST].u32 = tmp.\n// 32bit',
  DSOp.DS_INC_U32: 'tmp = MEM[ADDR];\nMEM[ADDR] = (tmp >= DATA) ? 0 : tmp + 1; // unsigned compare\nRETURN_DATA = tmp.\n// 32bit',
  DSOp.DS_DEC_U32: 'tmp = MEM[ADDR];\nMEM[ADDR] = (tmp == 0 || tmp > DATA) ? DATA : tmp - 1; //\nRETURN_DATA = tmp.\n// 32bit',
  DSOp.DS_MIN_I32: 'tmp = MEM[ADDR];\nMEM[ADDR] = (DATA < tmp) ? DATA : tmp; // signed compare\nRETURN_DATA = tmp.\n// 32bit',
  DSOp.DS_MAX_I32: 'tmp = MEM[ADDR];\nMEM[ADDR] = (DATA > tmp) ? DATA : tmp; // signed compare\nRETURN_DATA = tmp.',
  DSOp.DS_MIN_U32: '// 32bit\ntmp = MEM[ADDR];\nMEM[ADDR] = (DATA < tmp) ? DATA : tmp; // unsigned compare\nRETURN_DATA = tmp.\n// 32bit',
  DSOp.DS_MAX_U32: 'tmp = MEM[ADDR];\nMEM[ADDR] = (DATA > tmp) ? DATA : tmp; // unsigned compare\nRETURN_DATA = tmp.\n// 32bit',
  DSOp.DS_AND_B32: 'tmp = MEM[ADDR];\nMEM[ADDR] &= DATA;\nRETURN_DATA = tmp.\n// 32bit',
  DSOp.DS_OR_B32: 'tmp = MEM[ADDR];\nMEM[ADDR] |= DATA;\nRETURN_DATA = tmp.',
  DSOp.DS_XOR_B32: '// 32bit\ntmp = MEM[ADDR];\nMEM[ADDR] ^= DATA;\nRETURN_DATA = tmp.',
  DSOp.DS_MSKOR_B32: '// 32bit\ntmp = MEM[ADDR];\nMEM[ADDR] = (MEM[ADDR] & ~DATA) | DATA2;\nRETURN_DATA = tmp.',
  DSOp.DS_WRITE_B32: '// 32bit\nMEM[ADDR] = DATA.',
  DSOp.DS_WRITE2_B32: '// 32bit\nMEM[ADDR + OFFSET0 * 4] = DATA;\nMEM[ADDR + OFFSET1 * 4] = DATA2.',
  DSOp.DS_WRITE2ST64_B32: '// 32bit\nMEM[ADDR + OFFSET0 * 4 * 64] = DATA;\nMEM[ADDR + OFFSET1 * 4 * 64] = DATA2.',
  DSOp.DS_CMPST_B32: '// 32bit\ntmp = MEM[ADDR];\nsrc = DATA2;\ncmp = DATA;\nMEM[ADDR] = (tmp == cmp) ? src : tmp;\nRETURN_DATA[0] = tmp.',
  DSOp.DS_CMPST_F32: '// 32bit\ntmp = MEM[ADDR];\nsrc = DATA2;\ncmp = DATA;\nMEM[ADDR] = (tmp == cmp) ? src : tmp;\nRETURN_DATA[0] = tmp.',
  DSOp.DS_MIN_F32: '// 32bit\ntmp = MEM[ADDR];\nsrc = DATA;\ncmp = DATA2;\nMEM[ADDR] = (cmp < tmp) ? src : tmp.',
  DSOp.DS_MAX_F32: '// 32bit\ntmp = MEM[ADDR];\nsrc = DATA;\ncmp = DATA2;\nMEM[ADDR] = (tmp > cmp) ? src : tmp.',
  DSOp.DS_ADD_F32: 'float tmp = MEM[ADDR].f32;\nMEM[ADDR].f32 += DATA0.f32;\nVDST.f32 = tmp;',
  DSOp.DS_GWS_SEMA_RELEASE_ALL: '// Determine the GWS resource to work on\nrid[5:0] = gds_base[5:0] + offset0[5:0];\n// Incr the state counter of the resource\nstate.counter[rid] = state.wave_in_queue;\nstate.type = SEMAPHORE;\nreturn rd_done; //release calling wave',
  DSOp.DS_GWS_INIT: '// Determine the GWS resource to work on\nrid[5:0] = gds_base[5:0] + offset0[5:0];\n// Get the value to use in init\nindex = find_first_valid(vector mask)\nvalue = DATA[thread: index]\n// Set the state of the resource\nstate.counter[rid] = lsb(value); //limit #waves\nstate.flag[rid] = 0;\nreturn rd_done; //release calling wave',
  DSOp.DS_GWS_SEMA_V: '//Determine the GWS resource to work on\nrid[5:0] = gds_base[5:0] + offset0[5:0];\n//Incr the state counter of the resource\nstate.counter[rid] += 1;\nstate.type = SEMAPHORE;\nreturn rd_done; //release calling wave',
  DSOp.DS_GWS_SEMA_BR: '//Determine the GWS resource to work on\nrid[5:0] = gds_base[5:0] + offset0[5:0];\nindex =  find first valid (vector mask)\ncount = DATA[thread: index];\n//Add count to the resource state counter\nstate.counter[rid] += count;\nstate.type = SEMAPHORE;\nreturn rd_done; //release calling wave',
  DSOp.DS_GWS_SEMA_P: '//Determine the GWS resource to work on\nrid[5:0] = gds_base[5:0] + offset0[5:0];\nstate.type = SEMAPHORE;\nENQUEUE until(state[rid].counter > 0)\nstate[rid].counter -= 1;\nreturn rd_done;',
  DSOp.DS_GWS_BARRIER: '//Determine the GWS resource to work on\nrid[5:0] = gds_base[5:0] + OFFSET0[5:0];\nindex =  find first valid (vector mask);\nvalue = DATA[thread: index];\n// Input Decision Machine\nstate.type[rid] = BARRIER;\nif(state[rid].counter <= 0) then\nthread[rid].flag = state[rid].flag;\nENQUEUE;\nstate[rid].flag = !state.flag;\nstate[rid].counter = value;\nreturn rd_done;\nelse\nstate[rid].counter -= 1;\nthread.flag = state[rid].flag;\nENQUEUE;\nendif.\n// Release Machine\nif(state.type == BARRIER) then\nif(state.flag != thread.flag) then\nreturn rd_done;\nendif;\nendif.',
  DSOp.DS_WRITE_B8: 'MEM[ADDR] = DATA[7:0].',
  DSOp.DS_WRITE_B16: 'MEM[ADDR] = DATA[15:0].\n// 32bit',
  DSOp.DS_ADD_RTN_U32: 'tmp = MEM[ADDR];\nMEM[ADDR] += DATA;\nRETURN_DATA = tmp.\n// 32bit',
  DSOp.DS_SUB_RTN_U32: 'tmp = MEM[ADDR];\nMEM[ADDR] -= DATA;\nRETURN_DATA = tmp.',
  DSOp.DS_RSUB_RTN_U32: '// 32bit\naddr = VGPR[ADDR]+{INST1,INST0};\ntmp = DS[addr].u32;\nDS[addr].u32 = VGPR[DATA0].u32-DS[addr].u32;\nVGPR[VDST].u32 = tmp.\n// 32bit',
  DSOp.DS_INC_RTN_U32: 'tmp = MEM[ADDR];\nMEM[ADDR] = (tmp >= DATA) ? 0 : tmp + 1; // unsigned compare\nRETURN_DATA = tmp.\n// 32bit',
  DSOp.DS_DEC_RTN_U32: 'tmp = MEM[ADDR];\nMEM[ADDR] = (tmp == 0 || tmp > DATA) ? DATA : tmp - 1; //\nRETURN_DATA = tmp.',
  DSOp.DS_MIN_RTN_I32: '// 32bit\ntmp = MEM[ADDR];\nMEM[ADDR] = (DATA < tmp) ? DATA : tmp; // signed compare\nRETURN_DATA = tmp.\n// 32bit',
  DSOp.DS_MAX_RTN_I32: 'tmp = MEM[ADDR];\nMEM[ADDR] = (DATA > tmp) ? DATA : tmp; // signed compare\nRETURN_DATA = tmp.\n// 32bit',
  DSOp.DS_MIN_RTN_U32: 'tmp = MEM[ADDR];\nMEM[ADDR] = (DATA < tmp) ? DATA : tmp; // unsigned compare\nRETURN_DATA = tmp.',
  DSOp.DS_MAX_RTN_U32: '// 32bit\ntmp = MEM[ADDR];\nMEM[ADDR] = (DATA > tmp) ? DATA : tmp; // unsigned compare\nRETURN_DATA = tmp.\n// 32bit',
  DSOp.DS_AND_RTN_B32: 'tmp = MEM[ADDR];\nMEM[ADDR] &= DATA;\nRETURN_DATA = tmp.\n// 32bit',
  DSOp.DS_OR_RTN_B32: 'tmp = MEM[ADDR];\nMEM[ADDR] |= DATA;\nRETURN_DATA = tmp.\n// 32bit',
  DSOp.DS_XOR_RTN_B32: 'tmp = MEM[ADDR];\nMEM[ADDR] ^= DATA;\nRETURN_DATA = tmp.',
  DSOp.DS_MSKOR_RTN_B32: '// 32bit\ntmp = MEM[ADDR];\nMEM[ADDR] = (MEM[ADDR] & ~DATA) | DATA2;\nRETURN_DATA = tmp.',
  DSOp.DS_WRXCHG_RTN_B32: 'tmp = MEM[ADDR];\nMEM[ADDR] = DATA;\nRETURN_DATA = tmp.',
  DSOp.DS_CMPST_RTN_B32: '// 32bit\ntmp = MEM[ADDR];\nsrc = DATA2;\ncmp = DATA;\nMEM[ADDR] = (tmp == cmp) ? src : tmp;\nRETURN_DATA[0] = tmp.',
  DSOp.DS_CMPST_RTN_F32: '// 32bit\ntmp = MEM[ADDR];\nsrc = DATA2;\ncmp = DATA;\nMEM[ADDR] = (tmp == cmp) ? src : tmp;\nRETURN_DATA[0] = tmp.',
  DSOp.DS_MIN_RTN_F32: '// 32bit\ntmp = MEM[ADDR];\nsrc = DATA;\ncmp = DATA2;\nMEM[ADDR] = (cmp < tmp) ? src : tmp.',
  DSOp.DS_MAX_RTN_F32: '// 32bit\ntmp = MEM[ADDR];\nsrc = DATA;\ncmp = DATA2;\nMEM[ADDR] = (tmp > cmp) ? src : tmp.\ntmp = MEM[ADDR];',
  DSOp.DS_WRAP_RTN_B32: 'MEM[ADDR] = (tmp >= DATA) ? tmp - DATA : tmp + DATA2;\nRETURN_DATA = tmp.',
  DSOp.DS_READ_B32: 'RETURN_DATA = MEM[ADDR].',
  DSOp.DS_READ2_B32: 'RETURN_DATA[0] = MEM[ADDR + OFFSET0 * 4];\nRETURN_DATA[1] = MEM[ADDR + OFFSET1 * 4].',
  DSOp.DS_READ2ST64_B32: 'RETURN_DATA[0] = MEM[ADDR + OFFSET0 * 4 * 64];\nRETURN_DATA[1] = MEM[ADDR + OFFSET1 * 4 * 64].',
  DSOp.DS_READ_I8: 'RETURN_DATA = signext(MEM[ADDR][7:0]).',
  DSOp.DS_READ_U8: "RETURN_DATA = {24'h0,MEM[ADDR][7:0]}.",
  DSOp.DS_READ_I16: 'RETURN_DATA = signext(MEM[ADDR][15:0]).',
  DSOp.DS_READ_U16: "RETURN_DATA = {16'h0,MEM[ADDR][15:0]}.",
  DSOp.DS_CONSUME: 'addr = M0.base + offset; // offset by LDS HWBASE, limit to M.size\nrtnval =  LDS(addr);\nLDS(addr) = LDS(addr) - countbits(valid mask);\nGPR[VDST] = rtnval; // return to all valid threads',
  DSOp.DS_APPEND: 'addr = M0.base + offset; // offset by LDS HWBASE, limit to M.size\nrtnval =  LDS(addr);\nLDS(addr) = LDS(addr) + countbits(valid mask);\nGPR[VDST] = rtnval; // return to all valid threads',
  DSOp.DS_ORDERED_COUNT: '0 = ring0 pixel wave\n1 = ring0 CS\n2 = ring1 CS\n3 = ring2 CS\nindex =  find first valid (vector mask)\ncount = src0[index][31:0];\nPkr_id =  gds_size[1:0];\ngds_atomic_address[15:2]  = gds_base[15:2] will contain the dword\nds_address[15:2]  =  gds_base[15:2] + offset0[7:2]  +\n//2 new control signals\nWave_release = Offset1[0];\nWave_done = offset1[1];\nPixel_wave = offset1[2];\n// 64bit',
  DSOp.DS_ADD_U64: 'tmp = MEM[ADDR];\nMEM[ADDR] += DATA[0:1];\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  DSOp.DS_SUB_U64: 'tmp = MEM[ADDR];\nMEM[ADDR] -= DATA[0:1];\nRETURN_DATA[0:1] = tmp.',
  DSOp.DS_RSUB_U64: '// 64bit\ntmp = MEM[ADDR];\nMEM[ADDR] = DATA - MEM[ADDR];\nRETURN_DATA = tmp.',
  DSOp.DS_INC_U64: '// 64bit\ntmp = MEM[ADDR];\nMEM[ADDR] = (tmp >= DATA[0:1]) ? 0 : tmp + 1; // unsigned compare\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  DSOp.DS_DEC_U64: 'tmp = MEM[ADDR];\nMEM[ADDR] = (tmp == 0 || tmp > DATA[0:1]) ? DATA[0:1] : tmp - 1;\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  DSOp.DS_MIN_I64: 'tmp = MEM[ADDR];\nMEM[ADDR] = (DATA[0:1] < tmp) ? DATA[0:1] : tmp; // signed\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  DSOp.DS_MAX_I64: 'tmp = MEM[ADDR];\nMEM[ADDR] = (DATA[0:1] > tmp) ? DATA[0:1] : tmp; // signed\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  DSOp.DS_MIN_U64: 'tmp = MEM[ADDR];\nMEM[ADDR] = (DATA[0:1] < tmp) ? DATA[0:1] : tmp; // unsigned\nRETURN_DATA[0:1] = tmp.',
  DSOp.DS_MAX_U64: '// 64bit\ntmp = MEM[ADDR];\nMEM[ADDR] = (DATA[0:1] > tmp) ? DATA[0:1] : tmp; // unsigned\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  DSOp.DS_AND_B64: 'tmp = MEM[ADDR];\nMEM[ADDR] &= DATA[0:1];\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  DSOp.DS_OR_B64: 'tmp = MEM[ADDR];\nMEM[ADDR] |= DATA[0:1];\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  DSOp.DS_XOR_B64: 'tmp = MEM[ADDR];\nMEM[ADDR] ^= DATA[0:1];\nRETURN_DATA[0:1] = tmp.',
  DSOp.DS_MSKOR_B64: '// 64bit\ntmp = MEM[ADDR];\nMEM[ADDR] = (MEM[ADDR] & ~DATA) | DATA2;\nRETURN_DATA = tmp.',
  DSOp.DS_WRITE_B64: '// 64bit\nMEM[ADDR] = DATA.',
  DSOp.DS_WRITE2_B64: '// 64bit\nMEM[ADDR + OFFSET0 * 8] = DATA;\nMEM[ADDR + OFFSET1 * 8] = DATA2.',
  DSOp.DS_WRITE2ST64_B64: '// 64bit\nMEM[ADDR + OFFSET0 * 8 * 64] = DATA;\nMEM[ADDR + OFFSET1 * 8 * 64] = DATA2.',
  DSOp.DS_CMPST_B64: '// 64bit\ntmp = MEM[ADDR];\nsrc = DATA2;\ncmp = DATA;\nMEM[ADDR] = (tmp == cmp) ? src : tmp;\nRETURN_DATA[0] = tmp.',
  DSOp.DS_CMPST_F64: '// 64bit\ntmp = MEM[ADDR];\nsrc = DATA2;\ncmp = DATA;\nMEM[ADDR] = (tmp == cmp) ? src : tmp;\nRETURN_DATA[0] = tmp.',
  DSOp.DS_MIN_F64: '// 64bit\ntmp = MEM[ADDR];\nsrc = DATA;\ncmp = DATA2;\nMEM[ADDR] = (cmp < tmp) ? src : tmp.',
  DSOp.DS_MAX_F64: '// 64bit\ntmp = MEM[ADDR];\nsrc = DATA;\ncmp = DATA2;\nMEM[ADDR] = (tmp > cmp) ? src : tmp.',
  DSOp.DS_ADD_RTN_F32: 'float tmp = MEM[ADDR].f32;\nMEM[ADDR].f32 += DATA0.f32;\nVDST.f32 = tmp;\n// 64bit',
  DSOp.DS_ADD_RTN_U64: 'tmp = MEM[ADDR];\nMEM[ADDR] += DATA[0:1];\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  DSOp.DS_SUB_RTN_U64: 'tmp = MEM[ADDR];\nMEM[ADDR] -= DATA[0:1];\nRETURN_DATA[0:1] = tmp.',
  DSOp.DS_RSUB_RTN_U64: '// 64bit\ntmp = MEM[ADDR];\nMEM[ADDR] = DATA - MEM[ADDR];\nRETURN_DATA = tmp.',
  DSOp.DS_INC_RTN_U64: '// 64bit\ntmp = MEM[ADDR];\nMEM[ADDR] = (tmp >= DATA[0:1]) ? 0 : tmp + 1; // unsigned compare\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  DSOp.DS_DEC_RTN_U64: 'tmp = MEM[ADDR];\nMEM[ADDR] = (tmp == 0 || tmp > DATA[0:1]) ? DATA[0:1] : tmp - 1;\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  DSOp.DS_MIN_RTN_I64: 'tmp = MEM[ADDR];\nMEM[ADDR] = (DATA[0:1] < tmp) ? DATA[0:1] : tmp; // signed\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  DSOp.DS_MAX_RTN_I64: 'tmp = MEM[ADDR];\nMEM[ADDR] = (DATA[0:1] > tmp) ? DATA[0:1] : tmp; // signed\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  DSOp.DS_MIN_RTN_U64: 'tmp = MEM[ADDR];\nMEM[ADDR] = (DATA[0:1] < tmp) ? DATA[0:1] : tmp; // unsigned\nRETURN_DATA[0:1] = tmp.',
  DSOp.DS_MAX_RTN_U64: '// 64bit\ntmp = MEM[ADDR];\nMEM[ADDR] = (DATA[0:1] > tmp) ? DATA[0:1] : tmp; // unsigned\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  DSOp.DS_AND_RTN_B64: 'tmp = MEM[ADDR];\nMEM[ADDR] &= DATA[0:1];\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  DSOp.DS_OR_RTN_B64: 'tmp = MEM[ADDR];\nMEM[ADDR] |= DATA[0:1];\nRETURN_DATA[0:1] = tmp.',
  DSOp.DS_XOR_RTN_B64: '// 64bit\ntmp = MEM[ADDR];\nMEM[ADDR] ^= DATA[0:1];\nRETURN_DATA[0:1] = tmp.',
  DSOp.DS_MSKOR_RTN_B64: '// 64bit\ntmp = MEM[ADDR];\nMEM[ADDR] = (MEM[ADDR] & ~DATA) | DATA2;\nRETURN_DATA = tmp.',
  DSOp.DS_WRXCHG_RTN_B64: 'tmp = MEM[ADDR];\nMEM[ADDR] = DATA;\nRETURN_DATA = tmp.',
  DSOp.DS_CMPST_RTN_B64: '// 64bit\ntmp = MEM[ADDR];\nsrc = DATA2;\ncmp = DATA;\nMEM[ADDR] = (tmp == cmp) ? src : tmp;\nRETURN_DATA[0] = tmp.',
  DSOp.DS_CMPST_RTN_F64: '// 64bit\ntmp = MEM[ADDR];\nsrc = DATA2;\ncmp = DATA;\nMEM[ADDR] = (tmp == cmp) ? src : tmp;\nRETURN_DATA[0] = tmp.',
  DSOp.DS_MIN_RTN_F64: '// 64bit\ntmp = MEM[ADDR];\nsrc = DATA;\ncmp = DATA2;\nMEM[ADDR] = (cmp < tmp) ? src : tmp.',
  DSOp.DS_MAX_RTN_F64: '// 64bit\ntmp = MEM[ADDR];\nsrc = DATA;\ncmp = DATA2;\nMEM[ADDR] = (tmp > cmp) ? src : tmp.',
  DSOp.DS_READ_B64: 'RETURN_DATA = MEM[ADDR].',
  DSOp.DS_READ2_B64: 'RETURN_DATA[0] = MEM[ADDR + OFFSET0 * 8];\nRETURN_DATA[1] = MEM[ADDR + OFFSET1 * 8].',
  DSOp.DS_READ2ST64_B64: 'RETURN_DATA[0] = MEM[ADDR + OFFSET0 * 8 * 64];\nRETURN_DATA[1] = MEM[ADDR + OFFSET1 * 8 * 64].',
  DSOp.DS_WRITE_B8_D16_HI: 'MEM[ADDR] = DATA[23:16].',
  DSOp.DS_WRITE_B16_D16_HI: 'MEM[ADDR] = DATA[31:16].',
  DSOp.DS_READ_U8_D16: "RETURN_DATA[15:0] = {8'h0,MEM[ADDR][7:0]}.",
  DSOp.DS_READ_U8_D16_HI: "RETURN_DATA[31:16] = {8'h0,MEM[ADDR][7:0]}.",
  DSOp.DS_READ_I8_D16: 'RETURN_DATA[15:0] = signext(MEM[ADDR][7:0]).',
  DSOp.DS_READ_I8_D16_HI: 'RETURN_DATA[31:16] = signext(MEM[ADDR][7:0]).',
  DSOp.DS_READ_U16_D16: 'RETURN_DATA[15:0] = MEM[ADDR][15:0].',
  DSOp.DS_READ_U16_D16_HI: 'RETURN_DATA[31:0] = MEM[ADDR][15:0].',
  DSOp.DS_WRITE_ADDTID_B32: 'LDS_GS[LDS_BASE + {OFFSET1,OFFSET0} + M0[15:0] + TID*4].u32 =',
  DSOp.DS_READ_ADDTID_B32: 'VGPR[VDST].u32 = LDS_GS[LDS_BASE + {OFFSET1,OFFSET0} + M0[15:0] +\n// VGPR[index][thread_id] is the VGPR RAM',
  DSOp.DS_PERMUTE_B32: '// VDST, ADDR and DATA0 are from the microcode DS encoding\ntmp[0..63] = 0\nfor i in 0..63 do\n// If a source thread is disabled, it will not propagate data.\nnext if !EXEC[i]\n// ADDR needs to be divided by 4.\n// High-order bits are ignored.\ndst_lane = floor((VGPR[ADDR][i] + OFFSET) / 4) mod 64\ntmp[dst_lane] = VGPR[DATA0][i]\nendfor\n// Copy data into destination VGPRs. If multiple sources\n// select the same destination thread, the highest-numbered\n// source thread wins.\nfor i in 0..63 do\nnext if !EXEC[i]\nVGPR[VDST][i] = tmp[i]\nendfor',
  DSOp.DS_BPERMUTE_B32: '// VDST, ADDR and DATA0 are from the microcode DS encoding\ntmp[0..63] = 0\nfor i in 0..63 do\n// ADDR needs to be divided by 4.\n// High-order bits are ignored.\nsrc_lane = floor((VGPR[ADDR][i] + OFFSET) / 4) mod 64\n// EXEC is applied to the source VGPR reads.\nnext if !EXEC[src_lane]\ntmp[i] = VGPR[DATA0][src_lane]\nendfor\n// Copy data into destination VGPRs. Some source\n// data may be broadcast to multiple lanes.\nfor i in 0..63 do\nnext if !EXEC[i]\nVGPR[VDST][i] = tmp[i]\nendfor',
  DSOp.DS_WRITE_B96: '{MEM[ADDR + 8], MEM[ADDR + 4], MEM[ADDR]} = DATA[95:0].',
  DSOp.DS_WRITE_B128: '{MEM[ADDR + 12], MEM[ADDR + 8], MEM[ADDR + 4], MEM[ADDR]} =',
  FLATOp.FLAT_STORE_DWORDX3: "D0[15:0] = {8'h0, MEM[ADDR]}.",
  FLATOp.FLAT_LOAD_UBYTE_D16: "D0[31:16] = {8'h0, MEM[ADDR]}.",
  FLATOp.FLAT_LOAD_SBYTE_D16: 'D0[15:0] = signext(MEM[ADDR]).',
  FLATOp.FLAT_LOAD_SBYTE_D16_HI: 'D0[31:16] = signext(MEM[ADDR]).',
  FLATOp.FLAT_LOAD_SHORT_D16: 'D0[15:0] = MEM[ADDR].',
  FLATOp.FLAT_LOAD_SHORT_D16_HI: 'D0[31:16] = MEM[ADDR].\n// 32bit',
  FLATOp.FLAT_ATOMIC_SWAP: 'tmp = MEM[ADDR];\nMEM[ADDR] = DATA;\nRETURN_DATA = tmp.\n// 32bit',
  FLATOp.FLAT_ATOMIC_CMPSWAP: 'tmp = MEM[ADDR];\nsrc = DATA[0];\ncmp = DATA[1];\nMEM[ADDR] = (tmp == cmp) ? src : tmp;\nRETURN_DATA[0] = tmp.\n// 32bit',
  FLATOp.FLAT_ATOMIC_ADD: 'tmp = MEM[ADDR];\nMEM[ADDR] += DATA;\nRETURN_DATA = tmp.',
  FLATOp.FLAT_ATOMIC_SUB: '// 32bit\ntmp = MEM[ADDR];\nMEM[ADDR] -= DATA;\nRETURN_DATA = tmp.\n// 32bit',
  FLATOp.FLAT_ATOMIC_SMIN: 'tmp = MEM[ADDR];\nMEM[ADDR] = (DATA < tmp) ? DATA : tmp; // signed compare\nRETURN_DATA = tmp.\n// 32bit',
  FLATOp.FLAT_ATOMIC_UMIN: 'tmp = MEM[ADDR];\nMEM[ADDR] = (DATA < tmp) ? DATA : tmp; // unsigned compare\nRETURN_DATA = tmp.\n// 32bit',
  FLATOp.FLAT_ATOMIC_SMAX: 'tmp = MEM[ADDR];\nMEM[ADDR] = (DATA > tmp) ? DATA : tmp; // signed compare\nRETURN_DATA = tmp.',
  FLATOp.FLAT_ATOMIC_UMAX: '// 32bit\ntmp = MEM[ADDR];\nMEM[ADDR] = (DATA > tmp) ? DATA : tmp; // unsigned compare\nRETURN_DATA = tmp.\n// 32bit',
  FLATOp.FLAT_ATOMIC_AND: 'tmp = MEM[ADDR];\nMEM[ADDR] &= DATA;\nRETURN_DATA = tmp.\n// 32bit',
  FLATOp.FLAT_ATOMIC_OR: 'tmp = MEM[ADDR];\nMEM[ADDR] |= DATA;\nRETURN_DATA = tmp.\n// 32bit',
  FLATOp.FLAT_ATOMIC_XOR: 'tmp = MEM[ADDR];\nMEM[ADDR] ^= DATA;\nRETURN_DATA = tmp.',
  FLATOp.FLAT_ATOMIC_INC: '// 32bit\ntmp = MEM[ADDR];\nMEM[ADDR] = (tmp >= DATA) ? 0 : tmp + 1; // unsigned\nRETURN_DATA = tmp.\n// 32bit',
  FLATOp.FLAT_ATOMIC_DEC: 'tmp = MEM[ADDR];\nMEM[ADDR] = (tmp == 0 || tmp > DATA) ? DATA : tmp - 1; //\nRETURN_DATA = tmp.',
  FLATOp.FLAT_ATOMIC_FCMPSWAP: '// 32bit\ntmp = MEM[ADDR];\nsrc = DATA[0];\ncmp = DATA[1];\nMEM[ADDR] = (tmp == cmp) ? src : tmp;\nRETURN_DATA[0] = tmp.\n// 32bit',
  FLATOp.FLAT_ATOMIC_FMIN: 'tmp = MEM[ADDR];\nsrc = DATA[0];\nMEM[ADDR] = (src < tmp) ? src : tmp;\nRETURN_DATA[0] = tmp.\n// 32bit',
  FLATOp.FLAT_ATOMIC_FMAX: 'tmp = MEM[ADDR];\nsrc = DATA[0];\nMEM[ADDR] = (src > tmp) ? src : tmp;\nRETURN_DATA[0] = tmp.\n// 64bit',
  FLATOp.FLAT_ATOMIC_SWAP_X2: 'tmp = MEM[ADDR];\nMEM[ADDR] = DATA[0:1];\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  FLATOp.FLAT_ATOMIC_CMPSWAP_X2: 'tmp = MEM[ADDR];\nsrc = DATA[0:1];\ncmp = DATA[2:3];\nMEM[ADDR] = (tmp == cmp) ? src : tmp;\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  FLATOp.FLAT_ATOMIC_ADD_X2: 'tmp = MEM[ADDR];\nMEM[ADDR] += DATA[0:1];\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  FLATOp.FLAT_ATOMIC_SUB_X2: 'tmp = MEM[ADDR];\nMEM[ADDR] -= DATA[0:1];\nRETURN_DATA[0:1] = tmp.',
  FLATOp.FLAT_ATOMIC_SMIN_X2: '// 64bit\ntmp = MEM[ADDR];\nMEM[ADDR] = (DATA[0:1] < tmp) ? DATA[0:1] : tmp; // signed\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  FLATOp.FLAT_ATOMIC_UMIN_X2: 'tmp = MEM[ADDR];\nMEM[ADDR] = (DATA[0:1] < tmp) ? DATA[0:1] : tmp; //\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  FLATOp.FLAT_ATOMIC_SMAX_X2: 'tmp = MEM[ADDR];\nMEM[ADDR] = (DATA[0:1] > tmp) ? DATA[0:1] : tmp; // signed\nRETURN_DATA[0:1] = tmp.',
  FLATOp.FLAT_ATOMIC_UMAX_X2: '// 64bit\ntmp = MEM[ADDR];\nMEM[ADDR] = (DATA[0:1] > tmp) ? DATA[0:1] : tmp; //\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  FLATOp.FLAT_ATOMIC_AND_X2: 'tmp = MEM[ADDR];\nMEM[ADDR] &= DATA[0:1];\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  FLATOp.FLAT_ATOMIC_OR_X2: 'tmp = MEM[ADDR];\nMEM[ADDR] |= DATA[0:1];\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  FLATOp.FLAT_ATOMIC_XOR_X2: 'tmp = MEM[ADDR];\nMEM[ADDR] ^= DATA[0:1];\nRETURN_DATA[0:1] = tmp.',
  FLATOp.FLAT_ATOMIC_INC_X2: '// 64bit\ntmp = MEM[ADDR];\nMEM[ADDR] = (tmp >= DATA[0:1]) ? 0 : tmp + 1; // unsigned\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  FLATOp.FLAT_ATOMIC_DEC_X2: 'tmp = MEM[ADDR];\nMEM[ADDR] = (tmp == 0 || tmp > DATA[0:1]) ? DATA[0:1] : tmp\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  FLATOp.FLAT_ATOMIC_FCMPSWAP_X2: 'tmp = MEM[ADDR];\nsrc = DATA[0];\ncmp = DATA[1];\nMEM[ADDR] = (tmp == cmp) ? src : tmp;\nRETURN_DATA[0] = tmp.',
  FLATOp.FLAT_ATOMIC_FMIN_X2: '// 64bit\ntmp = MEM[ADDR];\nsrc = DATA[0];\nMEM[ADDR] = (src < tmp) ? src : tmp;\nRETURN_DATA[0] = tmp.\n// 64bit',
  FLATOp.FLAT_ATOMIC_FMAX_X2: 'tmp = MEM[ADDR];\nsrc = DATA[0];\nMEM[ADDR] = (src > tmp) ? src : tmp;\nRETURN_DATA[0] = tmp.',
  GLOBALOp.GLOBAL_LOAD_UBYTE_D16: "D0[15:0] = {8'h0, MEM[ADDR]}.\nD0[31:16] = {8'h0, MEM[ADDR]}.",
  GLOBALOp.GLOBAL_LOAD_UBYTE_D16_HI: 'D0[15:0] = signext(MEM[ADDR]).',
  GLOBALOp.GLOBAL_LOAD_SBYTE_D16: 'D0[31:16] = signext(MEM[ADDR]).',
  GLOBALOp.GLOBAL_LOAD_SBYTE_D16_HI: 'D0[15:0] = MEM[ADDR].',
  GLOBALOp.GLOBAL_LOAD_SHORT_D16: 'D0[31:16] = MEM[ADDR].',
  GLOBALOp.GLOBAL_LOAD_SHORT_D16_HI: '// 32bit',
  GLOBALOp.GLOBAL_ATOMIC_SWAP: 'tmp = MEM[ADDR];\nMEM[ADDR] = DATA;\nRETURN_DATA = tmp.\n// 32bit',
  GLOBALOp.GLOBAL_ATOMIC_CMPSWAP: 'tmp = MEM[ADDR];\nsrc = DATA[0];\ncmp = DATA[1];\nMEM[ADDR] = (tmp == cmp) ? src : tmp;\nRETURN_DATA[0] = tmp.',
  GLOBALOp.GLOBAL_ATOMIC_ADD: '// 32bit\ntmp = MEM[ADDR];\nMEM[ADDR] += DATA;\nRETURN_DATA = tmp.\n// 32bit',
  GLOBALOp.GLOBAL_ATOMIC_SUB: 'tmp = MEM[ADDR];\nMEM[ADDR] -= DATA;\nRETURN_DATA = tmp.\n// 32bit',
  GLOBALOp.GLOBAL_ATOMIC_CSUB: 'old_value = MEM[ADDR];\nif old_value < DATA then\nnew_value = 0;\nelse\nnew_value = old_value - DATA;\nendif;\nMEM[addr] = new_value;\nRETURN_DATA = old_value.\n// 32bit',
  GLOBALOp.GLOBAL_ATOMIC_SMIN: 'tmp = MEM[ADDR];\nMEM[ADDR] = (DATA < tmp) ? DATA : tmp; // signed compare\nRETURN_DATA = tmp.\n// 32bit',
  GLOBALOp.GLOBAL_ATOMIC_UMIN: 'tmp = MEM[ADDR];\nMEM[ADDR] = (DATA < tmp) ? DATA : tmp; // unsigned compare\nRETURN_DATA = tmp.\n// 32bit',
  GLOBALOp.GLOBAL_ATOMIC_SMAX: 'tmp = MEM[ADDR];\nMEM[ADDR] = (DATA > tmp) ? DATA : tmp; // signed compare\nRETURN_DATA = tmp.\n// 32bit',
  GLOBALOp.GLOBAL_ATOMIC_UMAX: 'tmp = MEM[ADDR];\nMEM[ADDR] = (DATA > tmp) ? DATA : tmp; // unsigned compare\nRETURN_DATA = tmp.\n// 32bit',
  GLOBALOp.GLOBAL_ATOMIC_AND: 'tmp = MEM[ADDR];\nMEM[ADDR] &= DATA;\nRETURN_DATA = tmp.\n// 32bit',
  GLOBALOp.GLOBAL_ATOMIC_OR: 'tmp = MEM[ADDR];\nMEM[ADDR] |= DATA;\nRETURN_DATA = tmp.',
  GLOBALOp.GLOBAL_ATOMIC_XOR: '// 32bit\ntmp = MEM[ADDR];\nMEM[ADDR] ^= DATA;\nRETURN_DATA = tmp.\n// 32bit',
  GLOBALOp.GLOBAL_ATOMIC_INC: 'tmp = MEM[ADDR];\nMEM[ADDR] = (tmp >= DATA) ? 0 : tmp + 1; // unsigned\nRETURN_DATA = tmp.\n// 32bit',
  GLOBALOp.GLOBAL_ATOMIC_DEC: 'tmp = MEM[ADDR];\nMEM[ADDR] = (tmp == 0 || tmp > DATA) ? DATA : tmp - 1; //\nRETURN_DATA = tmp.',
  GLOBALOp.GLOBAL_ATOMIC_FCMPSWAP: '// 32bit\ntmp = MEM[ADDR];\nsrc = DATA[0];\ncmp = DATA[1];\nMEM[ADDR] = (tmp == cmp) ? src : tmp;\nRETURN_DATA[0] = tmp.\n// 32bit',
  GLOBALOp.GLOBAL_ATOMIC_FMIN: 'tmp = MEM[ADDR];\nsrc = DATA[0];\nMEM[ADDR] = (src < tmp) ? src : tmp;\nRETURN_DATA[0] = tmp.\n// 32bit',
  GLOBALOp.GLOBAL_ATOMIC_FMAX: 'tmp = MEM[ADDR];\nsrc = DATA[0];\nMEM[ADDR] = (src > tmp) ? src : tmp;\nRETURN_DATA[0] = tmp.\n// 64bit',
  GLOBALOp.GLOBAL_ATOMIC_SWAP_X2: 'tmp = MEM[ADDR];\nMEM[ADDR] = DATA[0:1];\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  GLOBALOp.GLOBAL_ATOMIC_CMPSWAP_X2: 'tmp = MEM[ADDR];\nsrc = DATA[0:1];\ncmp = DATA[2:3];\nMEM[ADDR] = (tmp == cmp) ? src : tmp;\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  GLOBALOp.GLOBAL_ATOMIC_ADD_X2: 'tmp = MEM[ADDR];\nMEM[ADDR] += DATA[0:1];\nRETURN_DATA[0:1] = tmp.',
  GLOBALOp.GLOBAL_ATOMIC_SUB_X2: '// 64bit\ntmp = MEM[ADDR];\nMEM[ADDR] -= DATA[0:1];\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  GLOBALOp.GLOBAL_ATOMIC_SMIN_X2: 'tmp = MEM[ADDR];\nMEM[ADDR] = (DATA[0:1] < tmp) ? DATA[0:1] : tmp; // signed\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  GLOBALOp.GLOBAL_ATOMIC_UMIN_X2: 'tmp = MEM[ADDR];\nMEM[ADDR] = (DATA[0:1] < tmp) ? DATA[0:1] : tmp; //\nRETURN_DATA[0:1] = tmp.',
  GLOBALOp.GLOBAL_ATOMIC_SMAX_X2: '// 64bit\ntmp = MEM[ADDR];\nMEM[ADDR] = (DATA[0:1] > tmp) ? DATA[0:1] : tmp; // signed\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  GLOBALOp.GLOBAL_ATOMIC_UMAX_X2: 'tmp = MEM[ADDR];\nMEM[ADDR] = (DATA[0:1] > tmp) ? DATA[0:1] : tmp; //\nRETURN_DATA[0:1] = tmp.',
  GLOBALOp.GLOBAL_ATOMIC_AND_X2: '// 64bit\ntmp = MEM[ADDR];\nMEM[ADDR] &= DATA[0:1];\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  GLOBALOp.GLOBAL_ATOMIC_OR_X2: 'tmp = MEM[ADDR];\nMEM[ADDR] |= DATA[0:1];\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  GLOBALOp.GLOBAL_ATOMIC_XOR_X2: 'tmp = MEM[ADDR];\nMEM[ADDR] ^= DATA[0:1];\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  GLOBALOp.GLOBAL_ATOMIC_INC_X2: 'tmp = MEM[ADDR];\nMEM[ADDR] = (tmp >= DATA[0:1]) ? 0 : tmp + 1; // unsigned\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  GLOBALOp.GLOBAL_ATOMIC_DEC_X2: 'tmp = MEM[ADDR];\nMEM[ADDR] = (tmp == 0 || tmp > DATA[0:1]) ? DATA[0:1] : tmp\nRETURN_DATA[0:1] = tmp.',
  GLOBALOp.GLOBAL_ATOMIC_FMIN_X2: 'tmp = MEM[ADDR];\nsrc = DATA[0];\nMEM[ADDR] = (src < tmp) ? src : tmp;\nRETURN_DATA[0] = tmp.\n// 64bit',
  GLOBALOp.GLOBAL_ATOMIC_FMAX_X2: 'tmp = MEM[ADDR];\nsrc = DATA[0];\nMEM[ADDR] = (src > tmp) ? src : tmp;\nRETURN_DATA[0] = tmp.',
  MIMGOp.IMAGE_GET_RESINFO: '// 32bit',
  MIMGOp.IMAGE_ATOMIC_SWAP: 'tmp = MEM[ADDR];\nMEM[ADDR] = DATA;\nRETURN_DATA = tmp.\n// 32bit',
  MIMGOp.IMAGE_ATOMIC_CMPSWAP: 'tmp = MEM[ADDR];\nsrc = DATA[0];\ncmp = DATA[1];\nMEM[ADDR] = (tmp == cmp) ? src : tmp;\nRETURN_DATA[0] = tmp.',
  MIMGOp.IMAGE_ATOMIC_ADD: '// 32bit\ntmp = MEM[ADDR];\nMEM[ADDR] += DATA;\nRETURN_DATA = tmp.\n// 32bit',
  MIMGOp.IMAGE_ATOMIC_SUB: 'tmp = MEM[ADDR];\nMEM[ADDR] -= DATA;\nRETURN_DATA = tmp.\n// 32bit',
  MIMGOp.IMAGE_ATOMIC_SMIN: 'tmp = MEM[ADDR];\nMEM[ADDR] = (DATA < tmp) ? DATA : tmp; // signed compare\nRETURN_DATA = tmp.',
  MIMGOp.IMAGE_ATOMIC_UMIN: '// 32bit\ntmp = MEM[ADDR];\nMEM[ADDR] = (DATA < tmp) ? DATA : tmp; // unsigned compare\nRETURN_DATA = tmp.\n// 32bit',
  MIMGOp.IMAGE_ATOMIC_SMAX: 'tmp = MEM[ADDR];\nMEM[ADDR] = (DATA > tmp) ? DATA : tmp; // signed compare\nRETURN_DATA = tmp.\n// 32bit',
  MIMGOp.IMAGE_ATOMIC_UMAX: 'tmp = MEM[ADDR];\nMEM[ADDR] = (DATA > tmp) ? DATA : tmp; // unsigned compare\nRETURN_DATA = tmp.',
  MIMGOp.IMAGE_ATOMIC_AND: '// 32bit\ntmp = MEM[ADDR];\nMEM[ADDR] &= DATA;\nRETURN_DATA = tmp.\n// 32bit',
  MIMGOp.IMAGE_ATOMIC_OR: 'tmp = MEM[ADDR];\nMEM[ADDR] |= DATA;\nRETURN_DATA = tmp.\n// 32bit',
  MIMGOp.IMAGE_ATOMIC_XOR: 'tmp = MEM[ADDR];\nMEM[ADDR] ^= DATA;\nRETURN_DATA = tmp.\n// 32bit',
  MIMGOp.IMAGE_ATOMIC_INC: 'tmp = MEM[ADDR];\nMEM[ADDR] = (tmp >= DATA) ? 0 : tmp + 1; // unsigned\nRETURN_DATA = tmp.\n// 32bit',
  MIMGOp.IMAGE_ATOMIC_DEC: 'tmp = MEM[ADDR];\nMEM[ADDR] = (tmp == 0 || tmp > DATA) ? DATA : tmp - 1; //\nRETURN_DATA = tmp.',
  MIMGOp.IMAGE_ATOMIC_FCMPSWAP: '// 32bit\ntmp = MEM[ADDR];\nsrc = DATA[0];\ncmp = DATA[1];\nMEM[ADDR] = (tmp == cmp) ? src : tmp;\nRETURN_DATA[0] = tmp.\n// 32bit',
  MIMGOp.IMAGE_ATOMIC_FMIN: 'tmp = MEM[ADDR];\nsrc = DATA[0];\nMEM[ADDR] = (src < tmp) ? src : tmp;\nRETURN_DATA[0] = tmp.\n// 32bit',
  MIMGOp.IMAGE_ATOMIC_FMAX: 'tmp = MEM[ADDR];\nsrc = DATA[0];\nMEM[ADDR] = (src > tmp) ? src : tmp;\nRETURN_DATA[0] = tmp.',
  MIMGOp.IMAGE_GET_LOD: 'VDATA[0] = clampedLOD;\nVDATA[1] = rawLOD.',
  MIMGOp.IMAGE_BVH_INTERSECT_RAY: 'vgpr_a[0] = node_pointer (uint32)\nvgpr_a[1] = ray_extent (float32)\nvgpr_a[2] = ray_origin.x (float32)\nvgpr_a[3] = ray_origin.y (float32)\nvgpr_a[4] = ray_origin.z (float32)\nvgpr_a[5] = ray_dir.x (float32)\nvgpr_a[6] = ray_dir.y (float32)\nvgpr_a[7] = ray_dir.z (float32)\nvgpr_a[8] = ray_inv_dir.x (float32)\nvgpr_a[9] = ray_inv_dir.y (float32)\nvgpr_a[10]= ray_inv_dir.z (float32)\nvgpr_a[0] = node_pointer (uint32)\nvgpr_a[1] = ray_extent (float32)\nvgpr_a[2] = ray_origin.x (float32)\nvgpr_a[3] = ray_origin.y (float32)\nvgpr_a[4] = ray_origin.z (float32)\nvgpr_a[5] = {ray_dir.x,ray_dir.y}(2x float16)\nvgpr_a[6] = {ray_dir.z,ray_inv_dir.x}(2x float16)\nvgpr_a[7] = {ray_inv_dir.y,ray_inv_dir.z}(2x float16)',
  MIMGOp.IMAGE_BVH64_INTERSECT_RAY: 'vgpr_a[0] = node_pointer[31:0] (first part of uint64)\nvgpr_a[1] = node_pointer[63:32] (second part of uint64)\nvgpr_a[2] = ray_extent (float32)\nvgpr_a[3] = ray_origin.x (float32)\nvgpr_a[4] = ray_origin.y (float32)\nvgpr_a[5] = ray_origin.z (float32)\nvgpr_a[6] = ray_dir.x (float32)\nvgpr_a[7] = ray_dir.y (float32)\nvgpr_a[8] = ray_dir.z (float32)\nvgpr_a[9] = ray_inv_dir.x (float32)\nvgpr_a[10]= ray_inv_dir.y (float32)\nvgpr_a[11]= ray_inv_dir.z (float32)\nvgpr_a[0] = node_pointer[31:0] (first part of uint64)\nvgpr_a[1] = node_pointer[63:32] (second part of uint64)\nvgpr_a[2] = ray_extent (float32)\nvgpr_a[3] = ray_origin.x (float32)\nvgpr_a[4] = ray_origin.y (float32)\nvgpr_a[5] = ray_origin.z (float32)\nvgpr_a[6] = {ray_dir.x,ray_dir.y} (2x float16)\nvgpr_a[7] = {ray_dir.z,ray_inv_dir.x} (2x float16)\nvgpr_a[8] = {ray_inv_dir.y,ray_inv_dir.z} (2x float16)',
  MUBUFOp.BUFFER_LOAD_UBYTE_D16: "D0[15:0] = {8'h0, MEM[ADDR]}.",
  MUBUFOp.BUFFER_LOAD_UBYTE_D16_HI: "D0[31:16] = {8'h0, MEM[ADDR]}.",
  MUBUFOp.BUFFER_LOAD_SBYTE_D16: 'D0[15:0] = signext(MEM[ADDR]).',
  MUBUFOp.BUFFER_LOAD_SBYTE_D16_HI: 'D0[31:16] = signext(MEM[ADDR]).\nD0[15:0] = MEM[ADDR].',
  MUBUFOp.BUFFER_LOAD_SHORT_D16: 'D0[31:16] = MEM[ADDR].',
  MUBUFOp.BUFFER_LOAD_SHORT_D16_HI: 'D0[31:16] = MEM[ADDR].',
  MUBUFOp.BUFFER_STORE_FORMAT_D16_HI_X: '// 32bit',
  MUBUFOp.BUFFER_ATOMIC_SWAP: 'tmp = MEM[ADDR];\nMEM[ADDR] = DATA;\nRETURN_DATA = tmp.\n// 32bit',
  MUBUFOp.BUFFER_ATOMIC_CMPSWAP: 'tmp = MEM[ADDR];\nsrc = DATA[0];\ncmp = DATA[1];\nMEM[ADDR] = (tmp == cmp) ? src : tmp;\nRETURN_DATA[0] = tmp.\n// 32bit',
  MUBUFOp.BUFFER_ATOMIC_ADD: 'tmp = MEM[ADDR];\nMEM[ADDR] += DATA;\nRETURN_DATA = tmp.',
  MUBUFOp.BUFFER_ATOMIC_SUB: '// 32bit\ntmp = MEM[ADDR];\nMEM[ADDR] -= DATA;\nRETURN_DATA = tmp.\n// 32bit',
  MUBUFOp.BUFFER_ATOMIC_CSUB: 'old_value = MEM[ADDR];\nif old_value < DATA then\nnew_value = 0;\nelse\nnew_value = old_value - DATA;\nendif;\nMEM[addr] = new_value;\nRETURN_DATA = old_value.',
  MUBUFOp.BUFFER_ATOMIC_SMIN: '// 32bit\ntmp = MEM[ADDR];\nMEM[ADDR] = (DATA < tmp) ? DATA : tmp; // signed compare\nRETURN_DATA = tmp.\n// 32bit',
  MUBUFOp.BUFFER_ATOMIC_UMIN: 'tmp = MEM[ADDR];\nMEM[ADDR] = (DATA < tmp) ? DATA : tmp; // unsigned\nRETURN_DATA = tmp.\n// 32bit',
  MUBUFOp.BUFFER_ATOMIC_SMAX: 'tmp = MEM[ADDR];\nMEM[ADDR] = (DATA > tmp) ? DATA : tmp; // signed compare\nRETURN_DATA = tmp.',
  MUBUFOp.BUFFER_ATOMIC_UMAX: '// 32bit\ntmp = MEM[ADDR];\nMEM[ADDR] = (DATA > tmp) ? DATA : tmp; // unsigned\nRETURN_DATA = tmp.\n// 32bit',
  MUBUFOp.BUFFER_ATOMIC_AND: 'tmp = MEM[ADDR];\nMEM[ADDR] &= DATA;\nRETURN_DATA = tmp.\n// 32bit',
  MUBUFOp.BUFFER_ATOMIC_OR: 'tmp = MEM[ADDR];\nMEM[ADDR] |= DATA;\nRETURN_DATA = tmp.',
  MUBUFOp.BUFFER_ATOMIC_XOR: '// 32bit\ntmp = MEM[ADDR];\nMEM[ADDR] ^= DATA;\nRETURN_DATA = tmp.\n// 32bit',
  MUBUFOp.BUFFER_ATOMIC_INC: 'tmp = MEM[ADDR];\nMEM[ADDR] = (tmp >= DATA) ? 0 : tmp + 1; // unsigned\nRETURN_DATA = tmp.\n// 32bit',
  MUBUFOp.BUFFER_ATOMIC_DEC: 'tmp = MEM[ADDR];\nMEM[ADDR] = (tmp == 0 || tmp > DATA) ? DATA : tmp - 1;\nRETURN_DATA = tmp.\n// 32bit',
  MUBUFOp.BUFFER_ATOMIC_FCMPSWAP: 'tmp = MEM[ADDR];\nsrc = DATA[0];\ncmp = DATA[1];\nMEM[ADDR] = (tmp == cmp) ? src : tmp;\nRETURN_DATA[0] = tmp.\n// 32bit',
  MUBUFOp.BUFFER_ATOMIC_FMIN: 'tmp = MEM[ADDR];\nsrc = DATA[0];\nMEM[ADDR] = (src < tmp) ? src : tmp;\nRETURN_DATA[0] = tmp.\n// 32bit',
  MUBUFOp.BUFFER_ATOMIC_FMAX: 'tmp = MEM[ADDR];\nsrc = DATA[0];\nMEM[ADDR] = (src > tmp) ? src : tmp;\nRETURN_DATA[0] = tmp.',
  MUBUFOp.BUFFER_ATOMIC_SWAP_X2: '// 64bit\ntmp = MEM[ADDR];\nMEM[ADDR] = DATA[0:1];\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  MUBUFOp.BUFFER_ATOMIC_CMPSWAP_X2: 'tmp = MEM[ADDR];\nsrc = DATA[0:1];\ncmp = DATA[2:3];\nMEM[ADDR] = (tmp == cmp) ? src : tmp;\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  MUBUFOp.BUFFER_ATOMIC_ADD_X2: 'tmp = MEM[ADDR];\nMEM[ADDR] += DATA[0:1];\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  MUBUFOp.BUFFER_ATOMIC_SUB_X2: 'tmp = MEM[ADDR];\nMEM[ADDR] -= DATA[0:1];\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  MUBUFOp.BUFFER_ATOMIC_SMIN_X2: 'tmp = MEM[ADDR];\nMEM[ADDR] = (DATA[0:1] < tmp) ? DATA[0:1] : tmp; //\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  MUBUFOp.BUFFER_ATOMIC_UMIN_X2: 'tmp = MEM[ADDR];\nMEM[ADDR] = (DATA[0:1] < tmp) ? DATA[0:1] : tmp; //\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  MUBUFOp.BUFFER_ATOMIC_SMAX_X2: 'tmp = MEM[ADDR];\nMEM[ADDR] = (DATA[0:1] > tmp) ? DATA[0:1] : tmp; //\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  MUBUFOp.BUFFER_ATOMIC_UMAX_X2: 'tmp = MEM[ADDR];\nMEM[ADDR] = (DATA[0:1] > tmp) ? DATA[0:1] : tmp; //\nRETURN_DATA[0:1] = tmp.',
  MUBUFOp.BUFFER_ATOMIC_AND_X2: '// 64bit\ntmp = MEM[ADDR];\nMEM[ADDR] &= DATA[0:1];\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  MUBUFOp.BUFFER_ATOMIC_OR_X2: 'tmp = MEM[ADDR];\nMEM[ADDR] |= DATA[0:1];\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  MUBUFOp.BUFFER_ATOMIC_XOR_X2: 'tmp = MEM[ADDR];\nMEM[ADDR] ^= DATA[0:1];\nRETURN_DATA[0:1] = tmp.',
  MUBUFOp.BUFFER_ATOMIC_INC_X2: '// 64bit\ntmp = MEM[ADDR];\nMEM[ADDR] = (tmp >= DATA[0:1]) ? 0 : tmp + 1; //\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  MUBUFOp.BUFFER_ATOMIC_DEC_X2: 'tmp = MEM[ADDR];\nMEM[ADDR] = (tmp == 0 || tmp > DATA[0:1]) ? DATA[0:1] :\nRETURN_DATA[0:1] = tmp.\n// 64bit',
  MUBUFOp.BUFFER_ATOMIC_FCMPSWAP_X2: 'tmp = MEM[ADDR];\nsrc = DATA[0];\ncmp = DATA[1];\nMEM[ADDR] = (tmp == cmp) ? src : tmp;\nRETURN_DATA[0] = tmp.',
  MUBUFOp.BUFFER_ATOMIC_FMIN_X2: '// 64bit\ntmp = MEM[ADDR];\nsrc = DATA[0];\nMEM[ADDR] = (src < tmp) ? src : tmp;\nRETURN_DATA[0] = tmp.\n// 64bit',
  MUBUFOp.BUFFER_ATOMIC_FMAX_X2: 'tmp = MEM[ADDR];\nsrc = DATA[0];\nMEM[ADDR] = (src > tmp) ? src : tmp;\nRETURN_DATA[0] = tmp.',
  SCRATCHOp.SCRATCH_STORE_DWORDX3: "D0[15:0] = {8'h0, MEM[ADDR]}.",
  SCRATCHOp.SCRATCH_LOAD_UBYTE_D16: "D0[31:16] = {8'h0, MEM[ADDR]}.",
  SCRATCHOp.SCRATCH_LOAD_UBYTE_D16_HI: 'D0[15:0] = signext(MEM[ADDR]).',
  SCRATCHOp.SCRATCH_LOAD_SBYTE_D16_HI: 'D0[31:16] = signext(MEM[ADDR]).',
  SCRATCHOp.SCRATCH_LOAD_SHORT_D16: 'D0[15:0] = MEM[ADDR].',
  SCRATCHOp.SCRATCH_LOAD_SHORT_D16_HI: 'D0[31:16] = MEM[ADDR].',
  SOP1Op.S_MOV_B32: 'D.u = S0.u.',
  SOP1Op.S_MOV_B64: 'D.u64 = S0.u64.',
  SOP1Op.S_CMOV_B32: 'if(SCC) then\nD.u = S0.u;\nendif.',
  SOP1Op.S_CMOV_B64: 'if(SCC) then\nD.u64 = S0.u64;\nendif.',
  SOP1Op.S_NOT_B32: 'D = ~S0;\nSCC = (D != 0).',
  SOP1Op.S_NOT_B64: 'D = ~S0;\nSCC = (D != 0).',
  SOP1Op.S_WQM_B32: 'for i in 0 ... opcode_size_in_bits - 1 do\nD[i] = (S0[(i & ~3):(i | 3)] != 0);\nendfor;\nSCC = (D != 0).',
  SOP1Op.S_WQM_B64: 'for i in 0 ... opcode_size_in_bits - 1 do\nD[i] = (S0[(i & ~3):(i | 3)] != 0);\nendfor;\nSCC = (D != 0).',
  SOP1Op.S_BREV_B32: 'D.u[31:0] = S0.u[0:31].',
  SOP1Op.S_BREV_B64: 'D.u64[63:0] = S0.u64[0:63].',
  SOP1Op.S_BCNT0_I32_B32: 'D = 0;\nfor i in 0 ... opcode_size_in_bits - 1 do\nD += (S0[i] == 0 ? 1 : 0)\nendfor;\nSCC = (D != 0).',
  SOP1Op.S_BCNT0_I32_B64: 'D = 0;\nfor i in 0 ... opcode_size_in_bits - 1 do\nD += (S0[i] == 0 ? 1 : 0)\nendfor;\nSCC = (D != 0).',
  SOP1Op.S_BCNT1_I32_B32: 'D = 0;\nfor i in 0 ... opcode_size_in_bits - 1 do\nD += (S0[i] == 1 ? 1 : 0)\nendfor;\nSCC = (D != 0).',
  SOP1Op.S_BCNT1_I32_B64: 'D = 0;\nfor i in 0 ... opcode_size_in_bits - 1 do\nD += (S0[i] == 1 ? 1 : 0)\nendfor;\nSCC = (D != 0).',
  SOP1Op.S_FF0_I32_B32: 'D.i = -1; // Set if no zeros are found\nfor i in 0 ... opcode_size_in_bits - 1 do // Search from LSB\nif S0[i] == 0 then\nD.i = i;\nbreak for;\nendif;\nendfor.',
  SOP1Op.S_FF0_I32_B64: 'D.i = -1; // Set if no zeros are found\nfor i in 0 ... opcode_size_in_bits - 1 do // Search from LSB\nif S0[i] == 0 then\nD.i = i;\nbreak for;\nendif;\nendfor.',
  SOP1Op.S_FF1_I32_B32: 'D.i = -1; // Set if no ones are found\nfor i in 0 ... opcode_size_in_bits - 1 do // Search from LSB\nif S0[i] == 1 then\nD.i = i;\nbreak for;\nendif;\nendfor.',
  SOP1Op.S_FF1_I32_B64: 'D.i = -1; // Set if no ones are found\nfor i in 0 ... opcode_size_in_bits - 1 do // Search from LSB\nif S0[i] == 1 then\nD.i = i;\nbreak for;\nendif;\nendfor.',
  SOP1Op.S_FLBIT_I32_B32: 'D.i = -1; // Set if no ones are found\nfor i in 0 ... opcode_size_in_bits - 1 do\n// Note: search is from the MSB\nif S0[opcode_size_in_bits - 1 - i] == 1 then\nD.i = i;\nbreak for;\nendif;\nendfor.',
  SOP1Op.S_FLBIT_I32_B64: 'D.i = -1; // Set if no ones are found\nfor i in 0 ... opcode_size_in_bits - 1 do\n// Note: search is from the MSB\nif S0[opcode_size_in_bits - 1 - i] == 1 then\nD.i = i;\nbreak for;\nendif;\nendfor.',
  SOP1Op.S_FLBIT_I32: 'D.i = -1; // Set if all bits are the same\nfor i in 1 ... opcode_size_in_bits - 1 do\n// Note: search is from the MSB\nif S0[opcode_size_in_bits - 1 - i] != S0[opcode_size_in_bits - 1]\nD.i = i;\nbreak for;\nendif;\nendfor.',
  SOP1Op.S_FLBIT_I32_I64: 'D.i = -1; // Set if all bits are the same\nfor i in 1 ... opcode_size_in_bits - 1 do\n// Note: search is from the MSB\nif S0[opcode_size_in_bits - 1 - i] != S0[opcode_size_in_bits - 1]\nD.i = i;\nbreak for;\nendif;\nendfor.',
  SOP1Op.S_SEXT_I32_I8: 'D.i = signext(S0.i[7:0]).',
  SOP1Op.S_SEXT_I32_I16: 'D.i = signext(S0.i[15:0]).',
  SOP1Op.S_BITSET0_B32: 'D.u[S0.u[4:0]] = 0.',
  SOP1Op.S_BITSET0_B64: 'D.u64[S0.u[5:0]] = 0.',
  SOP1Op.S_BITSET1_B32: 'D.u[S0.u[4:0]] = 1.',
  SOP1Op.S_BITSET1_B64: 'D.u64[S0.u[5:0]] = 1.',
  SOP1Op.S_GETPC_B64: 'D.u64 = PC + 4.',
  SOP1Op.S_SETPC_B64: 'PC = S0.u64.',
  SOP1Op.S_SWAPPC_B64: 'D.u64 = PC + 4;\nPC = S0.u64.',
  SOP1Op.S_RFE_B64: 'PRIV = 0;\nPC = S0.u64.',
  SOP1Op.S_AND_SAVEEXEC_B64: 'D.u64 = EXEC;\nEXEC = S0.u64 & EXEC;\nSCC = (EXEC != 0).',
  SOP1Op.S_OR_SAVEEXEC_B64: 'D.u64 = EXEC;\nEXEC = S0.u64 | EXEC;\nSCC = (EXEC != 0).',
  SOP1Op.S_XOR_SAVEEXEC_B64: 'D.u64 = EXEC;\nEXEC = S0.u64 ^ EXEC;\nSCC = (EXEC != 0).',
  SOP1Op.S_ANDN2_SAVEEXEC_B64: 'D.u64 = EXEC;\nEXEC = S0.u64 & ~EXEC;\nSCC = (EXEC != 0).',
  SOP1Op.S_ORN2_SAVEEXEC_B64: 'D.u64 = EXEC;\nEXEC = S0.u64 | ~EXEC;\nSCC = (EXEC != 0).',
  SOP1Op.S_NAND_SAVEEXEC_B64: 'D.u64 = EXEC;\nEXEC = ~(S0.u64 & EXEC);\nSCC = (EXEC != 0).',
  SOP1Op.S_NOR_SAVEEXEC_B64: 'D.u64 = EXEC;\nEXEC = ~(S0.u64 | EXEC);\nSCC = (EXEC != 0).',
  SOP1Op.S_XNOR_SAVEEXEC_B64: 'D.u64 = EXEC;\nEXEC = ~(S0.u64 ^ EXEC);\nSCC = (EXEC != 0).',
  SOP1Op.S_QUADMASK_B32: 'D = 0;\nfor i in 0 ... (opcode_size_in_bits / 4) - 1 do\nD[i] = (S0[i * 4 + 3:i * 4] != 0);\nendfor;\nSCC = (D != 0).',
  SOP1Op.S_QUADMASK_B64: 'D = 0;\nfor i in 0 ... (opcode_size_in_bits / 4) - 1 do\nD[i] = (S0[i * 4 + 3:i * 4] != 0);\nendfor;\nSCC = (D != 0).',
  SOP1Op.S_MOVRELS_B32: 'SGPR[D.addr].u32 = SGPR[S0.addr+M0[31:0]].u32',
  SOP1Op.S_MOVRELS_B64: 'SGPR[D.addr].u64 = SGPR[S0.addr+M0[31:0]].u64',
  SOP1Op.S_MOVRELD_B32: 'SGPR[D.addr+M0[31:0]].u32 = SGPR[S0.addr].u32',
  SOP1Op.S_MOVRELD_B64: 'SGPR[D.addr+M0[31:0]].u64 = SGPR[S0.addr].u64',
  SOP1Op.S_ABS_I32: 'D.i = (S.i < 0 ? -S.i : S.i);\nSCC = (D.i != 0).',
  SOP1Op.S_ANDN1_SAVEEXEC_B64: 'D.u64 = EXEC;\nEXEC = ~S0.u64 & EXEC;\nSCC = (EXEC != 0).',
  SOP1Op.S_ORN1_SAVEEXEC_B64: 'D.u64 = EXEC;\nEXEC = ~S0.u64 | EXEC;\nSCC = (EXEC != 0).',
  SOP1Op.S_ANDN1_WREXEC_B64: 'EXEC = ~S0.u64 & EXEC;\nD.u64 = EXEC;\nSCC = (EXEC != 0).',
  SOP1Op.S_ANDN2_WREXEC_B64: 'EXEC = S0.u64 & ~EXEC;\nD.u64 = EXEC;\nSCC = (EXEC != 0).\n// V0 holds the index value per lane\n// save exec mask for restore at the end\ns_mov_b64 s2, exec\n// exec mask of remaining (unprocessed) threads\ns_mov_b64 s4, exec\nloop:\n// get the index value for the first active lane\nv_readfirstlane_b32  s0, v0\n// find all other lanes with same index value\nv_cmpx_eq s0, v0\n<OP>       // do the operation using the current EXEC mask. S0 holds\n// mask out thread that was just executed\n// s_andn2_b64  s4, s4, exec\n// s_mov_b64    exec, s4\ns_andn2_wrexec_b64 s4, s4    // replaces above 2 ops\n// repeat until EXEC==0\ns_cbranch_scc1  loop\ns_mov_b64    exec, s2',
  SOP1Op.S_BITREPLICATE_B64_B32: 'for i in 0 ... 31 do\nD.u64[i * 2 + 0] = S0.u32[i]\nD.u64[i * 2 + 1] = S0.u32[i]\nendfor.\ns_bitreplicate_b64 s2, s0\ns_bitreplicate_b64 s2, s2',
  SOP1Op.S_AND_SAVEEXEC_B32: 'D.u32 = EXEC_LO;\nEXEC_LO = S0.u32 & EXEC_LO;\nSCC = (EXEC_LO != 0).',
  SOP1Op.S_OR_SAVEEXEC_B32: 'D.u32 = EXEC_LO;\nEXEC_LO = S0.u32 | EXEC_LO;\nSCC = (EXEC_LO != 0).',
  SOP1Op.S_XOR_SAVEEXEC_B32: 'D.u32 = EXEC_LO;\nEXEC_LO = S0.u32 ^ EXEC_LO;\nSCC = (EXEC_LO != 0).',
  SOP1Op.S_ANDN2_SAVEEXEC_B32: 'D.u32 = EXEC_LO;\nEXEC_LO = S0.u32 & ~EXEC_LO;\nSCC = (EXEC_LO != 0).',
  SOP1Op.S_ORN2_SAVEEXEC_B32: 'D.u32 = EXEC_LO;\nEXEC_LO = S0.u32 | ~EXEC_LO;\nSCC = (EXEC_LO != 0).',
  SOP1Op.S_NAND_SAVEEXEC_B32: 'D.u32 = EXEC_LO;\nEXEC_LO = ~(S0.u32 & EXEC_LO);\nSCC = (EXEC_LO != 0).',
  SOP1Op.S_NOR_SAVEEXEC_B32: 'D.u32 = EXEC_LO;\nEXEC_LO = ~(S0.u32 | EXEC_LO);\nSCC = (EXEC_LO != 0).',
  SOP1Op.S_XNOR_SAVEEXEC_B32: 'D.u32 = EXEC_LO;\nEXEC_LO = ~(S0.u32 ^ EXEC_LO);\nSCC = (EXEC_LO != 0).',
  SOP1Op.S_ANDN1_SAVEEXEC_B32: 'D.u32 = EXEC_LO;\nEXEC_LO = ~S0.u32 & EXEC_LO;\nSCC = (EXEC_LO != 0).',
  SOP1Op.S_ORN1_SAVEEXEC_B32: 'D.u32 = EXEC_LO;\nEXEC_LO = ~S0.u32 | EXEC_LO;\nSCC = (EXEC_LO != 0).',
  SOP1Op.S_ANDN1_WREXEC_B32: 'EXEC_LO = ~S0.u32 & EXEC_LO;\nD.u32 = EXEC_LO;\nSCC = (EXEC_LO != 0).',
  SOP1Op.S_ANDN2_WREXEC_B32: 'EXEC_LO = S0.u32 & ~EXEC_LO;\nD.u32 = EXEC_LO;\nSCC = (EXEC_LO != 0).',
  SOP1Op.S_MOVRELSD_2_B32: 'SGPR[D.addr+M0[25:16]].u32 = SGPR[S0.addr+M0[9:0]].u32',
  SOP2Op.S_ADD_U32: 'D.u32 = S0.u32 + S1.u32;\nSCC = S0.u32 + S1.u32 >= 0x100000000ULL ? 1 : 0.',
  SOP2Op.S_SUB_U32: 'D.u = S0.u - S1.u;\nSCC = (S1.u > S0.u ? 1 : 0). // unsigned overflow or carry-out for',
  SOP2Op.S_ADD_I32: 'D.i = S0.i + S1.i;\nSCC = (S0.u[31] == S1.u[31] && S0.u[31] != D.u[31]). // signed',
  SOP2Op.S_SUB_I32: 'D.i = S0.i - S1.i;\nSCC = (S0.u[31] != S1.u[31] && S0.u[31] != D.u[31]). // signed',
  SOP2Op.S_ADDC_U32: 'D.u32 = S0.u32 + S1.u32 + SCC;\nSCC = S0.u32 + S1.u32 + SCC >= 0x100000000ULL ? 1 : 0.',
  SOP2Op.S_SUBB_U32: 'D.u = S0.u - S1.u - SCC;\nSCC = (S1.u + SCC > S0.u ? 1 : 0). // unsigned overflow.',
  SOP2Op.S_MIN_I32: 'D.i = (S0.i < S1.i) ? S0.i : S1.i;\nSCC = (S0.i < S1.i).',
  SOP2Op.S_MIN_U32: 'D.u = (S0.u < S1.u) ? S0.u : S1.u;\nSCC = (S0.u < S1.u).',
  SOP2Op.S_MAX_I32: 'D.i = (S0.i > S1.i) ? S0.i : S1.i;\nSCC = (S0.i > S1.i).',
  SOP2Op.S_MAX_U32: 'D.u = (S0.u > S1.u) ? S0.u : S1.u;\nSCC = (S0.u > S1.u).',
  SOP2Op.S_CSELECT_B32: 'D.u = SCC ? S0.u : S1.u.',
  SOP2Op.S_CSELECT_B64: 'D.u64 = SCC ? S0.u64 : S1.u64.',
  SOP2Op.S_AND_B32: 'D = S0 & S1;\nSCC = (D != 0).',
  SOP2Op.S_AND_B64: 'D = S0 & S1;\nSCC = (D != 0).',
  SOP2Op.S_OR_B32: 'D = S0 | S1;\nSCC = (D != 0).',
  SOP2Op.S_OR_B64: 'D = S0 | S1;\nSCC = (D != 0).',
  SOP2Op.S_XOR_B32: 'D = S0 ^ S1;\nSCC = (D != 0).',
  SOP2Op.S_XOR_B64: 'D = S0 ^ S1;\nSCC = (D != 0).',
  SOP2Op.S_ANDN2_B32: 'D = S0 & ~S1;\nSCC = (D != 0).',
  SOP2Op.S_ANDN2_B64: 'D = S0 & ~S1;\nSCC = (D != 0).',
  SOP2Op.S_ORN2_B32: 'D = S0 | ~S1;\nSCC = (D != 0).',
  SOP2Op.S_ORN2_B64: 'D = S0 | ~S1;\nSCC = (D != 0).',
  SOP2Op.S_NAND_B32: 'D = ~(S0 & S1);\nSCC = (D != 0).',
  SOP2Op.S_NAND_B64: 'D = ~(S0 & S1);\nSCC = (D != 0).',
  SOP2Op.S_NOR_B32: 'D = ~(S0 | S1);\nSCC = (D != 0).',
  SOP2Op.S_NOR_B64: 'D = ~(S0 | S1);\nSCC = (D != 0).',
  SOP2Op.S_XNOR_B32: 'D = ~(S0 ^ S1);\nSCC = (D != 0).',
  SOP2Op.S_XNOR_B64: 'D = ~(S0 ^ S1);\nSCC = (D != 0).',
  SOP2Op.S_LSHL_B32: 'D.u = S0.u << S1.u[4:0];\nSCC = (D.u != 0).',
  SOP2Op.S_LSHL_B64: 'D.u64 = S0.u64 << S1.u[5:0];\nSCC = (D.u64 != 0).',
  SOP2Op.S_LSHR_B32: 'D.u = S0.u >> S1.u[4:0];\nSCC = (D.u != 0).',
  SOP2Op.S_LSHR_B64: 'D.u64 = S0.u64 >> S1.u[5:0];\nSCC = (D.u64 != 0).',
  SOP2Op.S_ASHR_I32: 'D.i = signext(S0.i) >> S1.u[4:0];\nSCC = (D.i != 0).',
  SOP2Op.S_ASHR_I64: 'D.i64 = signext(S0.i64) >> S1.u[5:0];\nSCC = (D.i64 != 0).',
  SOP2Op.S_BFM_B32: 'D.u = ((1 << S0.u[4:0]) - 1) << S1.u[4:0].',
  SOP2Op.S_BFM_B64: 'D.u64 = ((1ULL << S0.u[5:0]) - 1) << S1.u[5:0].',
  SOP2Op.S_MUL_I32: 'D.i = S0.i * S1.i.',
  SOP2Op.S_BFE_U32: 'D.u = (S0.u >> S1.u[4:0]) & ((1 << S1.u[22:16]) - 1);\nSCC = (D.u != 0).',
  SOP2Op.S_BFE_I32: 'D.i = signext((S0.i >> S1.u[4:0]) & ((1 << S1.u[22:16]) - 1));\nSCC = (D.i != 0).',
  SOP2Op.S_BFE_U64: 'D.u64 = (S0.u64 >> S1.u[5:0]) & ((1 << S1.u[22:16]) - 1);\nSCC = (D.u64 != 0).',
  SOP2Op.S_BFE_I64: 'D.i64 = signext((S0.i64 >> S1.u[5:0]) & ((1 << S1.u[22:16]) - 1));\nSCC = (D.i64 != 0).',
  SOP2Op.S_ABSDIFF_I32: 'D.i = S0.i - S1.i;\nif(D.i < 0) then\nD.i = -D.i;\nendif;\nSCC = (D.i != 0).',
  SOP2Op.S_LSHL1_ADD_U32: 'D.u = (S0.u << N) + S1.u; // N is the shift value in the opcode\nSCC = (((S0.u << N) + S1.u) >= 0x100000000ULL ? 1 : 0). // unsigned',
  SOP2Op.S_LSHL2_ADD_U32: 'D.u = (S0.u << N) + S1.u; // N is the shift value in the opcode\nSCC = (((S0.u << N) + S1.u) >= 0x100000000ULL ? 1 : 0). // unsigned',
  SOP2Op.S_LSHL3_ADD_U32: 'D.u = (S0.u << N) + S1.u; // N is the shift value in the opcode\nSCC = (((S0.u << N) + S1.u) >= 0x100000000ULL ? 1 : 0). // unsigned',
  SOP2Op.S_LSHL4_ADD_U32: 'D.u = (S0.u << N) + S1.u; // N is the shift value in the opcode\nSCC = (((S0.u << N) + S1.u) >= 0x100000000ULL ? 1 : 0). // unsigned',
  SOP2Op.S_PACK_LL_B32_B16: 'D.u[31:0] = { S1.u[15:0], S0.u[15:0] }.',
  SOP2Op.S_PACK_LH_B32_B16: 'D.u[31:0] = { S1.u[31:16], S0.u[15:0] }.',
  SOP2Op.S_PACK_HH_B32_B16: 'D.u[31:0] = { S1.u[31:16], S0.u[31:16] }.',
  SOP2Op.S_MUL_HI_U32: 'D.u = (S0.u * S1.u) >> 32.',
  SOP2Op.S_MUL_HI_I32: 'D.i = (S0.i * S1.i) >> 32.',
  SOPCOp.S_CMP_EQ_I32: 'SCC = (S0 == S1).',
  SOPCOp.S_CMP_LG_I32: 'SCC = (S0 != S1).\nSCC = (S0.i > S1.i).',
  SOPCOp.S_CMP_GT_I32: 'SCC = (S0.i >= S1.i).',
  SOPCOp.S_CMP_GE_I32: 'SCC = (S0.i < S1.i).',
  SOPCOp.S_CMP_LT_I32: 'SCC = (S0.i <= S1.i).',
  SOPCOp.S_CMP_EQ_U32: 'SCC = (S0 == S1).',
  SOPCOp.S_CMP_LG_U32: 'SCC = (S0 != S1).\nSCC = (S0.u > S1.u).',
  SOPCOp.S_CMP_GT_U32: 'SCC = (S0.u >= S1.u).',
  SOPCOp.S_CMP_GE_U32: 'SCC = (S0.u < S1.u).',
  SOPCOp.S_CMP_LT_U32: 'SCC = (S0.u <= S1.u).',
  SOPCOp.S_BITCMP0_B32: 'SCC = (S0.u[S1.u[4:0]] == 0).\nSCC = (S0.u[S1.u[4:0]] == 1).',
  SOPCOp.S_BITCMP1_B32: 'SCC = (S0.u64[S1.u[5:0]] == 0).',
  SOPCOp.S_BITCMP0_B64: 'SCC = (S0.u64[S1.u[5:0]] == 1).',
  SOPCOp.S_BITCMP1_B64: 'SCC = (S0.i64 == S1.i64).',
  SOPCOp.S_CMP_LG_U64: 'SCC = (S0.i64 != S1.i64).',
  SOPKOp.S_MOVK_I32: 'D.i32 = signext(SIMM16[15:0]).',
  SOPKOp.S_CMOVK_I32: 'if(SCC)\nD.i32 = signext(SIMM16[15:0]);\nendif.\nSCC = (S0.i32 == signext(SIMM16[15:0])).',
  SOPKOp.S_CMPK_LG_I32: 'SCC = (S0.i32 != signext(SIMM16[15:0])).\nSCC = (S0.i32 > signext(SIMM16[15:0])).',
  SOPKOp.S_CMPK_GT_I32: 'SCC = (S0.i32 >= signext(SIMM16[15:0])).',
  SOPKOp.S_CMPK_GE_I32: 'SCC = (S0.i32 < signext(SIMM16[15:0])).',
  SOPKOp.S_CMPK_LT_I32: 'SCC = (S0.i32 <= signext(SIMM16[15:0])).',
  SOPKOp.S_CMPK_EQ_U32: 'SCC = (S0.u32 == SIMM16[15:0]).\nSCC = (S0.u32 != SIMM16[15:0]).',
  SOPKOp.S_CMPK_GT_U32: 'SCC = (S0.u32 > SIMM16[15:0]).\nSCC = (S0.u32 >= SIMM16[15:0]).',
  SOPKOp.S_CMPK_GE_U32: 'SCC = (S0.u32 < SIMM16[15:0]).',
  SOPKOp.S_CMPK_LT_U32: 'SCC = (S0.u32 <= SIMM16[15:0]).',
  SOPKOp.S_ADDK_I32: 'int32 tmp = D.i32; // save value so we can check sign bits for\nD.i32 = D.i32 + signext(SIMM16[15:0]);\nSCC = (tmp[31] == SIMM16[15] && tmp[31] != D.i32[31]). // signed',
  SOPKOp.S_MULK_I32: 'D.i32 = D.i32 * signext(SIMM16[15:0]).',
  SOPKOp.S_GETREG_B32: 'uint32 offset = SIMM16[10:6];\nuint32 size = SIMM16[15:11];\nuint32 id = SIMM16[5:0];\nD.u32 = hardware_reg[id][offset+size-1:offset].',
  SOPKOp.S_SETREG_B32: 'hardware-reg = S0.u.',
  SOPKOp.S_SETREG_IMM32_B32: 'hardware-reg = LITERAL.',
  SOPKOp.S_CALL_B64: 'D.u64 = PC + 4;\nPC = PC + signext(SIMM16 * 4) + 4.',
  SOPKOp.S_WAITCNT_VSCNT: 'vscnt <= S0.u[5:0] + S1.u[5:0].\n// Comparison is 6 bits, no clamping is applied for add overflow',
  SOPKOp.S_WAITCNT_VMCNT: 'vmcnt <= S0.u[5:0] + S1.u[5:0].\n// Comparison is 6 bits, no clamping is applied for add overflow',
  SOPKOp.S_WAITCNT_EXPCNT: 'expcnt <= S0.u[2:0] + S1.u[2:0].\n// Comparison is 3 bits, no clamping is applied for add overflow',
  SOPKOp.S_WAITCNT_LGKMCNT: 'lgkmcnt <= S0.u[5:0] + S1.u[5:0].\n// Comparison is 6 bits, no clamping is applied for add overflow',
  SOPKOp.S_SUBVECTOR_LOOP_BEGIN: 'if(EXEC[63:0] == 0)\n// no passes, skip entire loop\njump LABEL\nelif(EXEC_LO == 0)\n// execute high pass only\nD0 = EXEC_LO\nelse\n// execute low pass first, either running both passes or\nD0 = EXEC_HI\nEXEC_HI = 0\nendif.',
  SOPKOp.S_SUBVECTOR_LOOP_END: 'if(EXEC_HI != 0)\nEXEC_LO = D0\nelif(S0 == 0)\n// done: executed low pass and skip high pass\nnop\nelse\n// execute second pass of two-pass mode\nEXEC_HI = D0\nD0 = EXEC_LO\nEXEC_LO = 0\njump LABEL\nendif.',
  SOPPOp.S_BRANCH: 'PC = PC + signext(SIMM16 * 4) + 4. // short jump.',
  SOPPOp.S_CBRANCH_SCC0: 'if(SCC == 0) then\nPC = PC + signext(SIMM16 * 4) + 4;\nendif.',
  SOPPOp.S_CBRANCH_SCC1: 'if(SCC == 1) then\nPC = PC + signext(SIMM16 * 4) + 4;\nendif.',
  SOPPOp.S_CBRANCH_VCCZ: 'if(VCC == 0) then\nPC = PC + signext(SIMM16 * 4) + 4;\nendif.',
  SOPPOp.S_CBRANCH_VCCNZ: 'if(VCC != 0) then\nPC = PC + signext(SIMM16 * 4) + 4;\nendif.',
  SOPPOp.S_CBRANCH_EXECZ: 'if(EXEC == 0) then\nPC = PC + signext(SIMM16 * 4) + 4;\nendif.',
  SOPPOp.S_CBRANCH_EXECNZ: 'if(EXEC != 0) then\nPC = PC + signext(SIMM16 * 4) + 4;\nendif.',
  SOPPOp.S_WAITCNT: 'vmcnt <= {SIMM16[15:14], SIMM16[3:0]}\nexpcnt <= SIMM16[6:4]\nlgkmcnt <= SIMM16[13:8]',
  SOPPOp.S_TRAP: "TrapID = SIMM16[7:0];\nWait for all instructions to complete;\n{TTMP1, TTMP0} = {1'h0, PCRewind[5:0], HT[0], TrapID[7:0],\nPC = TBA; // trap base address\nPRIV = 1.",
  SOPPOp.S_CBRANCH_CDBGSYS: 'if(conditional_debug_system != 0) then\nPC = PC + signext(SIMM16 * 4) + 4;\nendif.',
  SOPPOp.S_CBRANCH_CDBGUSER: 'if(conditional_debug_user != 0) then\nPC = PC + signext(SIMM16 * 4) + 4;\nendif.',
  SOPPOp.S_CBRANCH_CDBGSYS_OR_USER: 'if(conditional_debug_system || conditional_debug_user) then\nPC = PC + signext(SIMM16 * 4) + 4;\nendif.',
  SOPPOp.S_CBRANCH_CDBGSYS_AND_USER: 'if(conditional_debug_system && conditional_debug_user) then\nPC = PC + signext(SIMM16 * 4) + 4;\nendif.',
  SOPPOp.S_INST_PREFETCH: '0: reserved\n1: SQ_PREFETCH_1_LINE -- prefetch 1 line\n2: SQ_PREFETCH_2_LINES -- prefetch 2 lines\n3: SQ_PREFETCH_3_LINES -- prefetch 3 lines',
  SOPPOp.S_CLAUSE: 'Texture, Buffer, Global, Scratch (clause may not mix atomics,\nLDS\nSMEM\nVALU\nSALU\nExport\nBranch\nMessage\nGDS',
  SOPPOp.S_WAITCNT_DEPCTR: 'va_vdst <= SIMM16[15:12] || SIMM16[15:12] == 0xf\nva_sdst <= SIMM16[11:9] || SIMM16[11:9] == 0x7\nva_ssrc == 0 || SIMM16[8] == 1\nhold_cnt == 0 || SIMM16[7] == 1\nvm_vsrc <= SIMM16[4:2] || SIMM16[4:2] == 0x7\nva_vcc == 0 || SIMM16[1] == 1\nsa_sdst == 0 || SIMM16[0] == 1',
  VINTRPOp.V_INTERP_P1_F32: 'D.f32 = P10[S1.u32].f32 * S0.f32 + P0[S1.u3].f32.',
  VINTRPOp.V_INTERP_P2_F32: 'D.f = P20[S1.u] * S0.f + D.f.',
  VINTRPOp.V_INTERP_MOV_F32: 'D.f = {P10,P20,P0}[S1.u].',
  VOP1Op.V_MOV_B32_E32: 'D.u = S0.u.',
  VOP1Op.V_CVT_I32_F64_E32: 'D.i = (int)S0.d.',
  VOP1Op.V_CVT_F64_I32_E32: 'D.d = (double)S0.i.',
  VOP1Op.V_CVT_F32_I32_E32: 'D.f = (float)S0.i.',
  VOP1Op.V_CVT_F32_U32_E32: 'D.f = (float)S0.u.',
  VOP1Op.V_CVT_U32_F32_E32: 'D.u = (unsigned)S0.f.',
  VOP1Op.V_CVT_I32_F32_E32: 'D.i = (int)S0.f.',
  VOP1Op.V_CVT_F16_F32_E32: 'D.f16 = flt32_to_flt16(S0.f).',
  VOP1Op.V_CVT_F32_F16_E32: 'D.f = flt16_to_flt32(S0.f16).',
  VOP1Op.V_CVT_RPI_I32_F32_E32: 'D.i = (int)floor(S0.f + 0.5).',
  VOP1Op.V_CVT_FLR_I32_F32_E32: 'D.i = (int)floor(S0.f).',
  VOP1Op.V_CVT_F32_F64_E32: 'D.f = (float)S0.d.',
  VOP1Op.V_CVT_F64_F32_E32: 'D.d = (double)S0.f.',
  VOP1Op.V_CVT_F32_UBYTE0_E32: 'D.f = (float)(S0.u[7:0]).',
  VOP1Op.V_CVT_F32_UBYTE1_E32: 'D.f = (float)(S0.u[15:8]).',
  VOP1Op.V_CVT_F32_UBYTE2_E32: 'D.f = (float)(S0.u[23:16]).',
  VOP1Op.V_CVT_F32_UBYTE3_E32: 'D.f = (float)(S0.u[31:24]).',
  VOP1Op.V_CVT_U32_F64_E32: 'D.u = (unsigned)S0.d.',
  VOP1Op.V_CVT_F64_U32_E32: 'D.d = (double)S0.u.',
  VOP1Op.V_TRUNC_F64_E32: 'D.d = trunc(S0.d).',
  VOP1Op.V_CEIL_F64_E32: 'D.d = trunc(S0.d);\nif(S0.d > 0.0 && S0.d != D.d) then\nD.d += 1.0;\nendif.',
  VOP1Op.V_RNDNE_F64_E32: 'D.d = floor(S0.d + 0.5);\nif(floor(S0.d) is even && fract(S0.d) == 0.5) then\nD.d -= 1.0;\nendif.',
  VOP1Op.V_FLOOR_F64_E32: 'D.d = trunc(S0.d);\nif(S0.d < 0.0 && S0.d != D.d) then\nD.d += -1.0;\nendif.',
  VOP1Op.V_FRACT_F32_E32: 'D.f = S0.f + -floor(S0.f).',
  VOP1Op.V_TRUNC_F32_E32: 'D.f = trunc(S0.f).',
  VOP1Op.V_CEIL_F32_E32: 'D.f = trunc(S0.f);\nif(S0.f > 0.0 && S0.f != D.f) then\nD.f += 1.0;\nendif.',
  VOP1Op.V_RNDNE_F32_E32: 'D.f = floor(S0.f + 0.5);\nif(floor(S0.f) is even && fract(S0.f) == 0.5) then\nD.f -= 1.0;\nendif.',
  VOP1Op.V_FLOOR_F32_E32: 'D.f = trunc(S0.f);\nif(S0.f < 0.0 && S0.f != D.f) then\nD.f += -1.0;\nendif.',
  VOP1Op.V_EXP_F32_E32: 'D.f = pow(2.0, S0.f).',
  VOP1Op.V_LOG_F32_E32: 'D.f = log2(S0.f).',
  VOP1Op.V_RCP_F32_E32: 'D.f = 1.0 / S0.f.',
  VOP1Op.V_RCP_IFLAG_F32_E32: 'D.f = 1.0 / S0.f.\nCVT_F32_U32\nRCP_IFLAG_F32\nMUL_F32 (2**32 - 1)\nCVT_U32_F32\nCVT_F32_I32\nRCP_IFLAG_F32\nMUL_F32 (2**31 - 1)\nCVT_I32_F32',
  VOP1Op.V_RSQ_F32_E32: 'D.f = 1.0 / sqrt(S0.f).',
  VOP1Op.V_RCP_F64_E32: 'D.d = 1.0 / S0.d.',
  VOP1Op.V_RSQ_F64_E32: 'D.f16 = 1.0 / sqrt(S0.f16).',
  VOP1Op.V_SQRT_F32_E32: 'D.f = sqrt(S0.f).',
  VOP1Op.V_SQRT_F64_E32: 'D.d = sqrt(S0.d).',
  VOP1Op.V_SIN_F32_E32: 'D.f = sin(S0.f * 2 * PI).',
  VOP1Op.V_COS_F32_E32: 'D.f = cos(S0.f * 2 * PI).',
  VOP1Op.V_NOT_B32_E32: 'D.u = ~S0.u.',
  VOP1Op.V_BFREV_B32_E32: 'D.u[31:0] = S0.u[0:31].',
  VOP1Op.V_FFBH_U32_E32: 'D.i = -1; // Set if no ones are found\nfor i in 0 ... 31 do\n// Note: search is from the MSB\nif S0.u[31 - i] == 1 then\nD.i = i;\nbreak for;\nendif;\nendfor.',
  VOP1Op.V_FFBL_B32_E32: 'D.i = -1; // Set if no ones are found\nfor i in 0 ... 31 do // Search from LSB\nif S0.u[i] == 1 then\nD.i = i;\nbreak for;\nendif;\nendfor.',
  VOP1Op.V_FFBH_I32_E32: 'D.i = -1; // Set if all bits are the same\nfor i in 1 ... 31 do\n// Note: search is from the MSB\nif S0.i[31 - i] != S0.i[31] then\nD.i = i;\nbreak for;\nendif;\nendfor.',
  VOP1Op.V_FREXP_EXP_I32_F64_E32: 'if(S0.f64 == +-INF || S0.f64 == NAN)\nD.i32 = 0;\nelse\nD.i32 = S0.f64.exp - 1023 + 1;\nendif.',
  VOP1Op.V_FREXP_MANT_F64_E32: 'if(S0.d == +-INF || S0.d == NAN) then\nD.d = S0.d;\nelse\nD.d = Mantissa(S0.d);\nendif.',
  VOP1Op.V_FRACT_F64_E32: 'D.d = S0.d + -floor(S0.d).',
  VOP1Op.V_FREXP_EXP_I32_F32_E32: 'if(S0.f == +-INF || S0.f == NAN) then\nD.i = 0;\nelse\nD.i = TwosComplement(Exponent(S0.f) - 127 + 1);\nendif.',
  VOP1Op.V_FREXP_MANT_F32_E32: 'if(S0.f == +-INF || S0.f == NAN) then\nD.f = S0.f;\nelse\nD.f = Mantissa(S0.f);\nendif.',
  VOP1Op.V_MOVRELD_B32_E32: 'addr = VGPR address appearing in instruction DST field;\naddr += M0.u[31:0];\nVGPR[addr].u = S0.u.',
  VOP1Op.V_MOVRELS_B32_E32: 'addr = VGPR address appearing in instruction SRC0 field;\naddr += M0.u[31:0];\nD.u = VGPR[addr].u.',
  VOP1Op.V_MOVRELSD_B32_E32: 'addr_src = VGPR address appearing in instruction SRC0 field;\naddr_src += M0.u[31:0];\naddr_dst = VGPR address appearing in instruction DST field;\naddr_dst += M0.u[31:0];\nVGPR[addr_dst].u = VGPR[addr_src].u.',
  VOP1Op.V_MOVRELSD_2_B32_E32: 'addr_src = VGPR address appearing in instruction SRC0 field;\naddr_src += M0.u[9:0];\naddr_dst = VGPR address appearing in instruction DST field;\naddr_dst += M0.u[25:16];\nVGPR[addr_dst].u = VGPR[addr_src].u.',
  VOP1Op.V_CVT_F16_U16_E32: 'D.f16 = uint16_to_flt16(S.u16).',
  VOP1Op.V_CVT_F16_I16_E32: 'D.f16 = int16_to_flt16(S.i16).',
  VOP1Op.V_CVT_U16_F16_E32: 'D.u16 = flt16_to_uint16(S.f16).',
  VOP1Op.V_CVT_I16_F16_E32: 'D.i16 = flt16_to_int16(S.f16).',
  VOP1Op.V_RCP_F16_E32: 'D.f16 = 1.0 / S0.f16.',
  VOP1Op.V_SQRT_F16_E32: 'D.f16 = sqrt(S0.f16).',
  VOP1Op.V_RSQ_F16_E32: 'D.f16 = 1.0 / sqrt(S0.f16).',
  VOP1Op.V_LOG_F16_E32: 'D.f16 = log2(S0.f).',
  VOP1Op.V_EXP_F16_E32: 'D.f16 = pow(2.0, S0.f16).',
  VOP1Op.V_FREXP_MANT_F16_E32: 'if(S0.f16 == +-INF || S0.f16 == NAN) then\nD.f16 = S0.f16;\nelse\nD.f16 = Mantissa(S0.f16);\nendif.',
  VOP1Op.V_FREXP_EXP_I16_F16_E32: 'if(S0.f16 == +-INF || S0.f16 == NAN) then\nD.i = 0;\nelse\nD.i = TwosComplement(Exponent(S0.f16) - 15 + 1);\nendif.',
  VOP1Op.V_FLOOR_F16_E32: 'D.f16 = trunc(S0.f16);\nif(S0.f16 < 0.0f && S0.f16 != D.f16) then\nD.f16 -= 1.0;\nendif.',
  VOP1Op.V_CEIL_F16_E32: 'D.f16 = trunc(S0.f16);\nif(S0.f16 > 0.0f && S0.f16 != D.f16) then\nD.f16 += 1.0;\nendif.',
  VOP1Op.V_TRUNC_F16_E32: 'D.f16 = trunc(S0.f16).',
  VOP1Op.V_RNDNE_F16_E32: 'D.f16 = floor(S0.f16 + 0.5);\nif(floor(S0.f16) is even && fract(S0.f16) == 0.5) then\nD.f16 -= 1.0;\nendif.',
  VOP1Op.V_FRACT_F16_E32: 'D.f16 = S0.f16 + -floor(S0.f16).',
  VOP1Op.V_SIN_F16_E32: 'D.f16 = sin(S0.f16 * 2 * PI).',
  VOP1Op.V_COS_F16_E32: 'D.f16 = cos(S0.f16 * 2 * PI).',
  VOP1Op.V_SAT_PK_U8_I16_E32: "D.u32 = {16'b0, sat8(S.u[31:16]), sat8(S.u[15:0])}.",
  VOP1Op.V_CVT_NORM_I16_F16_E32: 'D.i16 = flt16_to_snorm16(S.f16).',
  VOP1Op.V_CVT_NORM_U16_F16_E32: 'D.u16 = flt16_to_unorm16(S.f16).',
  VOP1Op.V_SWAP_B32_E32: 'tmp = D.u;\nD.u = S0.u;\nS0.u = tmp.',
  VOP1Op.V_SWAPREL_B32_E32: 'addr_src = VGPR address appearing in instruction SRC0 field;\naddr_src += M0.u[9:0];\naddr_dst = VGPR address appearing in instruction DST field;\naddr_dst += M0.u[25:16];\ntmp = VGPR[addr_dst];\nVGPR[addr_dst] = VGPR[addr_src];\nVGPR[addr_src] = tmp.',
  VOP2Op.V_CNDMASK_B32_E32: 'D.u32 = VCC ? S1.u32 : S0.u32.',
  VOP2Op.V_DOT2C_F32_F16_E32: 'D.f32 =\nS0.f16[0] * S1.f16[0] +\nS0.f16[1] * S1.f16[1] + D.f32.',
  VOP2Op.V_ADD_F32_E32: 'D.f32 = S0.f32 + S1.f32.',
  VOP2Op.V_SUB_F32_E32: 'D.f32 = S0.f32 - S1.f32.',
  VOP2Op.V_SUBREV_F32_E32: 'D.f32 = S1.f32 - S0.f32.',
  VOP2Op.V_FMAC_LEGACY_F32_E32: 'D.f32 = S0.f32 * S1.f32 + S2.f32. // DX9 rules, 0.0 * x = 0.0',
  VOP2Op.V_MUL_LEGACY_F32_E32: 'D.f32 = S0.f32 * S1.f32. // DX9 rules, 0.0*x = 0.0',
  VOP2Op.V_MUL_F32_E32: 'D.f32 = S0.f32 * S1.f32.',
  VOP2Op.V_MUL_I32_I24_E32: 'D.i32 = S0.i24 * S1.i24.',
  VOP2Op.V_MUL_HI_I32_I24_E32: 'D.i32 = (S0.i24 * S1.i24)>>32;',
  VOP2Op.V_MUL_U32_U24_E32: 'D.u32 = S0.u24 * S1.u24.',
  VOP2Op.V_MUL_HI_U32_U24_E32: 'D.u32 = (S0.u24 * S1.u24)>>32.',
  VOP2Op.V_DOT4C_I32_I8_E32: 'D.i32 =\nS0.i8[0] * S1.i8[0] +\nS0.i8[1] * S1.i8[1] +\nS0.i8[2] * S1.i8[2] +\nS0.i8[3] * S1.i8[3] + D.i32.',
  VOP2Op.V_MIN_F32_E32: "D.f32 = min(S0.f32,S1.f32);\nif (IEEE_MODE && S0.f == sNaN)\nD.f = Quiet(S0.f);\nelse if (IEEE_MODE && S1.f == sNaN)\nD.f = Quiet(S1.f);\nelse if (S0.f == NaN)\nD.f = S1.f;\nelse if (S1.f == NaN)\nD.f = S0.f;\nelse if (S0.f == +0.0 && S1.f == -0.0)\nD.f = S1.f;\nelse if (S0.f == -0.0 && S1.f == +0.0)\nD.f = S0.f;\nelse\n// Note: there's no IEEE special case here like there is for\nD.f = (S0.f < S1.f ? S0.f : S1.f);\nendif.",
  VOP2Op.V_MAX_F32_E32: 'D.f32 = max(S0.f32,S1.f32);\nif (IEEE_MODE && S0.f == sNaN)\nD.f = Quiet(S0.f);\nelse if (IEEE_MODE && S1.f == sNaN)\nD.f = Quiet(S1.f);\nelse if (S0.f == NaN)\nD.f = S1.f;\nelse if (S1.f == NaN)\nD.f = S0.f;\nelse if (S0.f == +0.0 && S1.f == -0.0)\nD.f = S0.f;\nelse if (S0.f == -0.0 && S1.f == +0.0)\nD.f = S1.f;\nelse if (IEEE_MODE)\nD.f = (S0.f >= S1.f ? S0.f : S1.f);\nelse\nD.f = (S0.f > S1.f ? S0.f : S1.f);\nendif.',
  VOP2Op.V_MAX_I32_E32: 'D.i32 = (S0.i32 >= S1.i32 ? S0.i32 : S1.i32).',
  VOP2Op.V_MIN_U32_E32: 'D.u32 = (S0.u32 < S1.u32 ? S0.u32 : S1.u32).',
  VOP2Op.V_MAX_U32_E32: 'D.u32 = (S0.u32 >= S1.u32 ? S0.u32 : S1.u32).',
  VOP2Op.V_LSHRREV_B32_E32: 'D.u32 = S1.u32 >> S0[4:0].',
  VOP2Op.V_ASHRREV_I32_E32: 'D.i32 = S1.i32 >> S0[4:0].',
  VOP2Op.V_LSHLREV_B32_E32: 'D.u32 = S1.u32 << S0[4:0].',
  VOP2Op.V_AND_B32_E32: 'D.u32 = S0.u32 & S1.u32.',
  VOP2Op.V_OR_B32_E32: 'D.u32 = S0.u32 | S1.u32.',
  VOP2Op.V_XOR_B32_E32: 'D.u32 = S0.u32 ^ S1.u32.',
  VOP2Op.V_XNOR_B32_E32: 'D.u32 = ~(S0.u32 ^ S1.u32).',
  VOP2Op.V_ADD_NC_U32_E32: 'D.u32 = S0.u32 + S1.u32.',
  VOP2Op.V_SUB_NC_U32_E32: 'D.u32 = S0.u32 - S1.u32.',
  VOP2Op.V_SUBREV_NC_U32_E32: 'D.u32 = S1.u32 - S0.u32.',
  VOP2Op.V_ADD_CO_CI_U32_E32: 'D.u32 = S0.u32 + S1.u32 + VCC;\nVCC = S0.u32 + S1.u32 + VCC >= 0x100000000ULL ? 1 : 0.',
  VOP2Op.V_SUB_CO_CI_U32_E32: 'D.u32 = S0.u32 - S1.u32 - VCC;\nVCC = S1.u32 + VCC > S0.u32 ? 1 : 0.',
  VOP2Op.V_SUBREV_CO_CI_U32_E32: 'D.u32 = S1.u32 - S0.u32 - VCC;\nVCC = S1.u32 + VCC > S0.u ? 1 : 0.',
  VOP2Op.V_FMAC_F32_E32: 'D.f32 = S0.f32 * S1.f32 + D.f32. // Fused operation',
  VOP2Op.V_FMAMK_F32_E32: 'D.f32 = S0.f32 * K.f32 + S1.f32. // K is a 32-bit literal constant.',
  VOP2Op.V_FMAAK_F32_E32: 'D.f32 = S0.f32 * S1.f32 + K.f32. // K is a 32-bit literal constant.',
  VOP2Op.V_CVT_PKRTZ_F16_F32_E32: 'D.f16_lo = f32_to_f16(S0.f32);\nD.f16_hi = f32_to_f16(S1.f32).\n// Round-toward-zero regardless of current round mode setting in',
  VOP2Op.V_ADD_F16_E32: 'D.f16_lo = S0.f16_lo + S1.f16_lo.',
  VOP2Op.V_SUB_F16_E32: 'D.f16_lo = S0.f16_lo - S1.f16_lo.',
  VOP2Op.V_SUBREV_F16_E32: 'D.f16_lo = S1.f16_lo - S0.f16_lo.',
  VOP2Op.V_MUL_F16_E32: 'D.f16_lo = S0.f16_lo * S1.f16_lo.',
  VOP2Op.V_FMAC_F16_E32: 'D.f16_lo = S0.f16_lo * S1.f16_lo + D.f16_lo.',
  VOP2Op.V_FMAMK_F16_E32: 'D.f16_lo = S0.f16_lo * K.f16_lo + S1.f16_lo.\n// K is a 32-bit literal constant stored in the following literal',
  VOP2Op.V_FMAAK_F16_E32: 'D.f16_lo = S0.f16_lo * S1.f16_lo + K.f16_lo.\n// K is a 32-bit literal constant stored in the following literal',
  VOP2Op.V_MAX_F16_E32: 'D.f16 = max(S0.f16,S1.f16);\nif (IEEE_MODE && S0.f16 == sNaN)\nD.f16 = Quiet(S0.f16);\nelse if (IEEE_MODE && S1.f16 == sNaN)\nD.f16 = Quiet(S1.f16);\nelse if (S0.f16 == NaN)\nD.f16 = S1.f16;\nelse if (S1.f16 == NaN)\nD.f16 = S0.f16;\nelse if (S0.f16 == +0.0 && S1.f16 == -0.0)\nD.f16 = S0.f16;\nelse if (S0.f16 == -0.0 && S1.f16 == +0.0)\nD.f16 = S1.f16;\nelse if (IEEE_MODE)\nD.f16 = (S0.f16 >= S1.f16 ? S0.f16 : S1.f16);\nelse\nD.f16 = (S0.f16 > S1.f16 ? S0.f16 : S1.f16);\nendif.',
  VOP2Op.V_MIN_F16_E32: "D.f16 = min(S0.f16,S1.f16);\nif (IEEE_MODE && S0.f16 == sNaN)\nD.f16 = Quiet(S0.f16);\nelse if (IEEE_MODE && S1.f16 == sNaN)\nD.f16 = Quiet(S1.f16);\nelse if (S0.f16 == NaN)\nD.f16 = S1.f16;\nelse if (S1.f16 == NaN)\nD.f16 = S0.f16;\nelse if (S0.f16 == +0.0 && S1.f16 == -0.0)\nD.f16 = S1.f16;\nelse if (S0.f16 == -0.0 && S1.f16 == +0.0)\nD.f16 = S0.f16;\nelse\n// Note: there's no IEEE special case here like there is for\nD.f16 = (S0.f16 < S1.f16 ? S0.f16 : S1.f16);\nendif.",
  VOP2Op.V_LDEXP_F16_E32: 'D.f16 = S0.f16 * (2 ** S1.i16).',
  VOP2Op.V_PK_FMAC_F16_E32: 'Multiply packed FP16 values and accumulate with destination.\nD.f16_lo = S0.f16_lo * S1.f16_lo + D.f16_lo;\nD.f16_hi = S0.f16_hi * S1.f16_hi + D.f16_hi.',
  VOP3Op.V_CMP_F_F32_E64: 'D[threadId] = 0.\n// D = VCC in VOPC encoding.\nD[threadId] = (S0 < S1).',
  VOP3Op.V_CMP_LT_F32_E64: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 == S1).',
  VOP3Op.V_CMP_EQ_F32_E64: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 <= S1).',
  VOP3Op.V_CMP_LE_F32_E64: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 > S1).',
  VOP3Op.V_CMP_GT_F32_E64: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 <> S1).',
  VOP3Op.V_CMP_LG_F32_E64: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 >= S1).',
  VOP3Op.V_CMP_GE_F32_E64: '// D = VCC in VOPC encoding.\nD[threadId] = (!isNan(S0) && !isNan(S1)).',
  VOP3Op.V_CMP_O_F32_E64: '// D = VCC in VOPC encoding.\nD[threadId] = (isNan(S0)  ||  isNan(S1)).',
  VOP3Op.V_CMP_U_F32_E64: '// D = VCC in VOPC encoding.',
  VOP3Op.V_CMP_NGE_F32_E64: 'D[threadId] = !(S0 >= S1)\n// With NAN inputs this is not the same operation as <.\n// D = VCC in VOPC encoding.',
  VOP3Op.V_CMP_NLG_F32_E64: 'D[threadId] = !(S0 <> S1)\n// With NAN inputs this is not the same operation as ==.\n// D = VCC in VOPC encoding.\nD[threadId] = !(S0 > S1)',
  VOP3Op.V_CMP_NGT_F32_E64: '// With NAN inputs this is not the same operation as <=.\n// D = VCC in VOPC encoding.\nD[threadId] = !(S0 <= S1)',
  VOP3Op.V_CMP_NLE_F32_E64: '// With NAN inputs this is not the same operation as >.\n// D = VCC in VOPC encoding.\nD[threadId] = !(S0 == S1)',
  VOP3Op.V_CMP_NEQ_F32_E64: '// With NAN inputs this is not the same operation as !=.\n// D = VCC in VOPC encoding.',
  VOP3Op.V_CMP_NLT_F32_E64: 'D[threadId] = !(S0 < S1)\n// With NAN inputs this is not the same operation as >=.\n// D = VCC in VOPC encoding.\nD[threadId] = 1.',
  VOP3Op.V_CMP_TRU_F32_E64: '// D = VCC in VOPC encoding.\nEXEC[threadId] = 0.',
  VOP3Op.V_CMPX_F_F32_E64: 'EXEC[threadId] = (S0 < S1).',
  VOP3Op.V_CMPX_LT_F32_E64: 'EXEC[threadId] = (S0 == S1).',
  VOP3Op.V_CMPX_EQ_F32_E64: 'EXEC[threadId] = (S0 <= S1).',
  VOP3Op.V_CMPX_GT_F32_E64: 'EXEC[threadId] = (S0 > S1).\nEXEC[threadId] = (S0 <> S1).',
  VOP3Op.V_CMPX_GE_F32_E64: 'EXEC[threadId] = (S0 >= S1).\nEXEC[threadId] = (!isNan(S0) && !isNan(S1)).',
  VOP3Op.V_CMPX_O_F32_E64: 'EXEC[threadId] = (isNan(S0)  ||  isNan(S1)).',
  VOP3Op.V_CMPX_U_F32_E64: 'EXEC[threadId] = !(S0 >= S1)',
  VOP3Op.V_CMPX_NGE_F32_E64: '// With NAN inputs this is not the same operation as <.\nEXEC[threadId] = !(S0 <> S1)',
  VOP3Op.V_CMPX_NLG_F32_E64: '// With NAN inputs this is not the same operation as ==.\nEXEC[threadId] = !(S0 > S1)',
  VOP3Op.V_CMPX_NGT_F32_E64: '// With NAN inputs this is not the same operation as <=.\nEXEC[threadId] = !(S0 <= S1)',
  VOP3Op.V_CMPX_NLE_F32_E64: '// With NAN inputs this is not the same operation as >.\nEXEC[threadId] = !(S0 == S1)',
  VOP3Op.V_CMPX_NEQ_F32_E64: '// With NAN inputs this is not the same operation as !=.\nEXEC[threadId] = !(S0 < S1)',
  VOP3Op.V_CMPX_NLT_F32_E64: '// With NAN inputs this is not the same operation as >=.\nEXEC[threadId] = 1.',
  VOP3Op.V_CMPX_TRU_F32_E64: 'D[threadId] = 0.',
  VOP3Op.V_CMP_F_F64_E64: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 < S1).',
  VOP3Op.V_CMP_LT_F64_E64: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 == S1).',
  VOP3Op.V_CMP_EQ_F64_E64: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 <= S1).',
  VOP3Op.V_CMP_LE_F64_E64: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 > S1).',
  VOP3Op.V_CMP_GT_F64_E64: '// D = VCC in VOPC encoding.',
  VOP3Op.V_CMP_LG_F64_E64: 'D[threadId] = (S0 <> S1).\n// D = VCC in VOPC encoding.',
  VOP3Op.V_CMP_GE_F64_E64: 'D[threadId] = (S0 >= S1).\n// D = VCC in VOPC encoding.\nD[threadId] = (!isNan(S0) && !isNan(S1)).',
  VOP3Op.V_CMP_O_F64_E64: '// D = VCC in VOPC encoding.\nD[threadId] = (isNan(S0)  ||  isNan(S1)).',
  VOP3Op.V_CMP_U_F64_E64: '// D = VCC in VOPC encoding.\nD[threadId] = !(S0 >= S1)',
  VOP3Op.V_CMP_NGE_F64_E64: '// With NAN inputs this is not the same operation as <.\n// D = VCC in VOPC encoding.\nD[threadId] = !(S0 <> S1)',
  VOP3Op.V_CMP_NLG_F64_E64: '// With NAN inputs this is not the same operation as ==.\n// D = VCC in VOPC encoding.',
  VOP3Op.V_CMP_NGT_F64_E64: 'D[threadId] = !(S0 > S1)\n// With NAN inputs this is not the same operation as <=.\n// D = VCC in VOPC encoding.\nD[threadId] = !(S0 <= S1)',
  VOP3Op.V_CMP_NLE_F64_E64: '// With NAN inputs this is not the same operation as >.\n// D = VCC in VOPC encoding.\nD[threadId] = !(S0 == S1)',
  VOP3Op.V_CMP_NEQ_F64_E64: '// With NAN inputs this is not the same operation as !=.\n// D = VCC in VOPC encoding.\nD[threadId] = !(S0 < S1)',
  VOP3Op.V_CMP_NLT_F64_E64: '// With NAN inputs this is not the same operation as >=.\n// D = VCC in VOPC encoding.',
  VOP3Op.V_CMP_TRU_F64_E64: 'D[threadId] = 1.\n// D = VCC in VOPC encoding.\nEXEC[threadId] = 0.',
  VOP3Op.V_CMPX_F_F64_E64: 'EXEC[threadId] = (S0 < S1).',
  VOP3Op.V_CMPX_EQ_F64_E64: 'EXEC[threadId] = (S0 == S1).\nEXEC[threadId] = (S0 <= S1).',
  VOP3Op.V_CMPX_GT_F64_E64: 'EXEC[threadId] = (S0 > S1).\nEXEC[threadId] = (S0 <> S1).',
  VOP3Op.V_CMPX_LG_F64_E64: 'EXEC[threadId] = (S0 >= S1).',
  VOP3Op.V_CMPX_GE_F64_E64: 'EXEC[threadId] = (!isNan(S0) && !isNan(S1)).',
  VOP3Op.V_CMPX_O_F64_E64: 'EXEC[threadId] = (isNan(S0)  ||  isNan(S1)).',
  VOP3Op.V_CMPX_NGE_F64_E64: 'EXEC[threadId] = !(S0 >= S1)\n// With NAN inputs this is not the same operation as <.\nEXEC[threadId] = !(S0 <> S1)',
  VOP3Op.V_CMPX_NLG_F64_E64: '// With NAN inputs this is not the same operation as ==.\nEXEC[threadId] = !(S0 > S1)',
  VOP3Op.V_CMPX_NGT_F64_E64: '// With NAN inputs this is not the same operation as <=.\nEXEC[threadId] = !(S0 <= S1)',
  VOP3Op.V_CMPX_NLE_F64_E64: '// With NAN inputs this is not the same operation as >.\nEXEC[threadId] = !(S0 == S1)',
  VOP3Op.V_CMPX_NEQ_F64_E64: '// With NAN inputs this is not the same operation as !=.\nEXEC[threadId] = !(S0 < S1)',
  VOP3Op.V_CMPX_NLT_F64_E64: '// With NAN inputs this is not the same operation as >=.',
  VOP3Op.V_CMPX_TRU_F64_E64: 'EXEC[threadId] = 1.\nD[threadId] = 0.',
  VOP3Op.V_CMP_F_I32_E64: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 < S1).',
  VOP3Op.V_CMP_LT_I32_E64: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 == S1).',
  VOP3Op.V_CMP_EQ_I32_E64: '// D = VCC in VOPC encoding.',
  VOP3Op.V_CMP_LE_I32_E64: 'D[threadId] = (S0 <= S1).\n// D = VCC in VOPC encoding.',
  VOP3Op.V_CMP_GT_I32_E64: 'D[threadId] = (S0 > S1).\n// D = VCC in VOPC encoding.\nD[threadId] = (S0 <> S1).',
  VOP3Op.V_CMP_NE_I32_E64: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 >= S1).',
  VOP3Op.V_CMP_GE_I32_E64: '// D = VCC in VOPC encoding.\nD[threadId] = 1.',
  VOP3Op.V_CMP_T_I32_E64: '// D = VCC in VOPC encoding.',
  VOP3Op.V_CMP_CLASS_F32_E64: 'D[threadId] = (S0 < S1).',
  VOP3Op.V_CMP_LT_I16_E64: '// D = VCC in VOPC encoding.',
  VOP3Op.V_CMP_EQ_I16_E64: 'D[threadId] = (S0 == S1).\n// D = VCC in VOPC encoding.\nD[threadId] = (S0 <= S1).',
  VOP3Op.V_CMP_LE_I16_E64: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 > S1).',
  VOP3Op.V_CMP_GT_I16_E64: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 <> S1).',
  VOP3Op.V_CMP_NE_I16_E64: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 >= S1).',
  VOP3Op.V_CMP_GE_I16_E64: '// D = VCC in VOPC encoding.',
  VOP3Op.V_CMP_CLASS_F16_E64: 'EXEC[threadId] = 0.',
  VOP3Op.V_CMPX_F_I32_E64: 'EXEC[threadId] = (S0 < S1).',
  VOP3Op.V_CMPX_LT_I32_E64: 'EXEC[threadId] = (S0 == S1).',
  VOP3Op.V_CMPX_EQ_I32_E64: 'EXEC[threadId] = (S0 <= S1).',
  VOP3Op.V_CMPX_LE_I32_E64: 'EXEC[threadId] = (S0 > S1).',
  VOP3Op.V_CMPX_GT_I32_E64: 'EXEC[threadId] = (S0 <> S1).',
  VOP3Op.V_CMPX_GE_I32_E64: 'EXEC[threadId] = (S0 >= S1).\nEXEC[threadId] = 1.',
  VOP3Op.V_CMPX_CLASS_F32_E64: 'EXEC[threadId] = (S0 < S1).',
  VOP3Op.V_CMPX_EQ_I16_E64: 'EXEC[threadId] = (S0 == S1).\nEXEC[threadId] = (S0 <= S1).',
  VOP3Op.V_CMPX_LE_I16_E64: 'EXEC[threadId] = (S0 > S1).',
  VOP3Op.V_CMPX_GT_I16_E64: 'EXEC[threadId] = (S0 <> S1).',
  VOP3Op.V_CMPX_NE_I16_E64: 'EXEC[threadId] = (S0 >= S1).',
  VOP3Op.V_CMPX_CLASS_F16_E64: 'D[threadId] = 0.',
  VOP3Op.V_CMP_F_I64_E64: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 < S1).',
  VOP3Op.V_CMP_LT_I64_E64: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 == S1).',
  VOP3Op.V_CMP_EQ_I64_E64: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 <= S1).',
  VOP3Op.V_CMP_LE_I64_E64: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 > S1).',
  VOP3Op.V_CMP_GT_I64_E64: '// D = VCC in VOPC encoding.',
  VOP3Op.V_CMP_NE_I64_E64: 'D[threadId] = (S0 <> S1).\n// D = VCC in VOPC encoding.',
  VOP3Op.V_CMP_GE_I64_E64: 'D[threadId] = (S0 >= S1).\n// D = VCC in VOPC encoding.\nD[threadId] = 1.',
  VOP3Op.V_CMP_T_I64_E64: '// D = VCC in VOPC encoding.',
  VOP3Op.V_CMP_LT_U16_E64: 'D[threadId] = (S0 < S1).\n// D = VCC in VOPC encoding.',
  VOP3Op.V_CMP_EQ_U16_E64: 'D[threadId] = (S0 == S1).\n// D = VCC in VOPC encoding.\nD[threadId] = (S0 <= S1).',
  VOP3Op.V_CMP_LE_U16_E64: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 > S1).',
  VOP3Op.V_CMP_GT_U16_E64: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 <> S1).',
  VOP3Op.V_CMP_NE_U16_E64: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 >= S1).',
  VOP3Op.V_CMP_GE_U16_E64: '// D = VCC in VOPC encoding.\nEXEC[threadId] = 0.',
  VOP3Op.V_CMPX_F_I64_E64: 'EXEC[threadId] = (S0 < S1).',
  VOP3Op.V_CMPX_LT_I64_E64: 'EXEC[threadId] = (S0 == S1).',
  VOP3Op.V_CMPX_LE_I64_E64: 'EXEC[threadId] = (S0 <= S1).\nEXEC[threadId] = (S0 > S1).',
  VOP3Op.V_CMPX_GT_I64_E64: 'EXEC[threadId] = (S0 <> S1).',
  VOP3Op.V_CMPX_NE_I64_E64: 'EXEC[threadId] = (S0 >= S1).',
  VOP3Op.V_CMPX_T_I64_E64: 'EXEC[threadId] = 1.',
  VOP3Op.V_CMPX_CLASS_F64_E64: 'EXEC[threadId] = (S0 < S1).',
  VOP3Op.V_CMPX_LT_U16_E64: 'EXEC[threadId] = (S0 == S1).',
  VOP3Op.V_CMPX_LE_U16_E64: 'EXEC[threadId] = (S0 <= S1).\nEXEC[threadId] = (S0 > S1).',
  VOP3Op.V_CMPX_GT_U16_E64: 'EXEC[threadId] = (S0 <> S1).',
  VOP3Op.V_CMPX_NE_U16_E64: 'EXEC[threadId] = (S0 >= S1).',
  VOP3Op.V_CMPX_GE_U16_E64: 'D[threadId] = 0.',
  VOP3Op.V_CMP_F_U32_E64: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 < S1).',
  VOP3Op.V_CMP_LT_U32_E64: '// D = VCC in VOPC encoding.',
  VOP3Op.V_CMP_EQ_U32_E64: 'D[threadId] = (S0 == S1).\n// D = VCC in VOPC encoding.\nD[threadId] = (S0 <= S1).',
  VOP3Op.V_CMP_LE_U32_E64: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 > S1).',
  VOP3Op.V_CMP_GT_U32_E64: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 <> S1).',
  VOP3Op.V_CMP_NE_U32_E64: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 >= S1).',
  VOP3Op.V_CMP_GE_U32_E64: '// D = VCC in VOPC encoding.\nD[threadId] = 1.',
  VOP3Op.V_CMP_T_U32_E64: '// D = VCC in VOPC encoding.',
  VOP3Op.V_CMP_F_F16_E64: 'D[threadId] = 0.\n// D = VCC in VOPC encoding.',
  VOP3Op.V_CMP_LT_F16_E64: 'D[threadId] = (S0 < S1).\n// D = VCC in VOPC encoding.\nD[threadId] = (S0 == S1).',
  VOP3Op.V_CMP_EQ_F16_E64: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 <= S1).',
  VOP3Op.V_CMP_LE_F16_E64: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 > S1).',
  VOP3Op.V_CMP_GT_F16_E64: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 <> S1).',
  VOP3Op.V_CMP_LG_F16_E64: '// D = VCC in VOPC encoding.',
  VOP3Op.V_CMP_GE_F16_E64: 'D[threadId] = (S0 >= S1).\n// D = VCC in VOPC encoding.',
  VOP3Op.V_CMP_O_F16_E64: 'D[threadId] = (!isNan(S0) && !isNan(S1)).\n// D = VCC in VOPC encoding.\nEXEC[threadId] = 0.',
  VOP3Op.V_CMPX_F_U32_E64: 'EXEC[threadId] = (S0 < S1).',
  VOP3Op.V_CMPX_EQ_U32_E64: 'EXEC[threadId] = (S0 == S1).\nEXEC[threadId] = (S0 <= S1).',
  VOP3Op.V_CMPX_GT_U32_E64: 'EXEC[threadId] = (S0 > S1).\nEXEC[threadId] = (S0 <> S1).',
  VOP3Op.V_CMPX_NE_U32_E64: 'EXEC[threadId] = (S0 >= S1).',
  VOP3Op.V_CMPX_GE_U32_E64: 'EXEC[threadId] = 1.',
  VOP3Op.V_CMPX_T_U32_E64: 'EXEC[threadId] = 0.',
  VOP3Op.V_CMPX_LT_F16_E64: 'EXEC[threadId] = (S0 < S1).\nEXEC[threadId] = (S0 == S1).',
  VOP3Op.V_CMPX_EQ_F16_E64: 'EXEC[threadId] = (S0 <= S1).',
  VOP3Op.V_CMPX_LE_F16_E64: 'EXEC[threadId] = (S0 > S1).',
  VOP3Op.V_CMPX_GT_F16_E64: 'EXEC[threadId] = (S0 <> S1).',
  VOP3Op.V_CMPX_GE_F16_E64: 'EXEC[threadId] = (S0 >= S1).\nEXEC[threadId] = (!isNan(S0) && !isNan(S1)).',
  VOP3Op.V_CMP_F_U64_E64: 'D[threadId] = 0.\n// D = VCC in VOPC encoding.',
  VOP3Op.V_CMP_LT_U64_E64: 'D[threadId] = (S0 < S1).\n// D = VCC in VOPC encoding.\nD[threadId] = (S0 == S1).',
  VOP3Op.V_CMP_EQ_U64_E64: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 <= S1).',
  VOP3Op.V_CMP_LE_U64_E64: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 > S1).',
  VOP3Op.V_CMP_GT_U64_E64: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 <> S1).',
  VOP3Op.V_CMP_NE_U64_E64: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 >= S1).',
  VOP3Op.V_CMP_GE_U64_E64: '// D = VCC in VOPC encoding.\nD[threadId] = 1.',
  VOP3Op.V_CMP_T_U64_E64: '// D = VCC in VOPC encoding.\nD[threadId] = (isNan(S0)  ||  isNan(S1)).',
  VOP3Op.V_CMP_U_F16_E64: '// D = VCC in VOPC encoding.\nD[threadId] = !(S0 >= S1)',
  VOP3Op.V_CMP_NGE_F16_E64: '// With NAN inputs this is not the same operation as <.\n// D = VCC in VOPC encoding.',
  VOP3Op.V_CMP_NLG_F16_E64: 'D[threadId] = !(S0 <> S1)\n// With NAN inputs this is not the same operation as ==.\n// D = VCC in VOPC encoding.\nD[threadId] = !(S0 > S1)',
  VOP3Op.V_CMP_NGT_F16_E64: '// With NAN inputs this is not the same operation as <=.\n// D = VCC in VOPC encoding.\nD[threadId] = !(S0 <= S1)',
  VOP3Op.V_CMP_NLE_F16_E64: '// With NAN inputs this is not the same operation as >.\n// D = VCC in VOPC encoding.\nD[threadId] = !(S0 == S1)',
  VOP3Op.V_CMP_NEQ_F16_E64: '// With NAN inputs this is not the same operation as !=.\n// D = VCC in VOPC encoding.',
  VOP3Op.V_CMP_NLT_F16_E64: 'D[threadId] = !(S0 < S1)\n// With NAN inputs this is not the same operation as >=.\n// D = VCC in VOPC encoding.',
  VOP3Op.V_CMP_TRU_F16_E64: 'D[threadId] = 1.\n// D = VCC in VOPC encoding.\nEXEC[threadId] = 0.',
  VOP3Op.V_CMPX_F_U64_E64: 'EXEC[threadId] = (S0 < S1).',
  VOP3Op.V_CMPX_EQ_U64_E64: 'EXEC[threadId] = (S0 == S1).\nEXEC[threadId] = (S0 <= S1).',
  VOP3Op.V_CMPX_GT_U64_E64: 'EXEC[threadId] = (S0 > S1).\nEXEC[threadId] = (S0 <> S1).',
  VOP3Op.V_CMPX_NE_U64_E64: 'EXEC[threadId] = (S0 >= S1).',
  VOP3Op.V_CMPX_GE_U64_E64: 'EXEC[threadId] = 1.',
  VOP3Op.V_CMPX_T_U64_E64: 'EXEC[threadId] = (isNan(S0)  ||  isNan(S1)).',
  VOP3Op.V_CMPX_NGE_F16_E64: 'EXEC[threadId] = !(S0 >= S1)\n// With NAN inputs this is not the same operation as <.\nEXEC[threadId] = !(S0 <> S1)',
  VOP3Op.V_CMPX_NLG_F16_E64: '// With NAN inputs this is not the same operation as ==.\nEXEC[threadId] = !(S0 > S1)',
  VOP3Op.V_CMPX_NGT_F16_E64: '// With NAN inputs this is not the same operation as <=.\nEXEC[threadId] = !(S0 <= S1)',
  VOP3Op.V_CMPX_NLE_F16_E64: '// With NAN inputs this is not the same operation as >.\nEXEC[threadId] = !(S0 == S1)',
  VOP3Op.V_CMPX_NEQ_F16_E64: '// With NAN inputs this is not the same operation as !=.\nEXEC[threadId] = !(S0 < S1)',
  VOP3Op.V_CMPX_NLT_F16_E64: '// With NAN inputs this is not the same operation as >=.\nEXEC[threadId] = 1.',
  VOP3Op.V_FMA_LEGACY_F32_E64: 'D.f = S0.f * S1.f + S2.f. // DX9 rules, 0.0 * x = 0.0',
  VOP3Op.V_MAD_I32_I24_E64: 'D.i = S0.i[23:0] * S1.i[23:0] + S2.i.',
  VOP3Op.V_MAD_U32_U24_E64: 'D.u = S0.u[23:0] * S1.u[23:0] + S2.u.',
  VOP3Op.V_CUBEID_F32_E64: '// Set D.f = cubemap face ID ({0.0, 1.0, ..., 5.0}).\n// XYZ coordinate is given in (S0.f, S1.f, S2.f).\n// S0.f = x\n// S1.f = y\n// S2.f = z\nif (abs(S2.f) >= abs(S0.f) && abs(S2.f) >= abs(S1.f))\nif (S2.f < 0)\nD.f = 5.0;\nelse\nD.f = 4.0;\nendif;\nelse if (abs(S1.f) >= abs(S0.f))\nif (S1.f < 0)\nD.f = 3.0;\nelse\nD.f = 2.0;\nendif;\nelse\nif (S0.f < 0)\nD.f = 1.0;\nelse\nD.f = 0.0;\nendif;\nendif.',
  VOP3Op.V_CUBESC_F32_E64: '// D.f = cubemap S coordinate.\n// XYZ coordinate is given in (S0.f, S1.f, S2.f).\n// S0.f = x\n// S1.f = y\n// S2.f = z\nif (abs(S2.f) >= abs(S0.f) && abs(S2.f) >= abs(S1.f))\nif (S2.f < 0)\nD.f = -S0.f;\nelse\nD.f = S0.f;\nendif;\nelse if (abs(S1.f) >= abs(S0.f))\nD.f = S0.f;\nelse\nif (S0.f < 0)\nD.f = S2.f;\nelse\nD.f = -S2.f;\nendif;\nendif.',
  VOP3Op.V_CUBETC_F32_E64: '// D.f = cubemap T coordinate.\n// XYZ coordinate is given in (S0.f, S1.f, S2.f).\n// S0.f = x\n// S1.f = y\n// S2.f = z\nif (abs(S2.f) >= abs(S0.f) && abs(S2.f) >= bs(S1.f))\nD.f = -S1.f;\nelse if (abs(S1.f) >= abs(S0.f))\nif (S1.f < 0)\nD.f = -S2.f;\nelse\nD.f = S2.f;\nendif;\nelse\nD.f = -S1.f;\nendif.',
  VOP3Op.V_CUBEMA_F32_E64: '// D.f = 2.0 * cubemap major axis.\n// XYZ coordinate is given in (S0.f, S1.f, S2.f).\n// S0.f = x\n// S1.f = y\n// S2.f = z\nif (abs(S2.f) >= abs(S0.f) && abs(S2.f) >= abs(S1.f))\nD.f = 2.0 * S2.f;\nelse if (abs(S1.f) >= abs(S0.f))\nD.f = 2.0 * S1.f;\nelse\nD.f = 2.0 * S0.f;\nendif.',
  VOP3Op.V_BFE_U32_E64: 'D.u = (S0.u >> S1.u[4:0]) & ((1 << S2.u[4:0]) - 1).',
  VOP3Op.V_BFE_I32_E64: 'D.i = (S0.i >> S1.u[4:0]) & ((1 << S2.u[4:0]) - 1).',
  VOP3Op.V_BFI_B32_E64: 'D.u = (S0.u & S1.u) | (~S0.u & S2.u).',
  VOP3Op.V_FMA_F32_E64: 'D.f = S0.f * S1.f + S2.f.',
  VOP3Op.V_FMA_F64_E64: 'D.d = S0.d * S1.d + S2.d.',
  VOP3Op.V_LERP_U8_E64: 'D.u = ((S0.u[31:24] + S1.u[31:24] + S2.u[24]) >> 1) << 24\nD.u += ((S0.u[23:16] + S1.u[23:16] + S2.u[16]) >> 1) << 16;\nD.u += ((S0.u[15:8] + S1.u[15:8] + S2.u[8]) >> 1) << 8;\nD.u += ((S0.u[7:0] + S1.u[7:0] + S2.u[0]) >> 1).',
  VOP3Op.V_ALIGNBIT_B32_E64: 'D.u = ({S0,S1} >> S2.u[4:0]) & 0xffffffff.',
  VOP3Op.V_ALIGNBYTE_B32_E64: 'D.u = ({S0,S1} >> (8*S2.u[4:0])) & 0xffffffff.',
  VOP3Op.V_MULLIT_F32_E64: 'D.f = S0.f * S1.f',
  VOP3Op.V_MIN3_F32_E64: 'D.f = V_MIN_F32(V_MIN_F32(S0.f, S1.f), S2.f).',
  VOP3Op.V_MIN3_I32_E64: 'D.i = V_MIN_I32(V_MIN_I32(S0.i, S1.i), S2.i).',
  VOP3Op.V_MIN3_U32_E64: 'D.u = V_MIN_U32(V_MIN_U32(S0.u, S1.u), S2.u).',
  VOP3Op.V_MAX3_F32_E64: 'D.f = V_MAX_F32(V_MAX_F32(S0.f, S1.f), S2.f).',
  VOP3Op.V_MAX3_I32_E64: 'D.i = V_MAX_I32(V_MAX_I32(S0.i, S1.i), S2.i).',
  VOP3Op.V_MAX3_U32_E64: 'D.u = V_MAX_U32(V_MAX_U32(S0.u, S1.u), S2.u).',
  VOP3Op.V_MED3_F32_E64: 'if (isNan(S0.f) || isNan(S1.f) || isNan(S2.f))\nD.f = V_MIN3_F32(S0.f, S1.f, S2.f);\nelse if (V_MAX3_F32(S0.f, S1.f, S2.f) == S0.f)\nD.f = V_MAX_F32(S1.f, S2.f);\nelse if (V_MAX3_F32(S0.f, S1.f, S2.f) == S1.f)\nD.f = V_MAX_F32(S0.f, S2.f);\nelse\nD.f = V_MAX_F32(S0.f, S1.f);\nendif.',
  VOP3Op.V_MED3_I32_E64: 'if (V_MAX3_I32(S0.i, S1.i, S2.i) == S0.i)\nD.i = V_MAX_I32(S1.i, S2.i);\nelse if (V_MAX3_I32(S0.i, S1.i, S2.i) == S1.i)\nD.i = V_MAX_I32(S0.i, S2.i);\nelse\nD.i = V_MAX_I32(S0.i, S1.i);\nendif.',
  VOP3Op.V_MED3_U32_E64: 'if (V_MAX3_U32(S0.u, S1.u, S2.u) == S0.u)\nD.u = V_MAX_U32(S1.u, S2.u);\nelse if (V_MAX3_U32(S0.u, S1.u, S2.u) == S1.u)\nD.u = V_MAX_U32(S0.u, S2.u);\nelse\nD.u = V_MAX_U32(S0.u, S1.u);\nendif.',
  VOP3Op.V_SAD_U8_E64: 'ABSDIFF(x, y) := (x > y ? x - y : y - x) // UNSIGNED comparison\nD.u  = S2.u;\nD.u += ABSDIFF(S0.u[31:24], S1.u[31:24]);\nD.u += ABSDIFF(S0.u[23:16], S1.u[23:16]);\nD.u += ABSDIFF(S0.u[15:8],  S1.u[15:8]);\nD.u += ABSDIFF(S0.u[7:0],   S1.u[7:0]).',
  VOP3Op.V_SAD_HI_U8_E64: 'D.u = (V_SAD_U8(S0, S1, 0) << 16) + S2.u.',
  VOP3Op.V_SAD_U16_E64: 'ABSDIFF(x, y) := (x > y ? x - y : y - x) // UNSIGNED comparison\nD.u  = S2.u;\nD.u += ABSDIFF(S0.u[31:16], S1.u[31:16]);\nD.u += ABSDIFF(S0.u[15:0],  S1.u[15:0]).',
  VOP3Op.V_SAD_U32_E64: 'ABSDIFF(x, y) := (x > y ? x - y : y - x) // UNSIGNED comparison\nD.u = ABSDIFF(S0.u, S1.u) + S2.u.',
  VOP3Op.V_CVT_PK_U8_F32_E64: 'D.u = (S2.u & ~(0xff << (8 * S1.u[1:0])));\nD.u = D.u | ((flt32_to_uint8(S0.f) & 0xff) << (8 * S1.u[1:0])).',
  VOP3Op.V_DIV_FIXUP_F32_E64: 'sign_out =  sign(S1.f)^sign(S2.f);\nif (S2.f == NAN)\nD.f = Quiet(S2.f);\nelse if (S1.f == NAN)\nD.f = Quiet(S1.f);\nelse if (S1.f == S2.f == 0)\n// 0/0\nD.f = 0xffc0_0000;\nelse if (abs(S1.f) == abs(S2.f) == +-INF)\n// inf/inf\nD.f = 0xffc0_0000;\nelse if (S1.f == 0 || abs(S2.f) == +-INF)\n// x/0, or inf/y\nD.f = sign_out ? -INF : +INF;\nelse if (abs(S1.f) == +-INF || S2.f == 0)\n// x/inf, 0/y\nD.f = sign_out ? -0 : 0;\nelse if ((exponent(S2.f) - exponent(S1.f)) < -150)\nD.f = sign_out ? -underflow : underflow;\nelse if (exponent(S1.f) == 255)\nD.f = sign_out ? -overflow : overflow;\nelse\nD.f = sign_out ? -abs(S0.f) : abs(S0.f);\nendif.',
  VOP3Op.V_DIV_FIXUP_F64_E64: 'sign_out =  sign(S1.d)^sign(S2.d);\nif (S2.d == NAN)\nD.d = Quiet(S2.d);\nelse if (S1.d == NAN)\nD.d = Quiet(S1.d);\nelse if (S1.d == S2.d == 0)\n// 0/0\nD.d = 0xfff8_0000_0000_0000;\nelse if (abs(S1.d) == abs(S2.d) == +-INF)\n// inf/inf\nD.d = 0xfff8_0000_0000_0000;\nelse if (S1.d == 0 || abs(S2.d) == +-INF)\n// x/0, or inf/y\nD.d = sign_out ? -INF : +INF;\nelse if (abs(S1.d) == +-INF || S2.d == 0)\n// x/inf, 0/y\nD.d = sign_out ? -0 : 0;\nelse if ((exponent(S2.d) - exponent(S1.d)) < -1075)\nD.d = sign_out ? -underflow : underflow;\nelse if (exponent(S1.d) == 2047)\nD.d = sign_out ? -overflow : overflow;\nelse\nD.d = sign_out ? -abs(S0.d) : abs(S0.d);\nendif.',
  VOP3Op.V_ADD_F64_E64: 'D.d = S0.d + S1.d.',
  VOP3Op.V_MUL_F64_E64: 'D.d = S0.d * S1.d.',
  VOP3Op.V_MIN_F64_E64: "if (IEEE_MODE && S0.d == sNaN)\nD.d = Quiet(S0.d);\nelse if (IEEE_MODE && S1.d == sNaN)\nD.d = Quiet(S1.d);\nelse if (S0.d == NaN)\nD.d = S1.d;\nelse if (S1.d == NaN)\nD.d = S0.d;\nelse if (S0.d == +0.0 && S1.d == -0.0)\nD.d = S1.d;\nelse if (S0.d == -0.0 && S1.d == +0.0)\nD.d = S0.d;\nelse\n// Note: there's no IEEE special case here like there is for\nD.d = (S0.d < S1.d ? S0.d : S1.d);\nendif.",
  VOP3Op.V_MAX_F64_E64: 'if (IEEE_MODE && S0.d == sNaN)\nD.d = Quiet(S0.d);\nelse if (IEEE_MODE && S1.d == sNaN)\nD.d = Quiet(S1.d);\nelse if (S0.d == NaN)\nD.d = S1.d;\nelse if (S1.d == NaN)\nD.d = S0.d;\nelse if (S0.d == +0.0 && S1.d == -0.0)\nD.d = S0.d;\nelse if (S0.d == -0.0 && S1.d == +0.0)\nD.d = S1.d;\nelse if (IEEE_MODE)\nD.d = (S0.d >= S1.d ? S0.d : S1.d);\nelse\nD.d = (S0.d > S1.d ? S0.d : S1.d);\nendif.',
  VOP3Op.V_LDEXP_F64_E64: 'D.d = S0.d * (2 ** S1.i).',
  VOP3Op.V_MUL_LO_U32_E64: 'D.u = S0.u * S1.u.',
  VOP3Op.V_MUL_HI_U32_E64: 'D.u = (S0.u * S1.u) >> 32.',
  VOP3Op.V_MUL_HI_I32_E64: 'D.i = (S0.i * S1.i) >> 32.',
  VOP3Op.V_DIV_FMAS_F32_E64: 'if (VCC[threadId])\nD.f = 2**32 * (S0.f * S1.f + S2.f);\nelse\nD.f = S0.f * S1.f + S2.f;\nend if.',
  VOP3Op.V_DIV_FMAS_F64_E64: 'if (VCC[threadId])\nD.d = 2**64 * (S0.d * S1.d + S2.d);\nelse\nD.d = S0.d * S1.d + S2.d;\nend if.',
  VOP3Op.V_MSAD_U8_E64: 'ABSDIFF(x, y) := (x > y ? x - y : y - x) // UNSIGNED comparison\nD.u  = S2.u;\nD.u += S1.u[31:24] == 0 ? 0 : ABSDIFF(S0.u[31:24], S1.u[31:24]);\nD.u += S1.u[23:16] == 0 ? 0 : ABSDIFF(S0.u[23:16], S1.u[23:16]);\nD.u += S1.u[15:8]  == 0 ? 0 : ABSDIFF(S0.u[15:8],  S1.u[15:8]);\nD.u += S1.u[7:0]   == 0 ? 0 : ABSDIFF(S0.u[7:0],   S1.u[7:0]).',
  VOP3Op.V_QSAD_PK_U16_U8_E64: 'D[63:48] = SAD_U8(S0[55:24], S1[31:0], S2[63:48]);\nD[47:32] = SAD_U8(S0[47:16], S1[31:0], S2[47:32]);\nD[31:16] = SAD_U8(S0[39:8],  S1[31:0], S2[31:16]);\nD[15:0]  = SAD_U8(S0[31:0],  S1[31:0], S2[15:0]).',
  VOP3Op.V_MQSAD_PK_U16_U8_E64: 'D[63:48] = MSAD_U8(S0[55:24], S1[31:0], S2[63:48]);\nD[47:32] = MSAD_U8(S0[47:16], S1[31:0], S2[47:32]);\nD[31:16] = MSAD_U8(S0[39:8],  S1[31:0], S2[31:16]);\nD[15:0]  = MSAD_U8(S0[31:0],  S1[31:0], S2[15:0]).',
  VOP3Op.V_TRIG_PREOP_F64_E64: 'shift = S1.u * 53;\nif exponent(S0.d) > 1077 then\nshift += exponent(S0.d) - 1077;\nendif\nresult = (double) ((2/PI[1200:0] << shift) & 0x1fffff_ffffffff);\nscale = (-53 - shift);\nif exponent(S0.d) >= 1968 then\nscale += 128;\nendif\nD.d = ldexp(result, scale).',
  VOP3Op.V_MQSAD_U32_U8_E64: 'D[127:96] = MSAD_U8(S0[55:24], S1[31:0], S2[127:96]);\nD[95:64]  = MSAD_U8(S0[47:16], S1[31:0], S2[95:64]);\nD[63:32]  = MSAD_U8(S0[39:8],  S1[31:0], S2[63:32]);\nD[31:0]   = MSAD_U8(S0[31:0],  S1[31:0], S2[31:0]).',
  VOP3Op.V_XOR3_B32_E64: 'D.u32 = S0.u32 ^ S1.u32 ^ S2.u32.',
  VOP3Op.V_LSHLREV_B64: 'D.u64 = S1.u64 << S0.u[5:0].',
  VOP3Op.V_LSHRREV_B64: 'D.u64 = S1.u64 >> S0.u[5:0].',
  VOP3Op.V_ASHRREV_I64: 'D.u64 = signext(S1.u64) >> S0.u[5:0].',
  VOP3Op.V_ADD_NC_U16: 'D.u16 = S0.u16 + S1.u16.',
  VOP3Op.V_SUB_NC_U16: 'D.u16 = S0.u16 - S1.u16.',
  VOP3Op.V_MUL_LO_U16: 'D.u16 = S0.u16 * S1.u16.',
  VOP3Op.V_LSHRREV_B16: 'D.u[15:0] = S1.u[15:0] >> S0.u[3:0].',
  VOP3Op.V_ASHRREV_I16: 'D.i[15:0] = signext(S1.i[15:0]) >> S0.i[3:0].',
  VOP3Op.V_MAX_U16: 'D.u16 = (S0.u16 >= S1.u16 ? S0.u16 : S1.u16).',
  VOP3Op.V_MAX_I16: 'D.i16 = (S0.i16 >= S1.i16 ? S0.i16 : S1.i16).',
  VOP3Op.V_MIN_U16: 'D.u16 = (S0.u16 < S1.u16 ? S0.u16 : S1.u16).',
  VOP3Op.V_MIN_I16: 'D.i16 = (S0.i16 < S1.i16 ? S0.i16 : S1.i16).',
  VOP3Op.V_ADD_NC_I16: 'D.i16 = S0.i16 + S1.i16.',
  VOP3Op.V_SUB_NC_I16: 'D.i16 = S0.i16 - S1.i16.',
  VOP3Op.V_PACK_B32_F16: 'D[31:16].f16 = S1.f16;\nD[15:0].f16 = S0.f16.',
  VOP3Op.V_CVT_PKNORM_I16_F16: 'D = {(snorm)S1.f16, (snorm)S0.f16}.',
  VOP3Op.V_CVT_PKNORM_U16_F16: 'D = {(unorm)S1.f16, (unorm)S0.f16}.',
  VOP3Op.V_LSHLREV_B16: 'D.u[15:0] = S1.u[15:0] << S0.u[3:0].',
  VOP3Op.V_MAD_U16: 'D.u16 = S0.u16 * S1.u16 + S2.u16.',
  VOP3Op.V_INTERP_P1LL_F16: 'D.f32 = P10.f16 * S0.f32 + P0.f16.',
  VOP3Op.V_INTERP_P1LV_F16: 'D.f32 = P10.f16 * S0.f32 + (S2.u32 >> (attr_word * 16)).f16.',
  VOP3Op.V_PERM_B32: 'D.u[31:24] = byte_permute({S0.u, S1.u}, S2.u[31:24]);\nD.u[23:16] = byte_permute({S0.u, S1.u}, S2.u[23:16]);\nD.u[15:8] = byte_permute({S0.u, S1.u}, S2.u[15:8]);\nD.u[7:0] = byte_permute({S0.u, S1.u}, S2.u[7:0]);\nbyte permute(byte in[8], byte sel) {\nif(sel>=13) then return 0xff;\nelsif(sel==12) then return 0x00;\nelsif(sel==11) then return in[7][7] * 0xff;\nelsif(sel==10) then return in[5][7] * 0xff;\nelsif(sel==9) then return in[3][7] * 0xff;\nelsif(sel==8) then return in[1][7] * 0xff;\nelse return in[sel];\n}',
  VOP3Op.V_XAD_U32: 'D.u32 = (S0.u32 ^ S1.u32) + S2.u32.',
  VOP3Op.V_LSHL_ADD_U32: 'D.u = (S0.u << S1.u[4:0]) + S2.u.',
  VOP3Op.V_ADD_LSHL_U32: 'D.u = (S0.u + S1.u) << S2.u[4:0].',
  VOP3Op.V_FMA_F16: 'D.f16 = S0.f16 * S1.f16 + S2.f16.',
  VOP3Op.V_MIN3_F16: 'D.f16 = V_MIN_F16(V_MIN_F16(S0.f16, S1.f16), S2.f16).',
  VOP3Op.V_MIN3_I16: 'D.i16 = V_MIN_I16(V_MIN_I16(S0.i16, S1.i16), S2.i16).',
  VOP3Op.V_MIN3_U16: 'D.u16 = V_MIN_U16(V_MIN_U16(S0.u16, S1.u16), S2.u16).',
  VOP3Op.V_MAX3_F16: 'D.f16 = V_MAX_F16(V_MAX_F16(S0.f16, S1.f16), S2.f16).',
  VOP3Op.V_MAX3_I16: 'D.i16 = V_MAX_I16(V_MAX_I16(S0.i16, S1.i16), S2.i16).',
  VOP3Op.V_MAX3_U16: 'D.u16 = V_MAX_U16(V_MAX_U16(S0.u16, S1.u16), S2.u16).',
  VOP3Op.V_MED3_F16: 'if (isNan(S0.f16) || isNan(S1.f16) || isNan(S2.f16))\nD.f16 = V_MIN3_F16(S0.f16, S1.f16, S2.f16);\nelse if (V_MAX3_F16(S0.f16, S1.f16, S2.f16) == S0.f16)\nD.f16 = V_MAX_F16(S1.f16, S2.f16);\nelse if (V_MAX3_F16(S0.f16, S1.f16, S2.f16) == S1.f16)\nD.f16 = V_MAX_F16(S0.f16, S2.f16);\nelse\nD.f16 = V_MAX_F16(S0.f16, S1.f16);\nendif.',
  VOP3Op.V_MED3_I16: 'if (V_MAX3_I16(S0.i16, S1.i16, S2.i16) == S0.i16)\nD.i16 = V_MAX_I16(S1.i16, S2.i16);\nelse if (V_MAX3_I16(S0.i16, S1.i16, S2.i16) == S1.i16)\nD.i16 = V_MAX_I16(S0.i16, S2.i16);\nelse\nD.i16 = V_MAX_I16(S0.i16, S1.i16);\nendif.',
  VOP3Op.V_MED3_U16: 'if (V_MAX3_U16(S0.u16, S1.u16, S2.u16) == S0.u16)\nD.u16 = V_MAX_U16(S1.u16, S2.u16);\nelse if (V_MAX3_U16(S0.u16, S1.u16, S2.u16) == S1.u16)\nD.u16 = V_MAX_U16(S0.u16, S2.u16);\nelse\nD.u16 = V_MAX_U16(S0.u16, S1.u16);\nendif.',
  VOP3Op.V_INTERP_P2_F16: 'D.f16 = P20.f16 * S0.f32 + S2.f32.',
  VOP3Op.V_MAD_I16: 'D.i16 = S0.i16 * S1.i16 + S2.i16.',
  VOP3Op.V_DIV_FIXUP_F16: 'sign_out =  sign(S1.f16)^sign(S2.f16);\nif (S2.f16 == NAN)\nD.f16 = Quiet(S2.f16);\nelse if (S1.f16 == NAN)\nD.f16 = Quiet(S1.f16);\nelse if (S1.f16 == S2.f16 == 0)\n// 0/0\nD.f16 = 0xfe00;\nelse if (abs(S1.f16) == abs(S2.f16) == +-INF)\n// inf/inf\nD.f16 = 0xfe00;\nelse if (S1.f16 ==0 || abs(S2.f16) == +-INF)\n// x/0, or inf/y\nD.f16 = sign_out ? -INF : +INF;\nelse if (abs(S1.f16) == +-INF || S2.f16 == 0)\n// x/inf, 0/y\nD.f16 = sign_out ? -0 : 0;\nelse\nD.f16 = sign_out ? -abs(S0.f16) : abs(S0.f16);\nend if.',
  VOP3Op.V_READLANE_B32: 'if(wave32)\nSMEM[D_ADDR] = VMEM[S0_ADDR][S1[4:0]]; // For wave32\nelse\nSMEM[D_ADDR] = VMEM[S0_ADDR][S1[5:0]]; // For wave64\nendif.',
  VOP3Op.V_WRITELANE_B32: 'if(wave32)\nVMEM[D_ADDR][S1[4:0]] = SMEM[S0_ADDR]; // For wave32\nelse\nVMEM[D_ADDR][S1[5:0]] = SMEM[S0_ADDR]; // For wave64\nendif.',
  VOP3Op.V_LDEXP_F32: 'D.f = S0.f * (2 ** S1.i).',
  VOP3Op.V_BFM_B32: 'D.u32 = ((1<<S0[4:0])-1) << S1[4:0].',
  VOP3Op.V_BCNT_U32_B32: "D.u = S1.u;\nfor i in 0 .. 31 do\nD.u += S0.u[i]; // count i'th bit\nendfor.",
  VOP3Op.V_MBCNT_LO_U32_B32: 'ThreadMask = (1LL << ThreadPosition) - 1;\nMaskedValue = (S0.u & ThreadMask[31:0]);\nD.u = S1.u;\nfor i in 0 ... 31 do\nD.u += (MaskedValue[i] == 1 ? 1 : 0);\nendfor.',
  VOP3Op.V_MBCNT_HI_U32_B32: 'ThreadMask = (1LL << ThreadPosition) - 1;\nMaskedValue = (S0.u & ThreadMask[63:32]);\nD.u = S1.u;\nfor i in 0 ... 31 do\nD.u += (MaskedValue[i] == 1 ? 1 : 0);\nendfor.',
  VOP3Op.V_CVT_PKNORM_I16_F32: 'D.i16_lo = (snorm)S0.f32;\nD.i16_hi = (snorm)S1.f32.',
  VOP3Op.V_CVT_PKNORM_U16_F32: 'D.u16_lo = (unorm)S0.f32;\nD.u16_hi = (unorm)S1.f32.',
  VOP3Op.V_CVT_PK_U16_U32: 'D.u16_lo = u32_to_u16(S0.u32);\nD.u16_hi = u32_to_u16(S1.u32).',
  VOP3Op.V_CVT_PK_I16_I32: 'D.i16_lo = i32_to_i16(S0.i32);\nD.i16_hi = i32_to_i16(S1.i32).',
  VOP3Op.V_ADD3_U32: 'D.u = S0.u + S1.u + S2.u.',
  VOP3Op.V_LSHL_OR_B32: 'D.u = (S0.u << S1.u[4:0]) | S2.u.',
  VOP3Op.V_AND_OR_B32: 'D.u = (S0.u & S1.u) | S2.u.',
  VOP3Op.V_OR3_B32: 'D.u = S0.u | S1.u | S2.u.',
  VOP3Op.V_MAD_U32_U16: 'D.u32 = S0.u16 * S1.u16 + S2.u32.',
  VOP3Op.V_MAD_I32_I16: 'D.i32 = S0.i16 * S1.i16 + S2.i32.',
  VOP3Op.V_SUB_NC_I32: 'D.i = S0.i - S1.i.',
  VOP3Op.V_PERMLANE16_B32: 'lanesel = { S2.u, S1.u }; // Concatenate lane select bits\nfor row in 0 ... 3 do // interval is 0 ... 1 for wave32 mode\n// Implement arbitrary swizzle within each row\nfor i in 0 ... 15 do\nD.lane[row * 16 + i] = S0.lane[row * 16 + lanesel[i * 4 + 3:i\nendfor;\nendfor.',
  VOP3Op.V_PERMLANEX16_B32: 'lanesel = { S2.u, S1.u }; // Concatenate lane select bits\nfor row in 0 ... 3 do // interval is 0 ... 1 for wave32 mode\n// Implement arbitrary swizzle across two rows\naltrow = {row[1], ~row[0]}; // 1<->0, 3<->2\nfor i in 0 ... 15 do\nD.lane[row * 16 + i] = S0.lane[altrow * 16 + lanesel[i * 4 +\nendfor;\nendfor.',
  VOP3Op.V_ADD_NC_I32: 'D.i = S0.i + S1.i.\n// 32bit',
  VOP3POp.V_PK_MAD_I16: 'D.i[31:16] = S0.i[31:16] * S1.i[31:16] + S2.i[31:16];\nD.i[15:0]  = S0.i[15:0]  * S1.i[15:0]  + S2.i[15:0].',
  VOP3POp.V_PK_MUL_LO_U16: 'D.u[31:16] = S0.u[31:16] * S1.u[31:16];\nD.u[15:0]  = S0.u[15:0]  * S1.u[15:0].',
  VOP3POp.V_PK_ADD_I16: 'D.i[31:16] = S0.i[31:16] + S1.i[31:16];\nD.i[15:0]  = S0.i[15:0]  + S1.i[15:0].',
  VOP3POp.V_PK_SUB_I16: 'D.i[31:16] = S0.i[31:16] - S1.i[31:16];\nD.i[15:0]  = S0.i[15:0]  - S1.i[15:0].',
  VOP3POp.V_PK_LSHLREV_B16: 'D.u[31:16] = S1.u[31:16] << S0.u[19:16];\nD.u[15:0]  = S1.u[15:0]  << S0.u[3:0].',
  VOP3POp.V_PK_LSHRREV_B16: 'D.u[31:16] = S1.u[31:16] >> S0.u[19:16];\nD.u[15:0]  = S1.u[15:0]  >> S0.u[3:0].',
  VOP3POp.V_PK_ASHRREV_I16: 'D.i[31:16] = S1.i[31:16] >> S0.i[19:16];\nD.i[15:0]  = S1.i[15:0]  >> S0.i[3:0].',
  VOP3POp.V_PK_MAX_I16: 'D.i[31:16] = (S0.i[31:16] >= S1.i[31:16]) ? S0.i[31:16] :\nD.i[15:0]  = (S0.i[15:0]  >= S1.i[15:0])  ? S0.i[15:0]  :',
  VOP3POp.V_PK_MIN_I16: 'D.i[31:16] = (S0.i[31:16] < S1.i[31:16]) ? S0.i[31:16] :\nD.i[15:0]  = (S0.i[15:0]  < S1.i[15:0])  ? S0.i[15:0]  :',
  VOP3POp.V_PK_MAD_U16: 'D.u[31:16] = S0.u[31:16] * S1.u[31:16] + S2.u[31:16];\nD.u[15:0]  = S0.u[15:0]  * S1.u[15:0]  + S2.u[15:0].',
  VOP3POp.V_PK_ADD_U16: 'D.u[31:16] = S0.u[31:16] + S1.u[31:16];\nD.u[15:0]  = S0.u[15:0]  + S1.u[15:0].',
  VOP3POp.V_PK_SUB_U16: 'D.u[31:16] = S0.u[31:16] - S1.u[31:16];\nD.u[15:0]  = S0.u[15:0]  - S1.u[15:0].',
  VOP3POp.V_PK_MAX_U16: 'D.u[31:16] = (S0.u[31:16] >= S1.u[31:16]) ? S0.u[31:16] :\nD.u[15:0]  = (S0.u[15:0]  >= S1.u[15:0])  ? S0.u[15:0]  :',
  VOP3POp.V_PK_MIN_U16: 'D.u[31:16] = (S0.u[31:16] < S1.u[31:16]) ? S0.u[31:16] :\nD.u[15:0]  = (S0.u[15:0]  < S1.u[15:0])  ? S0.u[15:0]  :',
  VOP3POp.V_PK_FMA_F16: 'D.f[31:16] = S0.f[31:16] * S1.f[31:16] + S2.f[31:16];\nD.f[15:0]  = S0.f[15:0]  * S1.f[15:0]  + S2.f[15:0].',
  VOP3POp.V_PK_ADD_F16: 'D.f[31:16] = S0.f[31:16] + S1.f[31:16];\nD.f[15:0]  = S0.f[15:0]  + S1.f[15:0].',
  VOP3POp.V_PK_MUL_F16: 'D.f[31:16] = S0.f[31:16] * S1.f[31:16];\nD.f[15:0]  = S0.f[15:0]  * S1.f[15:0].',
  VOP3POp.V_PK_MIN_F16: 'D.f[31:16] = min(S0.f[31:16], S1.f[31:16]);\nD.f[15:0]  = min(S0.f[15:0], S1.u[15:0]).',
  VOP3POp.V_PK_MAX_F16: 'D.f[31:16] = max(S0.f[31:16], S1.f[31:16]);\nD.f[15:0]  = max(S0.f[15:0], S1.f[15:0]).',
  VOP3POp.V_DOT2_F32_F16: 'D.f32 =\nS0.f16[0] * S1.f16[0] +\nS0.f16[1] * S1.f16[1] + S2.f32.',
  VOP3POp.V_DOT2_I32_I16: 'D.i32 =\nS0.i16[0] * S1.i16[0] +\nS0.i16[1] * S1.i16[1] + S2.i32.',
  VOP3POp.V_DOT2_U32_U16: 'D.u32 =\nS0.u16[0] * S1.u16[0] +\nS0.u16[1] * S1.u16[1] + S2.u32.',
  VOP3POp.V_DOT4_I32_I8: 'D.i32 =\nS0.i8[0] * S1.i8[0] +\nS0.i8[1] * S1.i8[1] +\nS0.i8[2] * S1.i8[2] +\nS0.i8[3] * S1.i8[3] + S2.i32.',
  VOP3POp.V_DOT4_U32_U8: 'D.u32 =\nS0.u8[0] * S1.u8[0] +\nS0.u8[1] * S1.u8[1] +\nS0.u8[2] * S1.u8[2] +\nS0.u8[3] * S1.u8[3] + S2.u32.',
  VOP3POp.V_DOT8_I32_I4: 'D.i32 =\nS0.i4[0] * S1.i4[0] +\nS0.i4[1] * S1.i4[1] +\nS0.i4[2] * S1.i4[2] +\nS0.i4[3] * S1.i4[3] +\nS0.i4[4] * S1.i4[4] +\nS0.i4[5] * S1.i4[5] +\nS0.i4[6] * S1.i4[6] +\nS0.i4[7] * S1.i4[7] + S2.i32.',
  VOP3POp.V_DOT8_U32_U4: 'D.u32 =\nS0.u4[0] * S1.u4[0] +\nS0.u4[1] * S1.u4[1] +\nS0.u4[2] * S1.u4[2] +\nS0.u4[3] * S1.u4[3] +\nS0.u4[4] * S1.u4[4] +\nS0.u4[5] * S1.u4[5] +\nS0.u4[6] * S1.u4[6] +\nS0.u4[7] * S1.u4[7] + S2.u32.',
  VOP3POp.V_FMA_MIX_F32: 'D.f[31:0] = S0.f * S1.f + S2.f.',
  VOP3POp.V_FMA_MIXLO_F16: 'D.f[15:0] = S0.f * S1.f + S2.f.',
  VOP3POp.V_FMA_MIXHI_F16: 'D.f[31:16] = S0.f * S1.f + S2.f.',
  VOP3SDOp.V_DIV_SCALE_F32: 'VCC = 0;\nif (S2.f == 0 || S1.f == 0)\nD.f = NAN\nelse if (exponent(S2.f) - exponent(S1.f) >= 96)\n// N/D near MAX_FLOAT\nVCC = 1;\nif (S0.f == S1.f)\n// Only scale the denominator\nD.f = ldexp(S0.f, 64);\nend if\nelse if (S1.f == DENORM)\nD.f = ldexp(S0.f, 64);\nelse if (1 / S1.f == DENORM && S2.f / S1.f == DENORM)\nVCC = 1;\nif (S0.f == S1.f)\n// Only scale the denominator\nD.f = ldexp(S0.f, 64);\nend if\nelse if (1 / S1.f == DENORM)\nD.f = ldexp(S0.f, -64);\nelse if (S2.f / S1.f==DENORM)\nVCC = 1;\nif (S0.f == S2.f)\n// Only scale the numerator\nD.f = ldexp(S0.f, 64);\nend if\nelse if (exponent(S2.f) <= 23)\n// Numerator is tiny\nD.f = ldexp(S0.f, 64);\nend if.',
  VOP3SDOp.V_DIV_SCALE_F64: 'VCC = 0;\nif (S2.d == 0 || S1.d == 0)\nD.d = NAN\nelse if (exponent(S2.d) - exponent(S1.d) >= 768)\n// N/D near MAX_FLOAT\nVCC = 1;\nif (S0.d == S1.d)\n// Only scale the denominator\nD.d = ldexp(S0.d, 128);\nend if\nelse if (S1.d == DENORM)\nD.d = ldexp(S0.d, 128);\nelse if (1 / S1.d == DENORM && S2.d / S1.d == DENORM)\nVCC = 1;\nif (S0.d == S1.d)\n// Only scale the denominator\nD.d = ldexp(S0.d, 128);\nend if\nelse if (1 / S1.d == DENORM)\nD.d = ldexp(S0.d, -128);\nelse if (S2.d / S1.d==DENORM)\nVCC = 1;\nif (S0.d == S2.d)\n// Only scale the numerator\nD.d = ldexp(S0.d, 128);\nend if\nelse if (exponent(S2.d) <= 53)\n// Numerator is tiny\nD.d = ldexp(S0.d, 128);\nend if.',
  VOP3SDOp.V_MAD_U64_U32: '{vcc_out,D.u64} = S0.u32 * S1.u32 + S2.u64.',
  VOP3SDOp.V_MAD_I64_I32: '{vcc_out,D.i64} = S0.i32 * S1.i32 + S2.i64.',
  VOP3SDOp.V_ADD_CO_U32: 'D.u32 = S0.u32 + S1.u32;\nVCC = S0.u + S1.u >= 0x100000000ULL ? 1 : 0.',
  VOP3SDOp.V_SUB_CO_U32: 'D.u = S0.u - S1.u;\nVCC[threadId] = (S1.u > S0.u ? 1 : 0).\n// VCC is an UNSIGNED overflow/carry-out for V_SUB_CO_CI_U32.',
  VOP3SDOp.V_SUBREV_CO_U32: 'D.u = S1.u - S0.u;\nVCC[threadId] = (S0.u > S1.u ? 1 : 0).\n// VCC is an UNSIGNED overflow/carry-out for V_SUB_CO_CI_U32.',
  VOPCOp.V_CMP_F_F32_E32: 'D[threadId] = 0.\n// D = VCC in VOPC encoding.\nD[threadId] = (S0 < S1).',
  VOPCOp.V_CMP_LT_F32_E32: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 == S1).',
  VOPCOp.V_CMP_EQ_F32_E32: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 <= S1).',
  VOPCOp.V_CMP_LE_F32_E32: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 > S1).',
  VOPCOp.V_CMP_GT_F32_E32: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 <> S1).',
  VOPCOp.V_CMP_LG_F32_E32: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 >= S1).',
  VOPCOp.V_CMP_GE_F32_E32: '// D = VCC in VOPC encoding.\nD[threadId] = (!isNan(S0) && !isNan(S1)).',
  VOPCOp.V_CMP_O_F32_E32: '// D = VCC in VOPC encoding.\nD[threadId] = (isNan(S0)  ||  isNan(S1)).',
  VOPCOp.V_CMP_U_F32_E32: '// D = VCC in VOPC encoding.',
  VOPCOp.V_CMP_NGE_F32_E32: 'D[threadId] = !(S0 >= S1)\n// With NAN inputs this is not the same operation as <.\n// D = VCC in VOPC encoding.',
  VOPCOp.V_CMP_NLG_F32_E32: 'D[threadId] = !(S0 <> S1)\n// With NAN inputs this is not the same operation as ==.\n// D = VCC in VOPC encoding.\nD[threadId] = !(S0 > S1)',
  VOPCOp.V_CMP_NGT_F32_E32: '// With NAN inputs this is not the same operation as <=.\n// D = VCC in VOPC encoding.\nD[threadId] = !(S0 <= S1)',
  VOPCOp.V_CMP_NLE_F32_E32: '// With NAN inputs this is not the same operation as >.\n// D = VCC in VOPC encoding.\nD[threadId] = !(S0 == S1)',
  VOPCOp.V_CMP_NEQ_F32_E32: '// With NAN inputs this is not the same operation as !=.\n// D = VCC in VOPC encoding.',
  VOPCOp.V_CMP_NLT_F32_E32: 'D[threadId] = !(S0 < S1)\n// With NAN inputs this is not the same operation as >=.\n// D = VCC in VOPC encoding.\nD[threadId] = 1.',
  VOPCOp.V_CMP_TRU_F32_E32: '// D = VCC in VOPC encoding.\nEXEC[threadId] = 0.',
  VOPCOp.V_CMPX_F_F32_E32: 'EXEC[threadId] = (S0 < S1).',
  VOPCOp.V_CMPX_LT_F32_E32: 'EXEC[threadId] = (S0 == S1).',
  VOPCOp.V_CMPX_EQ_F32_E32: 'EXEC[threadId] = (S0 <= S1).',
  VOPCOp.V_CMPX_GT_F32_E32: 'EXEC[threadId] = (S0 > S1).\nEXEC[threadId] = (S0 <> S1).',
  VOPCOp.V_CMPX_GE_F32_E32: 'EXEC[threadId] = (S0 >= S1).\nEXEC[threadId] = (!isNan(S0) && !isNan(S1)).',
  VOPCOp.V_CMPX_O_F32_E32: 'EXEC[threadId] = (isNan(S0)  ||  isNan(S1)).',
  VOPCOp.V_CMPX_U_F32_E32: 'EXEC[threadId] = !(S0 >= S1)',
  VOPCOp.V_CMPX_NGE_F32_E32: '// With NAN inputs this is not the same operation as <.\nEXEC[threadId] = !(S0 <> S1)',
  VOPCOp.V_CMPX_NLG_F32_E32: '// With NAN inputs this is not the same operation as ==.\nEXEC[threadId] = !(S0 > S1)',
  VOPCOp.V_CMPX_NGT_F32_E32: '// With NAN inputs this is not the same operation as <=.\nEXEC[threadId] = !(S0 <= S1)',
  VOPCOp.V_CMPX_NLE_F32_E32: '// With NAN inputs this is not the same operation as >.\nEXEC[threadId] = !(S0 == S1)',
  VOPCOp.V_CMPX_NEQ_F32_E32: '// With NAN inputs this is not the same operation as !=.\nEXEC[threadId] = !(S0 < S1)',
  VOPCOp.V_CMPX_NLT_F32_E32: '// With NAN inputs this is not the same operation as >=.\nEXEC[threadId] = 1.',
  VOPCOp.V_CMPX_TRU_F32_E32: 'D[threadId] = 0.',
  VOPCOp.V_CMP_F_F64_E32: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 < S1).',
  VOPCOp.V_CMP_LT_F64_E32: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 == S1).',
  VOPCOp.V_CMP_EQ_F64_E32: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 <= S1).',
  VOPCOp.V_CMP_LE_F64_E32: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 > S1).',
  VOPCOp.V_CMP_GT_F64_E32: '// D = VCC in VOPC encoding.',
  VOPCOp.V_CMP_LG_F64_E32: 'D[threadId] = (S0 <> S1).\n// D = VCC in VOPC encoding.',
  VOPCOp.V_CMP_GE_F64_E32: 'D[threadId] = (S0 >= S1).\n// D = VCC in VOPC encoding.\nD[threadId] = (!isNan(S0) && !isNan(S1)).',
  VOPCOp.V_CMP_O_F64_E32: '// D = VCC in VOPC encoding.\nD[threadId] = (isNan(S0)  ||  isNan(S1)).',
  VOPCOp.V_CMP_U_F64_E32: '// D = VCC in VOPC encoding.\nD[threadId] = !(S0 >= S1)',
  VOPCOp.V_CMP_NGE_F64_E32: '// With NAN inputs this is not the same operation as <.\n// D = VCC in VOPC encoding.\nD[threadId] = !(S0 <> S1)',
  VOPCOp.V_CMP_NLG_F64_E32: '// With NAN inputs this is not the same operation as ==.\n// D = VCC in VOPC encoding.',
  VOPCOp.V_CMP_NGT_F64_E32: 'D[threadId] = !(S0 > S1)\n// With NAN inputs this is not the same operation as <=.\n// D = VCC in VOPC encoding.\nD[threadId] = !(S0 <= S1)',
  VOPCOp.V_CMP_NLE_F64_E32: '// With NAN inputs this is not the same operation as >.\n// D = VCC in VOPC encoding.\nD[threadId] = !(S0 == S1)',
  VOPCOp.V_CMP_NEQ_F64_E32: '// With NAN inputs this is not the same operation as !=.\n// D = VCC in VOPC encoding.\nD[threadId] = !(S0 < S1)',
  VOPCOp.V_CMP_NLT_F64_E32: '// With NAN inputs this is not the same operation as >=.\n// D = VCC in VOPC encoding.',
  VOPCOp.V_CMP_TRU_F64_E32: 'D[threadId] = 1.\n// D = VCC in VOPC encoding.\nEXEC[threadId] = 0.',
  VOPCOp.V_CMPX_F_F64_E32: 'EXEC[threadId] = (S0 < S1).',
  VOPCOp.V_CMPX_EQ_F64_E32: 'EXEC[threadId] = (S0 == S1).\nEXEC[threadId] = (S0 <= S1).',
  VOPCOp.V_CMPX_GT_F64_E32: 'EXEC[threadId] = (S0 > S1).\nEXEC[threadId] = (S0 <> S1).',
  VOPCOp.V_CMPX_LG_F64_E32: 'EXEC[threadId] = (S0 >= S1).',
  VOPCOp.V_CMPX_GE_F64_E32: 'EXEC[threadId] = (!isNan(S0) && !isNan(S1)).',
  VOPCOp.V_CMPX_O_F64_E32: 'EXEC[threadId] = (isNan(S0)  ||  isNan(S1)).',
  VOPCOp.V_CMPX_NGE_F64_E32: 'EXEC[threadId] = !(S0 >= S1)\n// With NAN inputs this is not the same operation as <.\nEXEC[threadId] = !(S0 <> S1)',
  VOPCOp.V_CMPX_NLG_F64_E32: '// With NAN inputs this is not the same operation as ==.\nEXEC[threadId] = !(S0 > S1)',
  VOPCOp.V_CMPX_NGT_F64_E32: '// With NAN inputs this is not the same operation as <=.\nEXEC[threadId] = !(S0 <= S1)',
  VOPCOp.V_CMPX_NLE_F64_E32: '// With NAN inputs this is not the same operation as >.\nEXEC[threadId] = !(S0 == S1)',
  VOPCOp.V_CMPX_NEQ_F64_E32: '// With NAN inputs this is not the same operation as !=.\nEXEC[threadId] = !(S0 < S1)',
  VOPCOp.V_CMPX_NLT_F64_E32: '// With NAN inputs this is not the same operation as >=.',
  VOPCOp.V_CMPX_TRU_F64_E32: 'EXEC[threadId] = 1.\nD[threadId] = 0.',
  VOPCOp.V_CMP_F_I32_E32: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 < S1).',
  VOPCOp.V_CMP_LT_I32_E32: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 == S1).',
  VOPCOp.V_CMP_EQ_I32_E32: '// D = VCC in VOPC encoding.',
  VOPCOp.V_CMP_LE_I32_E32: 'D[threadId] = (S0 <= S1).\n// D = VCC in VOPC encoding.',
  VOPCOp.V_CMP_GT_I32_E32: 'D[threadId] = (S0 > S1).\n// D = VCC in VOPC encoding.\nD[threadId] = (S0 <> S1).',
  VOPCOp.V_CMP_NE_I32_E32: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 >= S1).',
  VOPCOp.V_CMP_GE_I32_E32: '// D = VCC in VOPC encoding.\nD[threadId] = 1.',
  VOPCOp.V_CMP_T_I32_E32: '// D = VCC in VOPC encoding.',
  VOPCOp.V_CMP_CLASS_F32_E32: 'D[threadId] = (S0 < S1).',
  VOPCOp.V_CMP_LT_I16_E32: '// D = VCC in VOPC encoding.',
  VOPCOp.V_CMP_EQ_I16_E32: 'D[threadId] = (S0 == S1).\n// D = VCC in VOPC encoding.\nD[threadId] = (S0 <= S1).',
  VOPCOp.V_CMP_LE_I16_E32: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 > S1).',
  VOPCOp.V_CMP_GT_I16_E32: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 <> S1).',
  VOPCOp.V_CMP_NE_I16_E32: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 >= S1).',
  VOPCOp.V_CMP_GE_I16_E32: '// D = VCC in VOPC encoding.',
  VOPCOp.V_CMP_CLASS_F16_E32: 'EXEC[threadId] = 0.',
  VOPCOp.V_CMPX_F_I32_E32: 'EXEC[threadId] = (S0 < S1).',
  VOPCOp.V_CMPX_LT_I32_E32: 'EXEC[threadId] = (S0 == S1).',
  VOPCOp.V_CMPX_EQ_I32_E32: 'EXEC[threadId] = (S0 <= S1).',
  VOPCOp.V_CMPX_LE_I32_E32: 'EXEC[threadId] = (S0 > S1).',
  VOPCOp.V_CMPX_GT_I32_E32: 'EXEC[threadId] = (S0 <> S1).',
  VOPCOp.V_CMPX_GE_I32_E32: 'EXEC[threadId] = (S0 >= S1).\nEXEC[threadId] = 1.',
  VOPCOp.V_CMPX_CLASS_F32_E32: 'EXEC[threadId] = (S0 < S1).',
  VOPCOp.V_CMPX_EQ_I16_E32: 'EXEC[threadId] = (S0 == S1).\nEXEC[threadId] = (S0 <= S1).',
  VOPCOp.V_CMPX_LE_I16_E32: 'EXEC[threadId] = (S0 > S1).',
  VOPCOp.V_CMPX_GT_I16_E32: 'EXEC[threadId] = (S0 <> S1).',
  VOPCOp.V_CMPX_NE_I16_E32: 'EXEC[threadId] = (S0 >= S1).',
  VOPCOp.V_CMPX_CLASS_F16_E32: 'D[threadId] = 0.',
  VOPCOp.V_CMP_F_I64_E32: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 < S1).',
  VOPCOp.V_CMP_LT_I64_E32: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 == S1).',
  VOPCOp.V_CMP_EQ_I64_E32: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 <= S1).',
  VOPCOp.V_CMP_LE_I64_E32: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 > S1).',
  VOPCOp.V_CMP_GT_I64_E32: '// D = VCC in VOPC encoding.',
  VOPCOp.V_CMP_NE_I64_E32: 'D[threadId] = (S0 <> S1).\n// D = VCC in VOPC encoding.',
  VOPCOp.V_CMP_GE_I64_E32: 'D[threadId] = (S0 >= S1).\n// D = VCC in VOPC encoding.\nD[threadId] = 1.',
  VOPCOp.V_CMP_T_I64_E32: '// D = VCC in VOPC encoding.',
  VOPCOp.V_CMP_LT_U16_E32: 'D[threadId] = (S0 < S1).\n// D = VCC in VOPC encoding.',
  VOPCOp.V_CMP_EQ_U16_E32: 'D[threadId] = (S0 == S1).\n// D = VCC in VOPC encoding.\nD[threadId] = (S0 <= S1).',
  VOPCOp.V_CMP_LE_U16_E32: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 > S1).',
  VOPCOp.V_CMP_GT_U16_E32: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 <> S1).',
  VOPCOp.V_CMP_NE_U16_E32: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 >= S1).',
  VOPCOp.V_CMP_GE_U16_E32: '// D = VCC in VOPC encoding.\nEXEC[threadId] = 0.',
  VOPCOp.V_CMPX_F_I64_E32: 'EXEC[threadId] = (S0 < S1).',
  VOPCOp.V_CMPX_LT_I64_E32: 'EXEC[threadId] = (S0 == S1).',
  VOPCOp.V_CMPX_LE_I64_E32: 'EXEC[threadId] = (S0 <= S1).\nEXEC[threadId] = (S0 > S1).',
  VOPCOp.V_CMPX_GT_I64_E32: 'EXEC[threadId] = (S0 <> S1).',
  VOPCOp.V_CMPX_NE_I64_E32: 'EXEC[threadId] = (S0 >= S1).',
  VOPCOp.V_CMPX_T_I64_E32: 'EXEC[threadId] = 1.',
  VOPCOp.V_CMPX_CLASS_F64_E32: 'EXEC[threadId] = (S0 < S1).',
  VOPCOp.V_CMPX_LT_U16_E32: 'EXEC[threadId] = (S0 == S1).',
  VOPCOp.V_CMPX_LE_U16_E32: 'EXEC[threadId] = (S0 <= S1).\nEXEC[threadId] = (S0 > S1).',
  VOPCOp.V_CMPX_GT_U16_E32: 'EXEC[threadId] = (S0 <> S1).',
  VOPCOp.V_CMPX_NE_U16_E32: 'EXEC[threadId] = (S0 >= S1).',
  VOPCOp.V_CMPX_GE_U16_E32: 'D[threadId] = 0.',
  VOPCOp.V_CMP_F_U32_E32: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 < S1).',
  VOPCOp.V_CMP_LT_U32_E32: '// D = VCC in VOPC encoding.',
  VOPCOp.V_CMP_EQ_U32_E32: 'D[threadId] = (S0 == S1).\n// D = VCC in VOPC encoding.\nD[threadId] = (S0 <= S1).',
  VOPCOp.V_CMP_LE_U32_E32: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 > S1).',
  VOPCOp.V_CMP_GT_U32_E32: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 <> S1).',
  VOPCOp.V_CMP_NE_U32_E32: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 >= S1).',
  VOPCOp.V_CMP_GE_U32_E32: '// D = VCC in VOPC encoding.\nD[threadId] = 1.',
  VOPCOp.V_CMP_T_U32_E32: '// D = VCC in VOPC encoding.',
  VOPCOp.V_CMP_F_F16_E32: 'D[threadId] = 0.\n// D = VCC in VOPC encoding.',
  VOPCOp.V_CMP_LT_F16_E32: 'D[threadId] = (S0 < S1).\n// D = VCC in VOPC encoding.\nD[threadId] = (S0 == S1).',
  VOPCOp.V_CMP_EQ_F16_E32: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 <= S1).',
  VOPCOp.V_CMP_LE_F16_E32: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 > S1).',
  VOPCOp.V_CMP_GT_F16_E32: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 <> S1).',
  VOPCOp.V_CMP_LG_F16_E32: '// D = VCC in VOPC encoding.',
  VOPCOp.V_CMP_GE_F16_E32: 'D[threadId] = (S0 >= S1).\n// D = VCC in VOPC encoding.',
  VOPCOp.V_CMP_O_F16_E32: 'D[threadId] = (!isNan(S0) && !isNan(S1)).\n// D = VCC in VOPC encoding.\nEXEC[threadId] = 0.',
  VOPCOp.V_CMPX_F_U32_E32: 'EXEC[threadId] = (S0 < S1).',
  VOPCOp.V_CMPX_EQ_U32_E32: 'EXEC[threadId] = (S0 == S1).\nEXEC[threadId] = (S0 <= S1).',
  VOPCOp.V_CMPX_GT_U32_E32: 'EXEC[threadId] = (S0 > S1).\nEXEC[threadId] = (S0 <> S1).',
  VOPCOp.V_CMPX_NE_U32_E32: 'EXEC[threadId] = (S0 >= S1).',
  VOPCOp.V_CMPX_GE_U32_E32: 'EXEC[threadId] = 1.',
  VOPCOp.V_CMPX_T_U32_E32: 'EXEC[threadId] = 0.',
  VOPCOp.V_CMPX_LT_F16_E32: 'EXEC[threadId] = (S0 < S1).\nEXEC[threadId] = (S0 == S1).',
  VOPCOp.V_CMPX_EQ_F16_E32: 'EXEC[threadId] = (S0 <= S1).',
  VOPCOp.V_CMPX_LE_F16_E32: 'EXEC[threadId] = (S0 > S1).',
  VOPCOp.V_CMPX_GT_F16_E32: 'EXEC[threadId] = (S0 <> S1).',
  VOPCOp.V_CMPX_GE_F16_E32: 'EXEC[threadId] = (S0 >= S1).\nEXEC[threadId] = (!isNan(S0) && !isNan(S1)).',
  VOPCOp.V_CMP_F_U64_E32: 'D[threadId] = 0.\n// D = VCC in VOPC encoding.',
  VOPCOp.V_CMP_LT_U64_E32: 'D[threadId] = (S0 < S1).\n// D = VCC in VOPC encoding.\nD[threadId] = (S0 == S1).',
  VOPCOp.V_CMP_EQ_U64_E32: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 <= S1).',
  VOPCOp.V_CMP_LE_U64_E32: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 > S1).',
  VOPCOp.V_CMP_GT_U64_E32: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 <> S1).',
  VOPCOp.V_CMP_NE_U64_E32: '// D = VCC in VOPC encoding.\nD[threadId] = (S0 >= S1).',
  VOPCOp.V_CMP_GE_U64_E32: '// D = VCC in VOPC encoding.\nD[threadId] = 1.',
  VOPCOp.V_CMP_T_U64_E32: '// D = VCC in VOPC encoding.\nD[threadId] = (isNan(S0)  ||  isNan(S1)).',
  VOPCOp.V_CMP_U_F16_E32: '// D = VCC in VOPC encoding.\nD[threadId] = !(S0 >= S1)',
  VOPCOp.V_CMP_NGE_F16_E32: '// With NAN inputs this is not the same operation as <.\n// D = VCC in VOPC encoding.',
  VOPCOp.V_CMP_NLG_F16_E32: 'D[threadId] = !(S0 <> S1)\n// With NAN inputs this is not the same operation as ==.\n// D = VCC in VOPC encoding.\nD[threadId] = !(S0 > S1)',
  VOPCOp.V_CMP_NGT_F16_E32: '// With NAN inputs this is not the same operation as <=.\n// D = VCC in VOPC encoding.\nD[threadId] = !(S0 <= S1)',
  VOPCOp.V_CMP_NLE_F16_E32: '// With NAN inputs this is not the same operation as >.\n// D = VCC in VOPC encoding.\nD[threadId] = !(S0 == S1)',
  VOPCOp.V_CMP_NEQ_F16_E32: '// With NAN inputs this is not the same operation as !=.\n// D = VCC in VOPC encoding.',
  VOPCOp.V_CMP_NLT_F16_E32: 'D[threadId] = !(S0 < S1)\n// With NAN inputs this is not the same operation as >=.\n// D = VCC in VOPC encoding.',
  VOPCOp.V_CMP_TRU_F16_E32: 'D[threadId] = 1.\n// D = VCC in VOPC encoding.\nEXEC[threadId] = 0.',
  VOPCOp.V_CMPX_F_U64_E32: 'EXEC[threadId] = (S0 < S1).',
  VOPCOp.V_CMPX_EQ_U64_E32: 'EXEC[threadId] = (S0 == S1).\nEXEC[threadId] = (S0 <= S1).',
  VOPCOp.V_CMPX_GT_U64_E32: 'EXEC[threadId] = (S0 > S1).\nEXEC[threadId] = (S0 <> S1).',
  VOPCOp.V_CMPX_NE_U64_E32: 'EXEC[threadId] = (S0 >= S1).',
  VOPCOp.V_CMPX_GE_U64_E32: 'EXEC[threadId] = 1.',
  VOPCOp.V_CMPX_T_U64_E32: 'EXEC[threadId] = (isNan(S0)  ||  isNan(S1)).',
  VOPCOp.V_CMPX_NGE_F16_E32: 'EXEC[threadId] = !(S0 >= S1)\n// With NAN inputs this is not the same operation as <.\nEXEC[threadId] = !(S0 <> S1)',
  VOPCOp.V_CMPX_NLG_F16_E32: '// With NAN inputs this is not the same operation as ==.\nEXEC[threadId] = !(S0 > S1)',
  VOPCOp.V_CMPX_NGT_F16_E32: '// With NAN inputs this is not the same operation as <=.\nEXEC[threadId] = !(S0 <= S1)',
  VOPCOp.V_CMPX_NLE_F16_E32: '// With NAN inputs this is not the same operation as >.\nEXEC[threadId] = !(S0 == S1)',
  VOPCOp.V_CMPX_NEQ_F16_E32: '// With NAN inputs this is not the same operation as !=.\nEXEC[threadId] = !(S0 < S1)',
  VOPCOp.V_CMPX_NLT_F16_E32: '// With NAN inputs this is not the same operation as >=.\nEXEC[threadId] = 1.',
}