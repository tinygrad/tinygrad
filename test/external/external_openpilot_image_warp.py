#!/usr/bin/env python
from pathlib import Path
import time
import numpy as np

from tinygrad.tensor import Tensor
from tinygrad.engine.jit import TinyJit
from tinygrad.device import Device


MODEL_WIDTH = 512
MODEL_HEIGHT = 256
MODEL_FRAME_SIZE = MODEL_WIDTH * MODEL_HEIGHT * 3 // 2
IMG_BUFFER_SHAPE = (30, 128, 256)
W, H = 1928, 1208

UV_SCALE_MATRIX = np.array([[0.5, 0, 0], [0, 0.5, 0], [0, 0, 1]], dtype=np.float32)
UV_SCALE_MATRIX_INV = np.linalg.inv(UV_SCALE_MATRIX)


def tensor_arange(end):
    return Tensor([float(i) for i in range(end)])

def tensor_round(tensor):
    return (tensor + 0.5).floor()

def warp_perspective_tinygrad(src, M_inv, dst_shape):
  w_dst, h_dst = dst_shape
  h_src, w_src = src.shape

  x = tensor_arange(w_dst).reshape(1, w_dst).expand(h_dst, w_dst)
  y = tensor_arange(h_dst).reshape(h_dst, 1).expand(h_dst, w_dst)
  ones = Tensor.ones_like(x)
  dst_coords = x.reshape(1, -1).cat(y.reshape(1, -1)).cat(ones.reshape(1, -1))

  src_coords = M_inv @ dst_coords
  src_coords = src_coords / src_coords[2:3, :]
  x_src = src_coords[0].reshape(h_dst, w_dst)
  y_src = src_coords[1].reshape(h_dst, w_dst)

  x_nn_clipped = tensor_round(x_src).clip(0, w_src - 1).cast('int')
  y_nn_clipped = tensor_round(y_src).clip(0, h_src - 1).cast('int')

  idx = (y_nn_clipped * w_src + x_nn_clipped).reshape(-1)

  src_flat = src.reshape(h_src * w_src)
  sampled = src_flat[idx]
  return sampled

def frames_to_tensor(frames):
  H = (frames.shape[0]*2)//3
  W = frames.shape[1]
  in_img1 = Tensor.cat(frames[0:H:2, 0::2],
                        frames[1:H:2, 0::2],
                        frames[0:H:2, 1::2],
                        frames[1:H:2, 1::2],
                        frames[H:H+H//4].reshape((H//2,W//2)),
                        frames[H+H//4:H+H//2].reshape((H//2,W//2)), dim=0).reshape((6, H//2, W//2))
  return in_img1

def frame_prepare_tinygrad(input_frame, M_inv):
  tg_scale = Tensor(UV_SCALE_MATRIX)
  M_inv_uv = tg_scale @ M_inv @ Tensor(UV_SCALE_MATRIX_INV)
  y = warp_perspective_tinygrad(input_frame[:H*W].reshape((H,W)), M_inv, (MODEL_WIDTH, MODEL_HEIGHT))
  u = warp_perspective_tinygrad(input_frame[H*W::2].reshape((H//2,W//2)), M_inv_uv, (MODEL_WIDTH//2, MODEL_HEIGHT//2))
  v = warp_perspective_tinygrad(input_frame[H*W+1::2].reshape((H//2,W//2)), M_inv_uv, (MODEL_WIDTH//2, MODEL_HEIGHT//2))
  yuv = y.cat(u).cat(v).reshape((MODEL_HEIGHT*3//2,MODEL_WIDTH))
  tensor = frames_to_tensor(yuv)
  return tensor

def update_img_input_tinygrad(tensor, frame, M_inv):
  new_img = frame_prepare_tinygrad(frame, M_inv)
  full_buffer = tensor[6:].cat(new_img, dim=0)
  return full_buffer, Tensor.cat(full_buffer[:6], full_buffer[-6:], dim=0)

def update_both_imgs_tinygrad(calib_img_buffer, new_img, M_inv,
                              calib_big_img_buffer, new_big_img, M_inv_big):
  calib_img_buffer, calib_img_pair = update_img_input_tinygrad(calib_img_buffer, new_img, M_inv)
  calib_big_img_buffer, calib_big_img_pair = update_img_input_tinygrad(calib_big_img_buffer, new_big_img, M_inv_big)
  return calib_img_buffer, calib_img_pair, calib_big_img_buffer, calib_big_img_pair

import numpy as np

def warp_perspective_numpy(src, M_inv, dst_shape):
    w_dst, h_dst = dst_shape
    h_src, w_src = src.shape[:2]
    xs, ys = np.meshgrid(np.arange(w_dst), np.arange(h_dst))
    dst_x = xs.reshape(-1)
    dst_y = ys.reshape(-1)

    ones = np.ones_like(xs)
    dst_hom = np.stack([xs, ys, ones], axis=0).reshape(3, -1)

    src_hom = M_inv @ dst_hom 
    src_hom /= src_hom[2:3, :]

    src_x = np.clip(np.round(src_hom[0, :]).astype(int), 0, w_src - 1)
    src_y = np.clip(np.round(src_hom[1, :]).astype(int), 0, h_src - 1)

    dst = np.zeros((h_dst, w_dst), dtype=src.dtype)
    dst[dst_y, dst_x] = src[src_y, src_x]
    return dst.ravel()

def frames_to_tensor_np(frames):
  H = (frames.shape[0]*2)//3
  W = frames.shape[1]
  p1 = frames[0:H:2, 0::2]
  p2 = frames[1:H:2, 0::2]
  p3 = frames[0:H:2, 1::2]
  p4 = frames[1:H:2, 1::2]
  p5 = frames[H:H+H//4].reshape((H//2, W//2))
  p6 = frames[H+H//4:H+H//2].reshape((H//2, W//2))
  return np.concatenate([p1, p2, p3, p4, p5, p6], axis=0)\
           .reshape((6, H//2, W//2))

def frame_prepare_np(input_frame, M_inv):
  M_inv_uv = UV_SCALE_MATRIX @ M_inv @ UV_SCALE_MATRIX_INV
  y  = warp_perspective_numpy(input_frame[:H*W].reshape(H, W),
                                 M_inv, (MODEL_WIDTH, MODEL_HEIGHT))
  u  = warp_perspective_numpy(input_frame[H*W::2].reshape(H//2, W//2),
                                 M_inv_uv, (MODEL_WIDTH//2, MODEL_HEIGHT//2))
  v  = warp_perspective_numpy(input_frame[H*W+1::2].reshape(H//2, W//2),
                                 M_inv_uv, (MODEL_WIDTH//2, MODEL_HEIGHT//2))
  yuv = np.concatenate([y, u, v]).reshape( MODEL_HEIGHT*3//2, MODEL_WIDTH)
  return frames_to_tensor_np(yuv)

def update_img_input_np(tensor, frame, M_inv):
  tensor[:-6]  = tensor[6:]
  tensor[-6:] = frame_prepare_np(frame, M_inv)
  return tensor, np.concatenate([tensor[:6], tensor[-6:]], axis=0)

def update_both_imgs_np(calib_img_buffer, new_img, M_inv,
                        calib_big_img_buffer, new_big_img, M_inv_big):
  calib_img_buffer, calib_img_pair = update_img_input_np(calib_img_buffer, new_img, M_inv)
  calib_big_img_buffer, calib_big_img_pair = update_img_input_np(calib_big_img_buffer, new_big_img, M_inv_big)
  return calib_img_buffer, calib_img_pair, calib_big_img_buffer, calib_big_img_pair

if __name__ == "__main__":
  update_img_jit = TinyJit(update_both_imgs_tinygrad, prune=True)

  full_buffer = Tensor.zeros(IMG_BUFFER_SHAPE, dtype='uint8').realize()
  big_full_buffer = Tensor.zeros(IMG_BUFFER_SHAPE, dtype='uint8').realize()
  full_buffer_np = np.zeros(IMG_BUFFER_SHAPE, dtype=np.uint8)
  big_full_buffer_np = np.zeros(IMG_BUFFER_SHAPE, dtype=np.uint8)

  # run 20 times
  step_times = []
  for _ in range(20):
    
    # make inputs
    img_inputs = [full_buffer, (32*Tensor.randn(W*H*3//2) + 128).cast(dtype='uint8').realize(), Tensor.randn(3,3).realize()]
    big_img_inputs = [big_full_buffer, (32*Tensor.randn(W*H*3//2) + 128).cast(dtype='uint8').realize(), Tensor.randn(3,3).realize()]
    inputs = img_inputs + big_img_inputs
    Device.default.synchronize()
    inputs_np = [x.numpy() for x in inputs]
    inputs_np[0] = full_buffer_np
    inputs_np[3] = big_full_buffer_np
    
    # do warp
    st = time.perf_counter()
    out = update_img_jit(*inputs)
    full_buffer = out[0]
    big_full_buffer = out[2]
    mt = time.perf_counter()
    Device.default.synchronize()
    et = time.perf_counter()
    step_times.append((et-st)*1e3)
    print(f"enqueue {(mt-st)*1e3:6.2f} ms -- total run {step_times[-1]:6.2f} ms")
    out_np = update_both_imgs_np(*inputs_np)
    full_buffer_np = out_np[0]
    big_full_buffer_np = out_np[2]

    for a, b in zip(out_np, (x.numpy() for x in out)):
      mismatch = np.abs(a - b) > 0
      mismatch_percent = sum(mismatch.flatten()) / len(mismatch.flatten()) * 100
      mismatch_percent_tol = 1e-2
      assert mismatch_percent < mismatch_percent_tol, f"input mismatch percent {mismatch_percent} exceeds tolerance {mismatch_percent_tol}"