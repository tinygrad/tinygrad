from extra.assembly.amd.autogen.rdna4.ins import *
from extra.assembly.amd.dsl import RawImm

N = 4096

def ds_load_b64(vdst, addr, offset1=0):
  return VDS(op=DSOp.DS_LOAD_B64, vdst=vdst, addr=addr, offset0=0, offset1=offset1)
def ds_load_b128(vdst, addr, offset0=0, offset1=0):
  return VDS(op=DSOp.DS_LOAD_B128, vdst=vdst, addr=addr, offset0=offset0, offset1=offset1)
def ds_store_b32(addr, data0, offset1=0):
  return VDS(op=DSOp.DS_STORE_B32, addr=addr, data0=data0, offset0=0, offset1=offset1)
def ds_store_b64(addr, data0, offset1=0):
  return VDS(op=DSOp.DS_STORE_B64, addr=addr, data0=data0, offset0=0, offset1=offset1)
def ds_store_b128(addr, data0, offset0=0, offset1=0):
  return VDS(op=DSOp.DS_STORE_B128, addr=addr, data0=data0, offset0=offset0, offset1=offset1)
def buffer_load_b32(vdata, vaddr, rsrc):
  return VBUFFER(op=VBUFFEROp.BUFFER_LOAD_B32, vdata=vdata, vaddr=vaddr, rsrc=RawImm(rsrc), soffset=NULL, offen=1, format=1)
def buffer_load_b128(vdata, vaddr, rsrc):
  return VBUFFER(op=VBUFFEROp.BUFFER_LOAD_B128, vdata=vdata, vaddr=vaddr, rsrc=RawImm(rsrc), soffset=NULL, offen=1, format=1)
def buffer_store_b64(vdata, vaddr, rsrc):
  return VBUFFER(op=VBUFFEROp.BUFFER_STORE_B64, vdata=vdata, vaddr=vaddr, rsrc=rsrc, soffset=NULL, offen=1, format=1)
def barrier_signal():
  return SOP1(op=SOP1Op.S_BARRIER_SIGNAL, sdst=RawImm(0), ssrc0=RawImm(193))

insts = [
  "kernel_entry:",
  s_mov_b32(s[2], ttmp[9]),
  s_and_b32(s[3], 0xffff, ttmp[7]),
  s_lshr_b32(s[4], ttmp[7], 16),
  s_load_b64(sdata=s[28:29], sbase=s[0:1], ioffset=0x0, soffset=RawImm(124)),
  s_load_b64(sdata=s[32:33], sbase=s[0:1], ioffset=0x10, soffset=RawImm(124)),
  s_load_b64(sdata=s[34:35], sbase=s[0:1], ioffset=0x8, soffset=RawImm(124)),
  s_waitcnt(simm16=64519),
  s_mov_b32(s[20], 1),
  s_mov_b32(s[21], 0),
  s_mov_b32(s[22], 0x2200001),
  s_mov_b32(s[11], 0x8010008),
  s_mov_b32(s[23], 0x400),
  s_mov_b32(s[24], 0x1000),
  s_mov_b32(s[25], 0x1000),
  s_mov_b32(s[26], 1),
  s_mov_b32(s[27], 0x1000),
  s_mov_b32(s[36], N),
  s_mov_b32(s[37], 0),
  s_mov_b32(s[38], 0x1000),
  s_mov_b32(s[39], 0),
  s_mov_b32(s[40], 0x1000),
  s_mov_b32(s[41], 0),
  s_mov_b32(s[42], 0x1000),
  s_and_b32(s[10], s[22], 0xffff0000),
  s_lshr_b32(s[10], s[10], 16),
  s_and_b32(s[46], s[22], 0xffff),
  s_mov_b32(s[5], s[21]),
  s_mov_b32(M0, 0x4400),
  v_mov_b32_e32(v[254], v[0]),
  s_mov_b32(VCC_HI, 0),
  s_lshr_b32(s[52], s[11], 16),
  s_ctz_i32_b32(s[52], s[52]),
  s_lshr_b32(s[53], s[11], 22),
  s_cmp_gt_i32(s[52], 0),
  s_cmp_eq_u32(s[21], 0),
  v_and_b32_e32(v[1], 31, v[254]),
  v_and_b32_e32(v[0], 15, v[1]),
  v_lshlrev_b32_e32(v[0], 2, v[0]),
  v_lshrrev_b32_e32(v[1], 4, v[1]),
  v_lshl_add_u32(v[0], v[1], 10, v[0]),
  v_lshrrev_b32_e32(v[4], 5, v[254]),
  v_and_b32_e32(v[4], 1, v[4]),
  v_lshl_add_u32(v[0], v[4], 6, v[0]),
  v_and_b32_e32(v[2], 31, v[254]),
  v_and_b32_e32(v[1], 15, v[2]),
  v_lshlrev_b32_e32(v[1], 5, v[1]),
  v_lshlrev_b32_e32(v[1], 2, v[1]),
  v_lshrrev_b32_e32(v[2], 4, v[2]),
  v_lshl_add_u32(v[1], v[2], 3, v[1]),
  v_lshrrev_b32_e32(v[3], 6, v[254]),
  v_and_b32_e32(v[3], 1, v[3]),
  v_lshl_add_u32(v[1], v[3], 11, v[1]),
  v_lshrrev_b32_e32(v[2], 5, v[254]),
  v_lshrrev_b32_e32(v[2], 2, v[2]),
  s_mov_b32(s[16], 0x1000),
  v_mul_lo_u32(v[2], s[16], v[2]),
  v_add_lshl_u32(v[138], v[2], v[0], 1),
  v_lshrrev_b32_e32(v[0], 5, v[254]),
  v_lshrrev_b32_e32(v[0], 2, v[0]),
  s_mov_b32(s[16], 32),
  v_mul_lo_u32(v[0], s[16], v[0]),
  v_add_lshl_u32(v[139], v[0], v[1], 1),
  v_lshrrev_b32_e32(v[2], 8, v[139]),
  v_lshl_add_u32(v[139], v[2], 5, v[139]),
  v_add_co_u32(v[139], VCC_LO, 0x2000, v[139]),
  v_lshrrev_b32_e32(v[1], 4, v[254]),
  v_and_b32_e32(v[0], 15, v[254]),
  v_lshlrev_b32_e32(v[0], 3, v[0]),
  v_mov_b32_e32(v[4], v[1]),
  v_lshrrev_b32_e32(v[2], 2, v[254]),
  v_and_b32_e32(v[3], 3, v[254]),
  v_lshlrev_b32_e32(v[3], 3, v[3]),
  v_mov_b32_e32(v[5], v[3]),
  v_mul_u32_u24_e32(v[136], 0x80, v[4]),
  v_add_lshl_u32(v[136], v[0], v[136], 1),
  v_mul_u32_u24_e32(v[137], 32, v[2]),
  v_add_lshl_u32(v[137], v[5], v[137], 1),
  v_lshrrev_b32_e32(v[6], 8, v[137]),
  v_lshl_add_u32(v[137], v[6], 5, v[137]),
  v_add_co_u32(v[137], VCC_LO, 0x2000, v[137]),
  s_wait_kmcnt(0x0),
  v_mov_b32_e32(v[8], 0x80),
  v_mov_b32_e32(v[7], s[24]),
  v_cvt_f32_u32_e32(v[6], v[8]),
  v_rcp_iflag_f32_e32(v[6], v[6]),
  v_cvt_f32_u32_e32(v[9], v[7]),
  v_mul_f32_e32(v[6], v[6], v[9]),
  v_cvt_u32_f32_e32(v[6], v[6]),
  v_mul_u32_u24_e32(v[9], v[6], v[8]),
  v_sub_nc_u32_e32(v[9], v[7], v[9]),
  v_cmp_ne_u32_e64(RawImm(106), v[9], 0),
  v_add_co_ci_u32(v[6], VCC_LO, v[6], 0, VCC_LO),
  v_mov_b32_e32(v[8], 0x80),
  v_mov_b32_e32(v[7], s[25]),
  v_readfirstlane_b32_e32(RawImm(14), v[6]),
  v_cvt_f32_u32_e32(v[6], v[8]),
  v_rcp_iflag_f32_e32(v[6], v[6]),
  v_cvt_f32_u32_e32(v[9], v[7]),
  v_mul_f32_e32(v[6], v[6], v[9]),
  v_cvt_u32_f32_e32(v[6], v[6]),
  v_mul_u32_u24_e32(v[9], v[6], v[8]),
  v_sub_nc_u32_e32(v[9], v[7], v[9]),
  v_cmp_ne_u32_e64(RawImm(106), v[9], 0),
  v_add_co_ci_u32(v[6], VCC_LO, v[6], 0, VCC_LO),
  v_readfirstlane_b32_e32(RawImm(15), v[6]),
  s_mul_i32(s[16], s[14], s[15]),
  s_and_b32(s[17], s[46], 0x3fff),
  s_mul_i32(s[16], s[16], s[17]),
  v_cvt_f32_u32_e32(v[6], s[16]),
  v_rcp_iflag_f32_e32(v[6], v[6]),
  v_cvt_f32_u32_e32(v[7], s[2]),
  v_mul_f32_e32(v[6], v[6], v[7]),
  v_cvt_u32_f32_e32(v[6], v[6]),
  v_mul_u32_u24_e64(v[7], v[6], s[16]),
  v_sub_nc_u32_e32(v[7], s[2], v[7]),
  v_cmp_eq_u32_e64(RawImm(106), v[7], s[16]),
  s_mov_b32(EXEC_LO, VCC_LO),
  v_add_nc_u32_e32(v[6], 1, v[6]),
  s_mov_b32(EXEC_LO, -1),
  v_cmp_gt_u32_e64(RawImm(106), v[7], s[16]),
  s_mov_b32(EXEC_LO, VCC_LO),
  v_sub_nc_u32_e64(v[6], v[6], 1),
  s_mov_b32(EXEC_LO, -1),
  v_readfirstlane_b32_e32(RawImm(16), v[6]),
  s_mov_b32(s[4], s[16]),
  s_mul_i32(s[16], s[15], s[14]),
  s_mul_i32(s[16], s[16], s[4]),
  s_mul_i32(s[16], s[16], s[17]),
  s_sub_co_u32(s[2], s[2], s[16]),
  v_cvt_f32_u32_e32(v[6], s[14]),
  v_rcp_iflag_f32_e32(v[6], v[6]),
  v_cvt_f32_u32_e32(v[7], s[2]),
  v_mul_f32_e32(v[6], v[6], v[7]),
  v_cvt_u32_f32_e32(v[6], v[6]),
  v_mul_u32_u24_e64(v[7], v[6], s[14]),
  v_sub_nc_u32_e32(v[7], s[2], v[7]),
  v_cmp_eq_u32_e64(RawImm(106), v[7], s[14]),
  s_mov_b32(EXEC_LO, VCC_LO),
  v_add_nc_u32_e32(v[6], 1, v[6]),
  s_mov_b32(EXEC_LO, -1),
  v_cmp_gt_u32_e64(RawImm(106), v[7], s[14]),
  s_mov_b32(EXEC_LO, VCC_LO),
  v_sub_nc_u32_e64(v[6], v[6], 1),
  s_mov_b32(EXEC_LO, -1),
  v_readfirstlane_b32_e32(RawImm(16), v[6]),
  s_mov_b32(s[3], s[16]),
  s_mul_i32(s[16], s[3], s[14]),
  s_sub_co_u32(s[2], s[2], s[16]),
  s_mov_b32(s[66], 0x5040100),
  s_mov_b32(s[67], 0x7060302),
  s_sub_co_u32(s[32], s[32], 16),
  s_sub_co_ci_u32(s[33], s[33], 0),
  s_sub_co_u32(s[34], s[34], 16),
  s_sub_co_ci_u32(s[35], s[35], 0),
  s_and_b32(s[16], s[46], 0x3fff),
  s_cmp_eq_u32(s[16], 1),
  s_mov_b64(s[6:7], 0),
  s_mov_b32(s[8], 1),
  s_mov_b32(s[9], 1),
  s_mov_b32(s[16], s[11]),
  s_sext_i32_i16(s[16], s[16]),
  s_cmp_gt_i32(s[16], 1),
  s_mov_b32(s[16], s[16]),
  v_cvt_f64_u32_e32(v[6:7], s[16]),
  v_rcp_f64_e32(v[6:7], v[6:7]),
  v_cvt_f64_u32_e32(v[8:9], s[3]),
  v_mul_f64_e32(v[6:7], v[6:7], v[8:9]),
  v_cvt_u32_f64_e32(v[6], v[6:7]),
  v_mul_lo_u32(v[7], v[6], s[16]),
  v_sub_nc_u32_e32(v[8], s[3], v[7]),
  v_cmp_ge_u32_e64(RawImm(106), v[8], s[16]),
  s_mov_b32(EXEC_LO, VCC_LO),
  v_add_nc_u32_e64(v[6], v[6], 1),
  s_mov_b32(EXEC_LO, -1),
  v_readfirstlane_b32_e32(RawImm(17), v[6]),
  s_mul_i32(s[20], s[17], s[16]),
  s_sub_co_u32(s[20], s[3], s[20]),
  s_mul_i32(s[20], s[20], s[14]),
  s_add_co_u32(s[20], s[20], s[2]),
  v_cvt_f64_u32_e32(v[6:7], s[16]),
  v_rcp_f64_e32(v[6:7], v[6:7]),
  v_cvt_f64_u32_e32(v[8:9], s[15]),
  v_mul_f64_e32(v[6:7], v[6:7], v[8:9]),
  v_cvt_u32_f64_e32(v[6], v[6:7]),
  v_mul_lo_u32(v[7], v[6], s[16]),
  v_sub_nc_u32_e32(v[8], s[15], v[7]),
  v_cmp_ge_u32_e64(RawImm(106), v[8], s[16]),
  s_mov_b32(EXEC_LO, VCC_LO),
  v_add_nc_u32_e64(v[6], v[6], 1),
  s_mov_b32(EXEC_LO, -1),
  v_readfirstlane_b32_e32(RawImm(18), v[6]),
  s_mul_i32(s[19], s[16], s[18]),
  s_sub_co_u32(s[19], s[15], s[19]),
  s_cmp_eq_u32(s[19], 0),
  s_cmov_b32(s[19], s[16]),
  s_cmp_ge_u32(s[17], s[18]),
  s_cselect_b32(s[18], s[19], s[16]),
  v_cvt_f64_u32_e32(v[6:7], s[18]),
  v_rcp_f64_e32(v[6:7], v[6:7]),
  v_cvt_f64_u32_e32(v[8:9], s[20]),
  v_mul_f64_e32(v[6:7], v[6:7], v[8:9]),
  v_cvt_u32_f64_e32(v[6], v[6:7]),
  v_mul_lo_u32(v[7], v[6], s[18]),
  v_sub_nc_u32_e32(v[8], s[20], v[7]),
  v_cmp_ge_u32_e64(RawImm(106), v[8], s[18]),
  s_mov_b32(EXEC_LO, VCC_LO),
  v_add_nc_u32_e64(v[6], v[6], 1),
  s_mov_b32(EXEC_LO, -1),
  v_mul_lo_u32(v[7], v[6], s[18]),
  v_sub_nc_u32_e32(v[8], s[20], v[7]),
  v_readfirstlane_b32_e32(RawImm(2), v[6]),
  v_readfirstlane_b32_e32(RawImm(3), v[8]),
  s_mul_i32(s[3], s[2], s[18]),
  s_sub_co_u32(s[3], s[20], s[3]),
  s_mul_i32(s[17], s[17], s[16]),
  s_add_co_u32(s[3], s[3], s[17]),
  v_mov_b32_e32(v[6], v[0]),
  v_mov_b32_e32(v[7], v[2]),
  v_add_co_u32(v[8], VCC_LO, 32, v[7]),
  v_add_co_u32(v[9], VCC_LO, 32, v[8]),
  v_add_co_u32(v[10], VCC_LO, 32, v[9]),
  v_mov_b32_e32(v[11], v[1]),
  v_add_co_u32(v[12], VCC_LO, 8, v[11]),
  v_add_co_u32(v[13], VCC_LO, 8, v[12]),
  v_add_co_u32(v[14], VCC_LO, 8, v[13]),
  v_mov_b32_e32(v[15], v[3]),
  s_mul_i32(s[16], s[2], 0x80),
  s_sub_co_u32(s[16], s[24], s[16]),
  s_sub_co_u32(s[16], s[16], 8),
  v_mov_b32_e32(v[16], s[16]),
  v_min_i32_e32(v[6], v[16], v[6]),
  s_mul_hi_u32(s[19], s[2], 0x80),
  s_mul_i32(s[18], s[2], 0x80),
  s_and_b32(s[16], s[46], 0x8000),
  s_cbranch_scc1("skip_gsu_offset_A"),
  s_mul_hi_u32(s[17], 32, s[6]),
  s_mul_i32(s[16], 32, s[6]),
  "skip_gsu_offset_A:",
  s_mul_hi_u32(s[17], s[16], s[40]),
  s_mul_i32(s[16], s[16], s[40]),
  s_add_co_u32(s[18], s[18], s[16]),
  s_add_co_ci_u32(s[19], s[19], s[17]),
  s_mov_b64(s[56:57], 1),
  s_sub_co_u32(s[16], s[24], 1),
  s_mul_hi_u32(s[17], 1, s[16]),
  s_mul_i32(s[16], 1, s[16]),
  s_add_co_u32(s[56], s[56], s[16]),
  s_add_co_ci_u32(s[57], s[57], s[17]),
  s_sub_co_u32(s[16], s[27], 1),
  s_mul_hi_u32(s[17], s[40], s[16]),
  s_mul_i32(s[16], s[40], s[16]),
  s_add_co_u32(s[56], s[56], s[16]),
  s_add_co_ci_u32(s[57], s[57], s[17]),
  s_sub_co_u32(s[56], s[56], s[18]),
  s_sub_co_ci_u32(s[57], s[57], s[19]),
  s_lshl_b64(s[56:57], s[56:57], 1),
  s_add_co_u32(s[56], s[56], 16),
  s_add_co_ci_u32(s[57], s[57], 0),
  s_cmp_eq_u32(s[57], 0),
  s_cselect_b32(s[50], s[56], -1),
  s_mul_hi_u32(s[17], s[41], s[4]),
  s_mul_i32(s[16], s[41], s[4]),
  s_add_co_u32(s[18], s[18], s[16]),
  s_add_co_ci_u32(s[19], s[19], s[17]),
  s_lshl_b64(s[18:19], s[18:19], 1),
  s_add_co_u32(s[48], s[32], s[18]),
  s_add_co_ci_u32(s[49], s[33], s[19]),
  s_mov_b32(s[51], 0x30020000),
  s_mul_hi_u32(s[19], s[3], 0x80),
  s_mul_i32(s[18], s[3], 0x80),
  s_mul_hi_u32(s[19], s[18], s[42]),
  s_mul_i32(s[18], s[18], s[42]),
  s_and_b32(s[16], s[46], 0x8000),
  s_cbranch_scc1("skip_gsu_offset_B"),
  s_mul_hi_u32(s[17], 32, s[6]),
  s_mul_i32(s[16], 32, s[6]),
  "skip_gsu_offset_B:",
  s_add_co_u32(s[18], s[18], s[16]),
  s_add_co_ci_u32(s[19], s[19], s[17]),
  s_mov_b64(s[58:59], 1),
  s_sub_co_u32(s[16], s[27], 1),
  s_mul_hi_u32(s[17], 1, s[16]),
  s_mul_i32(s[16], 1, s[16]),
  s_add_co_u32(s[58], s[58], s[16]),
  s_add_co_ci_u32(s[59], s[59], s[17]),
  s_sub_co_u32(s[16], s[25], 1),
  s_mul_hi_u32(s[17], s[42], s[16]),
  s_mul_i32(s[16], s[42], s[16]),
  s_add_co_u32(s[58], s[58], s[16]),
  s_add_co_ci_u32(s[59], s[59], s[17]),
  s_sub_co_u32(s[58], s[58], s[18]),
  s_sub_co_ci_u32(s[59], s[59], s[19]),
  s_lshl_b64(s[58:59], s[58:59], 1),
  s_add_co_u32(s[58], s[58], 16),
  s_add_co_ci_u32(s[59], s[59], 0),
  s_cmp_eq_u32(s[59], 0),
  s_cselect_b32(s[54], s[58], -1),
  s_mov_b32(s[17], 0),
  s_mov_b32(s[16], 0),
  s_add_co_u32(s[18], s[18], s[16]),
  s_add_co_ci_u32(s[19], s[19], s[17]),
  s_lshl_b64(s[18:19], s[18:19], 1),
  s_add_co_u32(s[52], s[34], s[18]),
  s_add_co_ci_u32(s[53], s[35], s[19]),
  s_mov_b32(s[55], 0x30020000),
  v_mul_lo_u32(v[16], s[40], v[11]),
  v_add_co_u32(v[128], VCC_LO, v[6], v[16]),
  v_add_nc_u32_e32(v[128], 8, v[128]),
  v_lshlrev_b32_e32(v[128], 1, v[128]),
  v_mul_lo_u32(v[16], s[40], v[12]),
  v_add_co_u32(v[129], VCC_LO, v[6], v[16]),
  v_add_nc_u32_e32(v[129], 8, v[129]),
  v_lshlrev_b32_e32(v[129], 1, v[129]),
  v_mul_lo_u32(v[16], s[40], v[13]),
  v_add_co_u32(v[130], VCC_LO, v[6], v[16]),
  v_add_nc_u32_e32(v[130], 8, v[130]),
  v_lshlrev_b32_e32(v[130], 1, v[130]),
  v_mul_lo_u32(v[16], s[40], v[14]),
  v_add_co_u32(v[131], VCC_LO, v[6], v[16]),
  v_add_nc_u32_e32(v[131], 8, v[131]),
  v_lshlrev_b32_e32(v[131], 1, v[131]),
  v_mul_lo_u32(v[11], s[42], v[7]),
  v_add_co_u32(v[132], VCC_LO, v[15], v[11]),
  v_add_nc_u32_e32(v[132], 8, v[132]),
  v_lshlrev_b32_e32(v[132], 1, v[132]),
  v_mul_lo_u32(v[11], s[42], v[8]),
  v_add_co_u32(v[133], VCC_LO, v[15], v[11]),
  v_add_nc_u32_e32(v[133], 8, v[133]),
  v_lshlrev_b32_e32(v[133], 1, v[133]),
  v_mul_lo_u32(v[11], s[42], v[9]),
  v_add_co_u32(v[134], VCC_LO, v[15], v[11]),
  v_add_nc_u32_e32(v[134], 8, v[134]),
  v_lshlrev_b32_e32(v[134], 1, v[134]),
  v_mul_lo_u32(v[11], s[42], v[10]),
  v_add_co_u32(v[135], VCC_LO, v[15], v[11]),
  v_add_nc_u32_e32(v[135], 8, v[135]),
  v_lshlrev_b32_e32(v[135], 1, v[135]),
  s_and_b32(s[17], s[46], 0x3fff),
  s_mul_i32(s[17], s[17], 64),
  s_and_b32(s[16], s[46], 0x8000),
  s_cmov_b32(s[17], 64),
  s_mul_i32(s[64], s[17], s[40]),
  s_and_b32(s[17], s[46], 0x3fff),
  s_mul_i32(s[17], s[17], 64),
  s_and_b32(s[16], s[46], 0x8000),
  s_cselect_b32(s[65], 64, s[17]),
  s_lshr_b32(s[12], s[27], 5),
  s_and_b32(s[16], s[46], 0x3fff),
  s_cmp_eq_u32(s[16], 1),
  s_mov_b32(s[13], s[12]),
  s_and_b32(s[18], s[10], 0x1f00),
  s_lshr_b32(s[18], s[18], 8),
  s_and_b32(s[19], s[10], 0xe000),
  s_and_b32(s[10], s[10], 0xff),
  s_mov_b32(s[16], s[10]),
  s_lshl_b32(s[17], s[16], s[18]),
  s_cmp_ge_u32(s[13], s[17]),
  s_sub_co_u32(s[17], s[16], 1),
  s_cmp_ge_u32(s[16], 1),
  s_cselect_b32(s[47], s[17], 0),
  s_cmp_eq_u32(s[19], 0),
  s_cmp_eq_u32(s[19], 0x2000),
  s_cbranch_scc1("stagger_done"),
  s_mov_b32(s[16], s[3]),
  "stagger_done:",
  s_and_b32(s[47], s[47], s[16]),
  s_lshl_b32(s[47], s[47], s[18]),
  s_mul_hi_i32(s[17], s[47], s[64]),
  s_mul_i32(s[16], s[47], s[64]),
  s_mul_hi_i32(s[61], s[12], s[64]),
  s_mul_i32(s[60], s[12], s[64]),
  s_sub_co_u32(s[60], s[64], s[60]),
  s_sub_co_ci_u32(s[61], 0, s[61]),
  s_add_co_u32(s[48], s[48], s[16]),
  s_add_co_ci_u32(s[49], s[49], s[17]),
  s_sub_co_u32(s[56], s[56], s[16]),
  s_sub_co_ci_u32(s[57], s[57], s[17]),
  s_cmp_eq_u32(s[57], 0),
  s_cselect_b32(s[50], s[56], -1),
  s_mul_hi_i32(s[17], s[47], s[65]),
  s_mul_i32(s[16], s[47], s[65]),
  s_mul_hi_i32(s[63], s[12], s[65]),
  s_mul_i32(s[62], s[12], s[65]),
  s_sub_co_u32(s[62], s[65], s[62]),
  s_sub_co_ci_u32(s[63], 0, s[63]),
  s_add_co_u32(s[52], s[52], s[16]),
  s_add_co_ci_u32(s[53], s[53], s[17]),
  s_sub_co_u32(s[58], s[58], s[16]),
  s_sub_co_ci_u32(s[59], s[59], s[17]),
  s_cmp_eq_u32(s[59], 0),
  s_cselect_b32(s[54], s[58], -1),
  s_add_co_u32(s[47], s[47], 2),
  s_cmp_eq_u32(s[12], 0),
  s_cbranch_scc1("skip_first_prefetch"),
  # Prefetch A matrix tiles (4 loads from rsrc=48)
  *[buffer_load_b128(v[222+i*4:226+i*4], v[128+i], 48) for i in range(4)],
  # Prefetch B matrix tiles (4 loads from rsrc=52)
  *[buffer_load_b128(v[238+i*4:242+i*4], v[132+i], 52) for i in range(4)],
  s_add_co_u32(s[18], s[12], 1),
  s_cmp_eq_u32(s[47], s[18]),
  s_cselect_b32(s[16], s[60], s[64]),
  s_cselect_b32(s[17], s[61], 0),
  s_add_co_u32(s[48], s[48], s[16]),
  s_add_co_ci_u32(s[49], s[49], s[17]),
  s_sub_co_u32(s[56], s[56], s[16]),
  s_sub_co_ci_u32(s[57], s[57], s[17]),
  s_cmp_eq_u32(s[57], 0),
  s_cselect_b32(s[50], s[56], -1),
  s_add_co_u32(s[18], s[12], 1),
  s_cmp_eq_u32(s[47], s[18]),
  s_cselect_b32(s[16], s[62], s[65]),
  s_cselect_b32(s[17], s[63], 0),
  s_add_co_u32(s[52], s[52], s[16]),
  s_add_co_ci_u32(s[53], s[53], s[17]),
  s_sub_co_u32(s[58], s[58], s[16]),
  s_sub_co_ci_u32(s[59], s[59], s[17]),
  s_cmp_eq_u32(s[59], 0),
  s_cselect_b32(s[54], s[58], -1),
  "skip_first_prefetch:",
  s_mov_b64(s[16:17], s[28:29]),
  s_mov_b32(s[18], 0x80000000),
  s_mov_b32(s[19], 0x30020000),
  s_mov_b64(s[20:21], s[30:31]),
  s_mov_b32(s[22], 0x80000000),
  s_mov_b32(s[23], 0x30020000),
  s_mul_i32(s[70], 0x80, s[3]),
  s_mul_hi_u32(s[69], s[70], s[38]),
  s_mul_i32(s[68], s[70], s[38]),
  s_lshl_b64(s[68:69], s[68:69], s[8]),
  s_add_co_u32(s[20], s[30], s[68]),
  s_add_co_ci_u32(s[21], s[31], s[69]),
  s_mul_hi_u32(s[69], s[70], s[36]),
  s_mul_i32(s[68], s[70], s[36]),
  s_lshl_b64(s[68:69], s[68:69], s[9]),
  s_add_co_u32(s[16], s[28], s[68]),
  s_add_co_ci_u32(s[17], s[29], s[69]),
  s_mul_hi_u32(s[69], s[4], s[39]),
  s_mul_i32(s[68], s[4], s[39]),
  s_lshl_b64(s[68:69], s[68:69], s[8]),
  s_add_co_u32(s[20], s[20], s[68]),
  s_add_co_ci_u32(s[21], s[21], s[69]),
  s_mul_hi_u32(s[69], s[4], s[37]),
  s_mul_i32(s[68], s[4], s[37]),
  s_lshl_b64(s[68:69], s[68:69], s[9]),
  s_add_co_u32(s[16], s[16], s[68]),
  s_add_co_ci_u32(s[17], s[17], s[69]),
  s_and_b32(s[68], s[46], 0x3fff),
  s_cmp_eq_u32(s[68], 1),
  # Zero initialize accumulators v[0:127]
  *[v_mov_b32_e32(v[i], 0) for i in range(128)],
  s_wait_loadcnt(0x0),
  ds_store_b128(v[136], v[222:225], offset1=0),
  ds_store_b128(v[136], v[226:229], offset1=8),
  ds_store_b128(v[136], v[230:233], offset1=16),
  ds_store_b128(v[136], v[234:237], offset1=24),
  ds_store_b128(v[137], v[238:241], offset1=0),
  ds_store_b128(v[137], v[242:245], offset1=9),
  ds_store_b128(v[137], v[246:249], offset1=18),
  ds_store_b128(v[137], v[250:253], offset1=27),
  s_cmp_eq_u32(s[12], 1),
  s_cbranch_scc1("skip_prefetch_2"),
  # Prefetch A matrix tiles (4 loads from rsrc=48)
  *[buffer_load_b128(v[222+i*4:226+i*4], v[128+i], 48) for i in range(4)],
  # Prefetch B matrix tiles (4 loads from rsrc=52)
  *[buffer_load_b128(v[238+i*4:242+i*4], v[132+i], 52) for i in range(4)],
  "skip_prefetch_2:",
  s_wait_dscnt(0x0),
  barrier_signal(),
  s_barrier_wait(0xffff),
  # Load A tile from LDS: 8x b64 loads
  *[ds_load_b64(v[156+i*2:158+i*2], v[138], offset1=i) for i in range(8)],
  # Load B tile from LDS: 4x b128 loads
  *[ds_load_b128(v[189+i*4:193+i*4], v[139], offset0=i*64) for i in range(4)],
  s_cmp_eq_u32(s[12], 1),
  s_cbranch_scc1("final_wmma"),
  s_cmp_le_u32(s[12], 2),
  s_cbranch_scc1("loop_epilogue"),
  s_nop(0),
  "main_loop:",
  s_wait_dscnt(0x3),
  v_perm_b32(v[140], v[158], v[156], s[66]),
  v_perm_b32(v[141], v[162], v[160], s[66]),
  v_perm_b32(v[142], v[166], v[164], s[66]),
  v_perm_b32(v[143], v[170], v[168], s[66]),
  v_perm_b32(v[144], v[158], v[156], s[67]),
  v_perm_b32(v[145], v[162], v[160], s[67]),
  v_wmma_f32_16x16x16_f16(v[0:7], v[189:192], v[140:143], v[0:7]),
  ds_load_b64(v[172:173], v[138], offset1=16),
  ds_load_b64(v[174:175], v[138], offset1=17),
  s_cmp_eq_u32(s[12], s[47]),
  s_cselect_b32(s[68], s[60], s[64]),
  s_cselect_b32(s[69], s[61], 0),
  v_perm_b32(v[146], v[166], v[164], s[67]),
  v_perm_b32(v[147], v[170], v[168], s[67]),
  v_perm_b32(v[148], v[159], v[157], s[66]),
  v_perm_b32(v[149], v[163], v[161], s[66]),
  v_wmma_f32_16x16x16_f16(v[8:15], v[189:192], v[144:147], v[8:15]),
  ds_load_b64(v[176:177], v[138], offset1=18),
  ds_load_b64(v[178:179], v[138], offset1=19),
  s_add_co_u32(s[48], s[48], s[68]),
  s_add_co_ci_u32(s[49], s[49], s[69]),
  s_sub_co_u32(s[56], s[56], s[68]),
  v_perm_b32(v[150], v[167], v[165], s[66]),
  v_perm_b32(v[151], v[171], v[169], s[66]),
  v_perm_b32(v[152], v[159], v[157], s[67]),
  v_perm_b32(v[153], v[163], v[161], s[67]),
  v_wmma_f32_16x16x16_f16(v[16:23], v[189:192], v[148:151], v[16:23]),
  ds_load_b64(v[180:181], v[138], offset1=20),
  ds_load_b64(v[182:183], v[138], offset1=21),
  s_sub_co_ci_u32(s[57], s[57], s[69]),
  s_cmp_eq_u32(s[57], 0),
  s_cselect_b32(s[50], s[56], -1),
  v_perm_b32(v[154], v[167], v[165], s[67]),
  v_perm_b32(v[155], v[171], v[169], s[67]),
  s_nop(1),
  v_wmma_f32_16x16x16_f16(v[24:31], v[189:192], v[152:155], v[24:31]),
  ds_load_b64(v[184:185], v[138], offset1=22),
  ds_load_b64(v[186:187], v[138], offset1=23),
  s_cmp_eq_u32(s[12], s[47]),
  s_cselect_b32(s[68], s[62], s[65]),
  s_cselect_b32(s[69], s[63], 0),
  s_wait_dscnt(0x8),
  v_wmma_f32_16x16x16_f16(v[32:39], v[193:196], v[140:143], v[32:39]),
  ds_load_b128(v[205:208], v[139], offset0=32),
  s_add_co_u32(s[52], s[52], s[68]),
  s_add_co_ci_u32(s[53], s[53], s[69]),
  s_sub_co_u32(s[58], s[58], s[68]),
  v_wmma_f32_16x16x16_f16(v[40:47], v[193:196], v[144:147], v[40:47]),
  ds_load_b128(v[209:212], v[139], offset0=96),
  s_sub_co_ci_u32(s[59], s[59], s[69]),
  s_cmp_eq_u32(s[59], 0),
  s_cselect_b32(s[54], s[58], -1),
  v_wmma_f32_16x16x16_f16(v[48:55], v[193:196], v[148:151], v[48:55]),
  ds_load_b128(v[213:216], v[139], offset0=160),
  v_wmma_f32_16x16x16_f16(v[56:63], v[193:196], v[152:155], v[56:63]),
  ds_load_b128(v[217:220], v[139], offset0=224),
  v_wmma_f32_16x16x16_f16(v[64:71], v[197:200], v[140:143], v[64:71]),
  v_wmma_f32_16x16x16_f16(v[72:79], v[197:200], v[144:147], v[72:79]),
  v_wmma_f32_16x16x16_f16(v[80:87], v[197:200], v[148:151], v[80:87]),
  v_wmma_f32_16x16x16_f16(v[88:95], v[197:200], v[152:155], v[88:95]),
  v_wmma_f32_16x16x16_f16(v[96:103], v[201:204], v[140:143], v[96:103]),
  s_wait_dscnt(0x0),
  barrier_signal(),
  s_barrier_wait(0xffff),
  v_wmma_f32_16x16x16_f16(v[104:111], v[201:204], v[144:147], v[104:111]),
  s_wait_loadcnt(0x7),
  ds_store_b128(v[136], v[222:225], offset1=0),
  buffer_load_b128(v[222:225], v[128], 48),
  s_wait_loadcnt(0x7),
  ds_store_b128(v[136], v[226:229], offset1=8),
  v_wmma_f32_16x16x16_f16(v[112:119], v[201:204], v[148:151], v[112:119]),
  buffer_load_b128(v[226:229], v[129], 48),
  s_wait_loadcnt(0x7),
  ds_store_b128(v[136], v[230:233], offset1=16),
  buffer_load_b128(v[230:233], v[130], 48),
  v_wmma_f32_16x16x16_f16(v[120:127], v[201:204], v[152:155], v[120:127]),
  s_wait_loadcnt(0x7),
  ds_store_b128(v[136], v[234:237], offset1=24),
  buffer_load_b128(v[234:237], v[131], 48),
  s_wait_loadcnt(0x7),
  ds_store_b128(v[137], v[238:241], offset1=0),
  s_wait_dscnt(0x5),
  v_perm_b32(v[140], v[174], v[172], s[66]),
  v_perm_b32(v[141], v[178], v[176], s[66]),
  v_perm_b32(v[142], v[182], v[180], s[66]),
  v_perm_b32(v[143], v[186], v[184], s[66]),
  v_perm_b32(v[144], v[174], v[172], s[67]),
  v_perm_b32(v[145], v[178], v[176], s[67]),
  v_wmma_f32_16x16x16_f16(v[0:7], v[205:208], v[140:143], v[0:7]),
  buffer_load_b128(v[238:241], v[132], 52),
  s_wait_loadcnt(0x7),
  ds_store_b128(v[137], v[242:245], offset1=9),
  buffer_load_b128(v[242:245], v[133], 52),
  v_perm_b32(v[146], v[182], v[180], s[67]),
  v_perm_b32(v[147], v[186], v[184], s[67]),
  v_perm_b32(v[148], v[175], v[173], s[66]),
  v_perm_b32(v[149], v[179], v[177], s[66]),
  v_wmma_f32_16x16x16_f16(v[8:15], v[205:208], v[144:147], v[8:15]),
  s_wait_loadcnt(0x7),
  ds_store_b128(v[137], v[246:249], offset1=18),
  buffer_load_b128(v[246:249], v[134], 52),
  s_wait_loadcnt(0x7),
  ds_store_b128(v[137], v[250:253], offset1=27),
  v_perm_b32(v[150], v[183], v[181], s[66]),
  v_perm_b32(v[151], v[187], v[185], s[66]),
  v_perm_b32(v[152], v[175], v[173], s[67]),
  v_perm_b32(v[153], v[179], v[177], s[67]),
  v_wmma_f32_16x16x16_f16(v[16:23], v[205:208], v[148:151], v[16:23]),
  buffer_load_b128(v[250:253], v[135], 52),
  v_perm_b32(v[154], v[183], v[181], s[67]),
  v_perm_b32(v[155], v[187], v[185], s[67]),
  s_nop(1),
  v_wmma_f32_16x16x16_f16(v[24:31], v[205:208], v[152:155], v[24:31]),
  v_wmma_f32_16x16x16_f16(v[32:39], v[209:212], v[140:143], v[32:39]),
  s_wait_dscnt(0x0),
  barrier_signal(),
  s_barrier_wait(0xffff),
  v_wmma_f32_16x16x16_f16(v[40:47], v[209:212], v[144:147], v[40:47]),
  ds_load_b64(v[156:157], v[138], offset1=0),
  ds_load_b64(v[158:159], v[138], offset1=1),
  v_wmma_f32_16x16x16_f16(v[48:55], v[209:212], v[148:151], v[48:55]),
  ds_load_b64(v[160:161], v[138], offset1=2),
  ds_load_b64(v[162:163], v[138], offset1=3),
  v_wmma_f32_16x16x16_f16(v[56:63], v[209:212], v[152:155], v[56:63]),
  ds_load_b64(v[164:165], v[138], offset1=4),
  ds_load_b64(v[166:167], v[138], offset1=5),
  v_wmma_f32_16x16x16_f16(v[64:71], v[213:216], v[140:143], v[64:71]),
  ds_load_b64(v[168:169], v[138], offset1=6),
  ds_load_b64(v[170:171], v[138], offset1=7),
  v_wmma_f32_16x16x16_f16(v[72:79], v[213:216], v[144:147], v[72:79]),
  ds_load_b128(v[189:192], v[139], offset0=0),
  v_wmma_f32_16x16x16_f16(v[80:87], v[213:216], v[148:151], v[80:87]),
  ds_load_b128(v[193:196], v[139], offset0=64),
  v_wmma_f32_16x16x16_f16(v[88:95], v[213:216], v[152:155], v[88:95]),
  ds_load_b128(v[197:200], v[139], offset0=128),
  v_wmma_f32_16x16x16_f16(v[96:103], v[217:220], v[140:143], v[96:103]),
  ds_load_b128(v[201:204], v[139], offset0=192),
  v_wmma_f32_16x16x16_f16(v[104:111], v[217:220], v[144:147], v[104:111]),
  v_wmma_f32_16x16x16_f16(v[112:119], v[217:220], v[148:151], v[112:119]),
  v_wmma_f32_16x16x16_f16(v[120:127], v[217:220], v[152:155], v[120:127]),
  s_sub_co_u32(s[12], s[12], 1),
  s_cmp_eq_i32(s[12], 2),
  s_cbranch_scc0("main_loop"),
  "loop_epilogue:",
  s_wait_dscnt(0x3),
  v_perm_b32(v[140], v[158], v[156], s[66]),
  v_perm_b32(v[141], v[162], v[160], s[66]),
  v_perm_b32(v[142], v[166], v[164], s[66]),
  v_perm_b32(v[143], v[170], v[168], s[66]),
  v_perm_b32(v[144], v[158], v[156], s[67]),
  v_perm_b32(v[145], v[162], v[160], s[67]),
  v_wmma_f32_16x16x16_f16(v[0:7], v[189:192], v[140:143], v[0:7]),
  ds_load_b64(v[172:173], v[138], offset1=16),
  ds_load_b64(v[174:175], v[138], offset1=17),
  s_cmp_eq_u32(s[12], s[47]),
  s_cselect_b32(s[68], s[60], s[64]),
  s_cselect_b32(s[69], s[61], 0),
  v_perm_b32(v[146], v[166], v[164], s[67]),
  v_perm_b32(v[147], v[170], v[168], s[67]),
  v_perm_b32(v[148], v[159], v[157], s[66]),
  v_perm_b32(v[149], v[163], v[161], s[66]),
  v_wmma_f32_16x16x16_f16(v[8:15], v[189:192], v[144:147], v[8:15]),
  ds_load_b64(v[176:177], v[138], offset1=18),
  ds_load_b64(v[178:179], v[138], offset1=19),
  s_add_co_u32(s[48], s[48], s[68]),
  s_add_co_ci_u32(s[49], s[49], s[69]),
  s_sub_co_u32(s[56], s[56], s[68]),
  v_perm_b32(v[150], v[167], v[165], s[66]),
  v_perm_b32(v[151], v[171], v[169], s[66]),
  v_perm_b32(v[152], v[159], v[157], s[67]),
  v_perm_b32(v[153], v[163], v[161], s[67]),
  v_wmma_f32_16x16x16_f16(v[16:23], v[189:192], v[148:151], v[16:23]),
  ds_load_b64(v[180:181], v[138], offset1=20),
  ds_load_b64(v[182:183], v[138], offset1=21),
  s_sub_co_ci_u32(s[57], s[57], s[69]),
  s_cmp_eq_u32(s[57], 0),
  s_cselect_b32(s[50], s[56], -1),
  v_perm_b32(v[154], v[167], v[165], s[67]),
  v_perm_b32(v[155], v[171], v[169], s[67]),
  s_nop(1),
  v_wmma_f32_16x16x16_f16(v[24:31], v[189:192], v[152:155], v[24:31]),
  ds_load_b64(v[184:185], v[138], offset1=22),
  ds_load_b64(v[186:187], v[138], offset1=23),
  s_cmp_eq_u32(s[12], s[47]),
  s_cselect_b32(s[68], s[62], s[65]),
  s_cselect_b32(s[69], s[63], 0),
  s_wait_dscnt(0x8),
  v_wmma_f32_16x16x16_f16(v[32:39], v[193:196], v[140:143], v[32:39]),
  ds_load_b128(v[205:208], v[139], offset0=32),
  s_add_co_u32(s[52], s[52], s[68]),
  s_add_co_ci_u32(s[53], s[53], s[69]),
  s_sub_co_u32(s[58], s[58], s[68]),
  v_wmma_f32_16x16x16_f16(v[40:47], v[193:196], v[144:147], v[40:47]),
  ds_load_b128(v[209:212], v[139], offset0=96),
  s_sub_co_ci_u32(s[59], s[59], s[69]),
  s_cmp_eq_u32(s[59], 0),
  s_cselect_b32(s[54], s[58], -1),
  v_wmma_f32_16x16x16_f16(v[48:55], v[193:196], v[148:151], v[48:55]),
  ds_load_b128(v[213:216], v[139], offset0=160),
  v_wmma_f32_16x16x16_f16(v[56:63], v[193:196], v[152:155], v[56:63]),
  ds_load_b128(v[217:220], v[139], offset0=224),
  v_wmma_f32_16x16x16_f16(v[64:71], v[197:200], v[140:143], v[64:71]),
  v_wmma_f32_16x16x16_f16(v[72:79], v[197:200], v[144:147], v[72:79]),
  v_wmma_f32_16x16x16_f16(v[80:87], v[197:200], v[148:151], v[80:87]),
  v_wmma_f32_16x16x16_f16(v[88:95], v[197:200], v[152:155], v[88:95]),
  v_wmma_f32_16x16x16_f16(v[96:103], v[201:204], v[140:143], v[96:103]),
  s_wait_dscnt(0x0),
  barrier_signal(),
  s_barrier_wait(0xffff),
  v_wmma_f32_16x16x16_f16(v[104:111], v[201:204], v[144:147], v[104:111]),
  s_wait_loadcnt(0x7),
  ds_store_b128(v[136], v[222:225], offset1=0),
  s_wait_loadcnt(0x6),
  ds_store_b128(v[136], v[226:229], offset1=8),
  v_wmma_f32_16x16x16_f16(v[112:119], v[201:204], v[148:151], v[112:119]),
  s_wait_loadcnt(0x5),
  ds_store_b128(v[136], v[230:233], offset1=16),
  v_wmma_f32_16x16x16_f16(v[120:127], v[201:204], v[152:155], v[120:127]),
  s_wait_loadcnt(0x4),
  ds_store_b128(v[136], v[234:237], offset1=24),
  s_wait_loadcnt(0x3),
  ds_store_b128(v[137], v[238:241], offset1=0),
  s_wait_dscnt(0x5),
  v_perm_b32(v[140], v[174], v[172], s[66]),
  v_perm_b32(v[141], v[178], v[176], s[66]),
  v_perm_b32(v[142], v[182], v[180], s[66]),
  v_perm_b32(v[143], v[186], v[184], s[66]),
  v_perm_b32(v[144], v[174], v[172], s[67]),
  v_perm_b32(v[145], v[178], v[176], s[67]),
  v_wmma_f32_16x16x16_f16(v[0:7], v[205:208], v[140:143], v[0:7]),
  s_wait_loadcnt(0x2),
  ds_store_b128(v[137], v[242:245], offset1=9),
  v_perm_b32(v[146], v[182], v[180], s[67]),
  v_perm_b32(v[147], v[186], v[184], s[67]),
  v_perm_b32(v[148], v[175], v[173], s[66]),
  v_perm_b32(v[149], v[179], v[177], s[66]),
  v_wmma_f32_16x16x16_f16(v[8:15], v[205:208], v[144:147], v[8:15]),
  s_wait_loadcnt(0x1),
  ds_store_b128(v[137], v[246:249], offset1=18),
  s_wait_loadcnt(0x0),
  ds_store_b128(v[137], v[250:253], offset1=27),
  v_perm_b32(v[150], v[183], v[181], s[66]),
  v_perm_b32(v[151], v[187], v[185], s[66]),
  v_perm_b32(v[152], v[175], v[173], s[67]),
  v_perm_b32(v[153], v[179], v[177], s[67]),
  v_wmma_f32_16x16x16_f16(v[16:23], v[205:208], v[148:151], v[16:23]),
  v_perm_b32(v[154], v[183], v[181], s[67]),
  v_perm_b32(v[155], v[187], v[185], s[67]),
  s_nop(1),
  v_wmma_f32_16x16x16_f16(v[24:31], v[205:208], v[152:155], v[24:31]),
  v_wmma_f32_16x16x16_f16(v[32:39], v[209:212], v[140:143], v[32:39]),
  s_wait_dscnt(0x0),
  barrier_signal(),
  s_barrier_wait(0xffff),
  v_wmma_f32_16x16x16_f16(v[40:47], v[209:212], v[144:147], v[40:47]),
  ds_load_b64(v[156:157], v[138], offset1=0),
  ds_load_b64(v[158:159], v[138], offset1=1),
  v_wmma_f32_16x16x16_f16(v[48:55], v[209:212], v[148:151], v[48:55]),
  ds_load_b64(v[160:161], v[138], offset1=2),
  ds_load_b64(v[162:163], v[138], offset1=3),
  v_wmma_f32_16x16x16_f16(v[56:63], v[209:212], v[152:155], v[56:63]),
  ds_load_b64(v[164:165], v[138], offset1=4),
  ds_load_b64(v[166:167], v[138], offset1=5),
  v_wmma_f32_16x16x16_f16(v[64:71], v[213:216], v[140:143], v[64:71]),
  ds_load_b64(v[168:169], v[138], offset1=6),
  ds_load_b64(v[170:171], v[138], offset1=7),
  v_wmma_f32_16x16x16_f16(v[72:79], v[213:216], v[144:147], v[72:79]),
  ds_load_b128(v[189:192], v[139], offset0=0),
  v_wmma_f32_16x16x16_f16(v[80:87], v[213:216], v[148:151], v[80:87]),
  ds_load_b128(v[193:196], v[139], offset0=64),
  v_wmma_f32_16x16x16_f16(v[88:95], v[213:216], v[152:155], v[88:95]),
  ds_load_b128(v[197:200], v[139], offset0=128),
  v_wmma_f32_16x16x16_f16(v[96:103], v[217:220], v[140:143], v[96:103]),
  ds_load_b128(v[201:204], v[139], offset0=192),
  v_wmma_f32_16x16x16_f16(v[104:111], v[217:220], v[144:147], v[104:111]),
  v_wmma_f32_16x16x16_f16(v[112:119], v[217:220], v[148:151], v[112:119]),
  v_wmma_f32_16x16x16_f16(v[120:127], v[217:220], v[152:155], v[120:127]),
  "final_wmma:",
  s_wait_dscnt(0x3),
  v_perm_b32(v[140], v[158], v[156], s[66]),
  v_perm_b32(v[141], v[162], v[160], s[66]),
  v_perm_b32(v[142], v[166], v[164], s[66]),
  v_perm_b32(v[143], v[170], v[168], s[66]),
  v_perm_b32(v[144], v[158], v[156], s[67]),
  v_perm_b32(v[145], v[162], v[160], s[67]),
  v_wmma_f32_16x16x16_f16(v[0:7], v[189:192], v[140:143], v[0:7]),
  ds_load_b64(v[172:173], v[138], offset1=16),
  ds_load_b64(v[174:175], v[138], offset1=17),
  v_perm_b32(v[146], v[166], v[164], s[67]),
  v_perm_b32(v[147], v[170], v[168], s[67]),
  v_perm_b32(v[148], v[159], v[157], s[66]),
  v_perm_b32(v[149], v[163], v[161], s[66]),
  v_wmma_f32_16x16x16_f16(v[8:15], v[189:192], v[144:147], v[8:15]),
  ds_load_b64(v[176:177], v[138], offset1=18),
  ds_load_b64(v[178:179], v[138], offset1=19),
  v_perm_b32(v[150], v[167], v[165], s[66]),
  v_perm_b32(v[151], v[171], v[169], s[66]),
  v_perm_b32(v[152], v[159], v[157], s[67]),
  v_perm_b32(v[153], v[163], v[161], s[67]),
  v_wmma_f32_16x16x16_f16(v[16:23], v[189:192], v[148:151], v[16:23]),
  ds_load_b64(v[180:181], v[138], offset1=20),
  ds_load_b64(v[182:183], v[138], offset1=21),
  v_perm_b32(v[154], v[167], v[165], s[67]),
  v_perm_b32(v[155], v[171], v[169], s[67]),
  s_nop(1),
  v_wmma_f32_16x16x16_f16(v[24:31], v[189:192], v[152:155], v[24:31]),
  ds_load_b64(v[184:185], v[138], offset1=22),
  ds_load_b64(v[186:187], v[138], offset1=23),
  s_wait_dscnt(0x8),
  v_wmma_f32_16x16x16_f16(v[32:39], v[193:196], v[140:143], v[32:39]),
  ds_load_b128(v[205:208], v[139], offset0=32),
  v_wmma_f32_16x16x16_f16(v[40:47], v[193:196], v[144:147], v[40:47]),
  ds_load_b128(v[209:212], v[139], offset0=96),
  v_wmma_f32_16x16x16_f16(v[48:55], v[193:196], v[148:151], v[48:55]),
  ds_load_b128(v[213:216], v[139], offset0=160),
  v_wmma_f32_16x16x16_f16(v[56:63], v[193:196], v[152:155], v[56:63]),
  ds_load_b128(v[217:220], v[139], offset0=224),
  v_wmma_f32_16x16x16_f16(v[64:71], v[197:200], v[140:143], v[64:71]),
  v_wmma_f32_16x16x16_f16(v[72:79], v[197:200], v[144:147], v[72:79]),
  v_wmma_f32_16x16x16_f16(v[80:87], v[197:200], v[148:151], v[80:87]),
  v_wmma_f32_16x16x16_f16(v[88:95], v[197:200], v[152:155], v[88:95]),
  v_wmma_f32_16x16x16_f16(v[96:103], v[201:204], v[140:143], v[96:103]),
  v_wmma_f32_16x16x16_f16(v[104:111], v[201:204], v[144:147], v[104:111]),
  s_wait_dscnt(0x0),
  barrier_signal(),
  s_barrier_wait(0xffff),
  v_wmma_f32_16x16x16_f16(v[112:119], v[201:204], v[148:151], v[112:119]),
  v_wmma_f32_16x16x16_f16(v[120:127], v[201:204], v[152:155], v[120:127]),
  s_wait_dscnt(0x0),
  v_perm_b32(v[140], v[174], v[172], s[66]),
  v_perm_b32(v[141], v[178], v[176], s[66]),
  v_perm_b32(v[142], v[182], v[180], s[66]),
  v_perm_b32(v[143], v[186], v[184], s[66]),
  v_perm_b32(v[144], v[174], v[172], s[67]),
  v_perm_b32(v[145], v[178], v[176], s[67]),
  v_wmma_f32_16x16x16_f16(v[0:7], v[205:208], v[140:143], v[0:7]),
  v_perm_b32(v[146], v[182], v[180], s[67]),
  v_perm_b32(v[147], v[186], v[184], s[67]),
  v_perm_b32(v[148], v[175], v[173], s[66]),
  v_perm_b32(v[149], v[179], v[177], s[66]),
  v_wmma_f32_16x16x16_f16(v[8:15], v[205:208], v[144:147], v[8:15]),
  v_perm_b32(v[150], v[183], v[181], s[66]),
  v_perm_b32(v[151], v[187], v[185], s[66]),
  v_perm_b32(v[152], v[175], v[173], s[67]),
  v_perm_b32(v[153], v[179], v[177], s[67]),
  v_wmma_f32_16x16x16_f16(v[16:23], v[205:208], v[148:151], v[16:23]),
  v_perm_b32(v[154], v[183], v[181], s[67]),
  v_perm_b32(v[155], v[187], v[185], s[67]),
  s_nop(1),
  v_wmma_f32_16x16x16_f16(v[24:31], v[205:208], v[152:155], v[24:31]),
  v_wmma_f32_16x16x16_f16(v[32:39], v[209:212], v[140:143], v[32:39]),
  v_wmma_f32_16x16x16_f16(v[40:47], v[209:212], v[144:147], v[40:47]),
  v_wmma_f32_16x16x16_f16(v[48:55], v[209:212], v[148:151], v[48:55]),
  v_wmma_f32_16x16x16_f16(v[56:63], v[209:212], v[152:155], v[56:63]),
  v_wmma_f32_16x16x16_f16(v[64:71], v[213:216], v[140:143], v[64:71]),
  v_wmma_f32_16x16x16_f16(v[72:79], v[213:216], v[144:147], v[72:79]),
  v_wmma_f32_16x16x16_f16(v[80:87], v[213:216], v[148:151], v[80:87]),
  v_wmma_f32_16x16x16_f16(v[88:95], v[213:216], v[152:155], v[88:95]),
  v_wmma_f32_16x16x16_f16(v[96:103], v[217:220], v[140:143], v[96:103]),
  v_wmma_f32_16x16x16_f16(v[104:111], v[217:220], v[144:147], v[104:111]),
  v_wmma_f32_16x16x16_f16(v[112:119], v[217:220], v[148:151], v[112:119]),
  v_wmma_f32_16x16x16_f16(v[120:127], v[217:220], v[152:155], v[120:127]),
  s_load_b256(sdata=s[48:55], sbase=s[0:1], ioffset=0x58, soffset=RawImm(124)),
  s_load_b32(sdata=s[56], sbase=s[0:1], ioffset=0x78, soffset=RawImm(124)),
  # calculate address
  v_lshrrev_b32_e32(v[132], 5, v[254]),
  v_lshrrev_b32_e32(v[133], 1, v[132]),
  v_mul_lo_u32(v[133], 16, v[133]),
  v_and_b32_e32(v[129], 31, v[254]),
  v_lshrrev_b32_e32(v[129], 4, v[129]),
  v_lshlrev_b32_e32(v[129], 3, v[129]),
  v_add_lshl_u32(v[129], v[133], v[129], 2),
  v_mul_lo_u32(v[130], v[129], s[38]),
  v_mul_lo_u32(v[131], v[129], s[36]),
  v_and_b32_e32(v[128], 1, v[132]),
  v_mul_lo_u32(v[128], 16, v[128]),
  v_and_b32_e32(v[133], 15, v[254]),
  s_mul_i32(s[8], 0x80, s[2]),
  v_add_lshl_u32(v[128], v[133], v[128], 2),
  v_add_nc_u32_e32(v[128], s[8], v[128]),
  v_add_lshl_u32(v[137], v[131], v[128], 1),
  barrier_signal(),
  s_barrier_wait(0xffff),
]

# final stores

ptr, tmpv = 16, 140
vaddr = v[137]
bases = (0, 32, 64, 96)
row_pairs = ((0, 1), (2, 3), (4, 5), (6, 7))

first = True
for a, b in row_pairs:
  insts += [s_nop(0), s_wait_dscnt(0x0)]
  # even row then odd row, for each base
  for r in (a, b):
    for base in bases:
      # advance the ptr SGPR
      if not first: insts += [s_add_co_u32(s[ptr], s[ptr], N << 1), s_add_co_ci_u32(s[ptr+1], s[ptr+1], 0)]
      first = False
      # pack 4 fp16s
      acc4 = [v[base+r], v[base+r+8], v[base+r+16], v[base+r+24]]
      insts += [
        v_cvt_f16_f32_e64(acc4[0], acc4[0]),
        v_cvt_f16_f32_e64(acc4[1], acc4[1]),
        v_pack_b32_f16(v[tmpv+0], acc4[0], acc4[1]),
        v_cvt_f16_f32_e64(acc4[2], acc4[2]),
        v_cvt_f16_f32_e64(acc4[3], acc4[3]),
        v_pack_b32_f16(v[tmpv+1], acc4[2], acc4[3]),
      ]
      insts.append(buffer_store_b64(v[tmpv:tmpv+1], vaddr, ptr))

insts.append(s_endpgm())
