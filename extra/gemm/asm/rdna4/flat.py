import pathlib
import numpy as np
from tinygrad import Device, dtypes
from tinygrad.uop.ops import UOp, Ops, KernelInfo

from extra.assembly.amd.autogen.rdna4.ins import *
from extra.gemm.amd_uop_matmul import N, test_matmul

# tiny hsaco packer
import tempfile, subprocess, os
def pack_hsaco(src:str, arch:str) -> bytes:
  with tempfile.TemporaryDirectory() as d:
    s,o,h = [os.path.join(d,x) for x in ("k.s","k.o","k.hsaco")]
    open(s,"w").write(src)
    subprocess.check_call(["llvm-mc","-triple=amdgcn-amd-amdhsa",f"-mcpu={arch}","-mattr=+real-true16","-filetype=obj",s,"-o",o])
    subprocess.check_call(["ld.lld","-shared","-m","elf64_amdgpu",o,"-o",h])
    return open(h,"rb").read()

# 2Ã—2 wave-level tiling of a 128Ã—128 workgroup C tile, where each wave computes a 64Ã—64 sub-tile using WMMA
N = 4096
WAVE_BLOCK = 2         # 2 wave ping pong
WAVE_TILE = 64         # each wave computes 64Ã—64 tile
K_TILE = 32            # K dimension tile size (2 WMMA iterations of 16)
TILE_GROUP_HEIGHT = 8  # rows of tiles processed together for better cache locality
C_TILE = WAVE_TILE * WAVE_BLOCK
TN = (N + C_TILE - 1) // C_TILE
NUM_WG = TN * TN
THREADS_PER_WG = 128
assert N % THREADS_PER_WG == 0, "N must be divisible by THREADS_PER_WG"

def custom_gemm(N:int, dev:str) -> UOp:
  lidx = UOp.special(THREADS_PER_WG, "lidx0")
  gidx = UOp.special(NUM_WG, "gidx0")

  A = UOp.placeholder((N*N,), dtypes.half, slot=1)
  B = UOp.placeholder((N*N,), dtypes.half, slot=2)
  C = UOp.placeholder((N*N,), dtypes.half, slot=0)

  insts = [
  "kernel_entry:",
  s_mov_b32(s[2], ttmp[9]),
  s_and_b32(s[3], 0xffff, ttmp[7]),
  s_lshr_b32(s[4], ttmp[7], 16),
  s_load_b64(sdata=s[28:29], sbase=s[0:1], ioffset=0x0, soffset=NULL),
  s_load_b64(sdata=s[32:33], sbase=s[0:1], ioffset=0x10, soffset=NULL),
  s_load_b64(sdata=s[34:35], sbase=s[0:1], ioffset=0x8, soffset=NULL),
  s_waitcnt(simm16=64519),
  s_mov_b32(s[27], N),
  s_mov_b32(M0, 0x4400),
  v_mov_b32_e32(v[254], v[0]),
  s_mov_b32(VCC_HI, 0),
  v_and_b32_e32(v[1], 31, v[254]),
  v_and_b32_e32(v[0], 15, v[1]),
  v_lshlrev_b32_e32(v[0], 2, v[0]),
  v_lshrrev_b32_e32(v[1], 4, v[1]),
  v_lshl_add_u32(v[0], v[1], 10, v[0]),
  v_lshrrev_b32_e32(v[4], 5, v[254]),
  v_and_b32_e32(v[4], 1, v[4]),
  v_lshl_add_u32(v[0], v[4], 6, v[0]),
  v_and_b32_e32(v[2], 31, v[254]),
  v_and_b32_e32(v[1], 15, v[2]),
  v_lshlrev_b32_e32(v[1], 5, v[1]),
  v_lshlrev_b32_e32(v[1], 2, v[1]),
  v_lshrrev_b32_e32(v[2], 4, v[2]),
  v_lshl_add_u32(v[1], v[2], 3, v[1]),
  v_lshrrev_b32_e32(v[3], 6, v[254]),
  v_and_b32_e32(v[3], 1, v[3]),
  v_lshl_add_u32(v[1], v[3], 11, v[1]),
  v_lshrrev_b32_e32(v[2], 5, v[254]),
  v_lshrrev_b32_e32(v[2], 2, v[2]),
  s_mov_b32(s[16], 0x1000),
  v_mul_lo_u32(v[2], s[16], v[2]),
  v_add_lshl_u32(v[138], v[2], v[0], 1),
  v_lshrrev_b32_e32(v[0], 5, v[254]),
  v_lshrrev_b32_e32(v[0], 2, v[0]),
  s_mov_b32(s[16], 32),
  v_mul_lo_u32(v[0], s[16], v[0]),
  v_add_lshl_u32(v[139], v[0], v[1], 1),
  v_lshrrev_b32_e32(v[2], 8, v[139]),
  v_lshl_add_u32(v[139], v[2], 5, v[139]),
  v_add_co_u32(v[139], VCC_LO, 0x2000, v[139]),
  v_lshrrev_b32_e32(v[1], 4, v[254]),
  v_and_b32_e32(v[0], 15, v[254]),
  v_lshlrev_b32_e32(v[0], 3, v[0]),
  v_mov_b32_e32(v[4], v[1]),
  v_lshrrev_b32_e32(v[2], 2, v[254]),
  v_and_b32_e32(v[3], 3, v[254]),
  v_lshlrev_b32_e32(v[3], 3, v[3]),
  v_mov_b32_e32(v[5], v[3]),
  v_mul_u32_u24_e32(v[136], C_TILE, v[4]),
  v_add_lshl_u32(v[136], v[0], v[136], 1),
  v_mul_u32_u24_e32(v[137], 32, v[2]),
  v_add_lshl_u32(v[137], v[5], v[137], 1),
  v_lshrrev_b32_e32(v[6], 8, v[137]),
  v_lshl_add_u32(v[137], v[6], 5, v[137]),
  v_add_co_u32(v[137], VCC_LO, 0x2000, v[137]),
  s_wait_kmcnt(0x0),
  s_lshr_b32(s[14], s[27], 7),
  s_mov_b32(s[15], s[14]),
  s_mul_i32(s[16], s[14], s[15]),
  s_lshr_b32(s[4], s[2], 10),
  s_and_b32(s[2], s[2], 1023),
  s_lshr_b32(s[3], s[2], 5),
  s_and_b32(s[2], s[2], 31),
  s_mov_b32(s[66], 0x5040100),
  s_mov_b32(s[67], 0x7060302),
  s_sub_co_u32(s[32], s[32], 16),
  s_sub_co_ci_u32(s[33], s[33], 0),
  s_sub_co_u32(s[34], s[34], 16),
  s_sub_co_ci_u32(s[35], s[35], 0),
  s_mov_b32(s[8], 1),
  s_mov_b32(s[9], 1),
  s_mov_b32(s[16], TILE_GROUP_HEIGHT),
  s_lshr_b32(s[17], s[3], 3),
  s_and_b32(s[20], s[3], 7),
  s_mul_i32(s[20], s[17], s[16]),
  s_sub_co_u32(s[20], s[3], s[20]),
  s_mul_i32(s[20], s[20], s[14]),
  s_add_co_u32(s[20], s[20], s[2]),
  s_lshr_b32(s[18], s[15], 3),
  s_mul_i32(s[19], s[16], s[18]),
  s_sub_co_u32(s[19], s[15], s[19]),
  s_cmp_eq_u32(s[19], 0),
  s_cmov_b32(s[19], s[16]),
  s_cmp_ge_u32(s[17], s[18]),
  s_cselect_b32(s[18], s[19], s[16]),
  s_lshr_b32(s[2], s[20], 3),
  s_and_b32(s[3], s[20], 7),
  s_mul_i32(s[17], s[17], s[16]),
  s_add_co_u32(s[3], s[3], s[17]),
  v_dual_mov_b32(VOPDOp.V_DUAL_MOV_B32, v[6], v[7], v[0], v[2]),
  v_add_co_u32(v[8], VCC_LO, 32, v[7]),
  v_add_co_u32(v[9], VCC_LO, 32, v[8]),
  v_add_co_u32(v[10], VCC_LO, 32, v[9]),
  v_mov_b32_e32(v[11], v[1]),
  v_add_co_u32(v[12], VCC_LO, 8, v[11]),
  v_add_co_u32(v[13], VCC_LO, 8, v[12]),
  v_add_co_u32(v[14], VCC_LO, 8, v[13]),
  v_mov_b32_e32(v[15], v[3]),
  s_mul_i32(s[16], s[2], C_TILE),
  s_sub_co_u32(s[16], s[27], s[16]),
  s_sub_co_u32(s[16], s[16], 8),
  v_mov_b32_e32(v[16], s[16]),
  v_min_i32_e32(v[6], v[16], v[6]),
  s_mul_hi_u32(s[19], s[2], C_TILE),
  s_mul_i32(s[18], s[2], C_TILE),
  s_mov_b64(s[56:57], 1),
  s_sub_co_u32(s[16], s[27], 1),
  s_mul_hi_u32(s[17], 1, s[16]),
  s_mul_i32(s[16], 1, s[16]),
  s_add_co_u32(s[56], s[56], s[16]),
  s_add_co_ci_u32(s[57], s[57], s[17]),
  s_sub_co_u32(s[16], s[27], 1),
  s_mul_hi_u32(s[17], s[27], s[16]),
  s_mul_i32(s[16], s[27], s[16]),
  s_add_co_u32(s[56], s[56], s[16]),
  s_add_co_ci_u32(s[57], s[57], s[17]),
  s_sub_co_u32(s[56], s[56], s[18]),
  s_sub_co_ci_u32(s[57], s[57], s[19]),
  s_lshl_b64(s[56:57], s[56:57], 1),
  s_add_co_u32(s[56], s[56], 16),
  s_add_co_ci_u32(s[57], s[57], 0),
  s_cmp_eq_u32(s[57], 0),
  s_cselect_b32(s[50], s[56], -1),
  s_lshl_b64(s[18:19], s[18:19], 1),
  s_add_co_u32(s[48], s[32], s[18]),
  s_add_co_ci_u32(s[49], s[33], s[19]),
  s_mov_b32(s[51], 0x30020000),
  s_mul_hi_u32(s[19], s[3], C_TILE),
  s_mul_i32(s[18], s[3], C_TILE),
  s_mul_hi_u32(s[19], s[18], s[27]),
  s_mul_i32(s[18], s[18], s[27]),
  s_mov_b64(s[58:59], 1),
  s_sub_co_u32(s[16], s[27], 1),
  s_mul_hi_u32(s[17], 1, s[16]),
  s_mul_i32(s[16], 1, s[16]),
  s_add_co_u32(s[58], s[58], s[16]),
  s_add_co_ci_u32(s[59], s[59], s[17]),
  s_sub_co_u32(s[16], s[27], 1),
  s_mul_hi_u32(s[17], s[27], s[16]),
  s_mul_i32(s[16], s[27], s[16]),
  s_add_co_u32(s[58], s[58], s[16]),
  s_add_co_ci_u32(s[59], s[59], s[17]),
  s_sub_co_u32(s[58], s[58], s[18]),
  s_sub_co_ci_u32(s[59], s[59], s[19]),
  s_lshl_b64(s[58:59], s[58:59], 1),
  s_add_co_u32(s[58], s[58], 16),
  s_add_co_ci_u32(s[59], s[59], 0),
  s_cmp_eq_u32(s[59], 0),
  s_cselect_b32(s[54], s[58], -1),
  s_lshl_b64(s[18:19], s[18:19], 1),
  s_add_co_u32(s[52], s[34], s[18]),
  s_add_co_ci_u32(s[53], s[35], s[19]),
  s_mov_b32(s[55], 0x30020000),
  v_mul_lo_u32(v[16], s[27], v[11]),
  v_add_co_u32(v[128], VCC_LO, v[6], v[16]),
  v_add_nc_u32_e32(v[128], 8, v[128]),
  v_lshlrev_b32_e32(v[128], 1, v[128]),
  v_mul_lo_u32(v[16], s[27], v[12]),
  v_add_co_u32(v[129], VCC_LO, v[6], v[16]),
  v_add_nc_u32_e32(v[129], 8, v[129]),
  v_lshlrev_b32_e32(v[129], 1, v[129]),
  v_mul_lo_u32(v[16], s[27], v[13]),
  v_add_co_u32(v[130], VCC_LO, v[6], v[16]),
  v_add_nc_u32_e32(v[130], 8, v[130]),
  v_lshlrev_b32_e32(v[130], 1, v[130]),
  v_mul_lo_u32(v[16], s[27], v[14]),
  v_add_co_u32(v[131], VCC_LO, v[6], v[16]),
  v_add_nc_u32_e32(v[131], 8, v[131]),
  v_lshlrev_b32_e32(v[131], 1, v[131]),
  v_mul_lo_u32(v[11], s[27], v[7]),
  v_add_co_u32(v[132], VCC_LO, v[15], v[11]),
  v_add_nc_u32_e32(v[132], 8, v[132]),
  v_lshlrev_b32_e32(v[132], 1, v[132]),
  v_mul_lo_u32(v[11], s[27], v[8]),
  v_add_co_u32(v[133], VCC_LO, v[15], v[11]),
  v_add_nc_u32_e32(v[133], 8, v[133]),
  v_lshlrev_b32_e32(v[133], 1, v[133]),
  v_mul_lo_u32(v[11], s[27], v[9]),
  v_add_co_u32(v[134], VCC_LO, v[15], v[11]),
  v_add_nc_u32_e32(v[134], 8, v[134]),
  v_lshlrev_b32_e32(v[134], 1, v[134]),
  v_mul_lo_u32(v[11], s[27], v[10]),
  v_add_co_u32(v[135], VCC_LO, v[15], v[11]),
  v_add_nc_u32_e32(v[135], 8, v[135]),
  v_lshlrev_b32_e32(v[135], 1, v[135]),
  # tile strides: s[64] = WAVE_TILE*N (A), s[65] = WAVE_TILE (B)
  s_mul_i32(s[64], WAVE_TILE, s[27]),
  s_mov_b32(s[65], WAVE_TILE),
  s_lshr_b32(s[12], s[27], K_TILE.bit_length() - 1),  # N // K_TILE
  s_mov_b32(s[47], 0),
  # wrap values for prefetch pointer updates
  s_mul_hi_i32(s[61], s[12], s[64]),
  s_mul_i32(s[60], s[12], s[64]),
  s_sub_co_u32(s[60], s[64], s[60]),
  s_sub_co_ci_u32(s[61], 0, s[61]),
  s_cmp_eq_u32(s[57], 0),
  s_cselect_b32(s[50], s[56], -1),
  s_mul_hi_i32(s[63], s[12], s[65]),
  s_mul_i32(s[62], s[12], s[65]),
  s_sub_co_u32(s[62], s[65], s[62]),
  s_sub_co_ci_u32(s[63], 0, s[63]),
  s_cmp_eq_u32(s[59], 0),
  s_cselect_b32(s[54], s[58], -1),
  s_add_co_u32(s[47], s[47], 2),
  s_cmp_eq_u32(s[12], 0),
  s_cbranch_scc1("skip_first_prefetch"),
  # **** GLOBAL -> VGPR
  # Prefetch A matrix tiles (4 loads from rsrc=48)
  *[buffer_load_b128(v[222+i*4:226+i*4], v[128+i], soffset=NULL, format=1, offen=1, rsrc=48) for i in range(4)],
  # Prefetch B matrix tiles (4 loads from rsrc=52)
  *[buffer_load_b128(v[238+i*4:242+i*4], v[132+i], soffset=NULL, format=1, offen=1, rsrc=52) for i in range(4)],
  s_add_co_u32(s[18], s[12], 1),
  s_cmp_eq_u32(s[47], s[18]),
  s_cselect_b32(s[16], s[60], s[64]),
  s_cselect_b32(s[17], s[61], 0),
  s_add_co_u32(s[48], s[48], s[16]),
  s_add_co_ci_u32(s[49], s[49], s[17]),
  s_sub_co_u32(s[56], s[56], s[16]),
  s_sub_co_ci_u32(s[57], s[57], s[17]),
  s_cmp_eq_u32(s[57], 0),
  s_cselect_b32(s[50], s[56], -1),
  s_add_co_u32(s[18], s[12], 1),
  s_cmp_eq_u32(s[47], s[18]),
  s_cselect_b32(s[16], s[62], s[65]),
  s_cselect_b32(s[17], s[63], 0),
  s_add_co_u32(s[52], s[52], s[16]),
  s_add_co_ci_u32(s[53], s[53], s[17]),
  s_sub_co_u32(s[58], s[58], s[16]),
  s_sub_co_ci_u32(s[59], s[59], s[17]),
  s_cmp_eq_u32(s[59], 0),
  s_cselect_b32(s[54], s[58], -1),
  "skip_first_prefetch:",
  s_mov_b64(s[16:17], s[28:29]),
  s_mov_b32(s[18], 0x80000000),
  s_mov_b32(s[19], 0x30020000),
  s_mov_b64(s[20:21], s[30:31]),
  s_mul_i32(s[70], C_TILE, s[3]),
  s_mul_hi_u32(s[69], s[70], s[27]),
  s_mul_i32(s[68], s[70], s[27]),
  s_lshl_b64(s[68:69], s[68:69], s[8]),
  s_add_co_u32(s[20], s[30], s[68]),
  s_add_co_ci_u32(s[21], s[31], s[69]),
  s_mul_hi_u32(s[69], s[70], s[27]),
  s_mul_i32(s[68], s[70], s[27]),
  s_lshl_b64(s[68:69], s[68:69], s[9]),
  s_add_co_u32(s[16], s[28], s[68]),
  s_add_co_ci_u32(s[17], s[29], s[69]),
  # **** VGPR -> LDS
  # Zero initialize accumulators v[0:127]
  *[v_dual_mov_b32(VOPDOp.V_DUAL_MOV_B32, v[i], v[i+1], 0, 0) for i in range(0, 128, 2)],
  s_wait_loadcnt(0x0),
  ds_store_b128(addr=v[136], data0=v[222:225], offset1=0),
  ds_store_b128(addr=v[136], data0=v[226:229], offset1=8),
  ds_store_b128(addr=v[136], data0=v[230:233], offset1=16),
  ds_store_b128(addr=v[136], data0=v[234:237], offset1=24),
  ds_store_b128(addr=v[137], data0=v[238:241], offset1=0),
  ds_store_b128(addr=v[137], data0=v[242:245], offset1=9),
  ds_store_b128(addr=v[137], data0=v[246:249], offset1=18),
  ds_store_b128(addr=v[137], data0=v[250:253], offset1=27),
  s_cmp_eq_u32(s[12], 1),
  s_cbranch_scc1("skip_prefetch_2"),
  # Prefetch A matrix tiles (4 loads from rsrc=48)
  *[buffer_load_b128(v[222+i*4:226+i*4], v[128+i], soffset=NULL, format=1, offen=1, rsrc=48) for i in range(4)],
  # Prefetch B matrix tiles (4 loads from rsrc=52)
  *[buffer_load_b128(v[238+i*4:242+i*4], v[132+i], soffset=NULL, format=1, offen=1, rsrc=52) for i in range(4)],
  "skip_prefetch_2:",
  s_wait_dscnt(0x0),
  s_barrier_signal(ssrc0=RawImm(193)),
  s_barrier_wait(0xffff),
  # **** LDS -> VGPR
  # Load A tile from LDS: 8x b64 loads
  *[ds_load_b64(v[156+i*2:158+i*2], v[138], offset1=i) for i in range(8)],
  # Load B tile from LDS: 4x b128 loads
  *[ds_load_b128(v[189+i*4:193+i*4], v[139], offset0=i*64) for i in range(4)],
  s_cmp_eq_u32(s[12], 1),
  s_cbranch_scc1("final_wmma"),
  s_cmp_le_u32(s[12], 2),
  s_cbranch_scc1("loop_epilogue"),
  s_nop(0),
  "main_loop:",
  s_wait_dscnt(0x3),
  # **** VPGR -> WMMA layout
  v_perm_b32(v[140], v[158], v[156], s[66]),
  v_perm_b32(v[141], v[162], v[160], s[66]),
  v_perm_b32(v[142], v[166], v[164], s[66]),
  v_perm_b32(v[143], v[170], v[168], s[66]),
  v_perm_b32(v[144], v[158], v[156], s[67]),
  v_perm_b32(v[145], v[162], v[160], s[67]),
  v_wmma_f32_16x16x16_f16(v[0:7], v[189:192], v[140:143], v[0:7]),
  ds_load_b64(v[172:173], v[138], offset1=16),
  ds_load_b64(v[174:175], v[138], offset1=17),
  s_cmp_eq_u32(s[12], s[47]),
  s_cselect_b32(s[68], s[60], s[64]),
  s_cselect_b32(s[69], s[61], 0),
  v_perm_b32(v[146], v[166], v[164], s[67]),
  v_perm_b32(v[147], v[170], v[168], s[67]),
  v_perm_b32(v[148], v[159], v[157], s[66]),
  v_perm_b32(v[149], v[163], v[161], s[66]),
  v_wmma_f32_16x16x16_f16(v[8:15], v[189:192], v[144:147], v[8:15]),
  ds_load_b64(v[176:177], v[138], offset1=18),
  ds_load_b64(v[178:179], v[138], offset1=19),
  s_add_co_u32(s[48], s[48], s[68]),
  s_add_co_ci_u32(s[49], s[49], s[69]),
  s_sub_co_u32(s[56], s[56], s[68]),
  v_perm_b32(v[150], v[167], v[165], s[66]),
  v_perm_b32(v[151], v[171], v[169], s[66]),
  v_perm_b32(v[152], v[159], v[157], s[67]),
  v_perm_b32(v[153], v[163], v[161], s[67]),
  v_wmma_f32_16x16x16_f16(v[16:23], v[189:192], v[148:151], v[16:23]),
  ds_load_b64(v[180:181], v[138], offset1=20),
  ds_load_b64(v[182:183], v[138], offset1=21),
  s_sub_co_ci_u32(s[57], s[57], s[69]),
  s_cmp_eq_u32(s[57], 0),
  s_cselect_b32(s[50], s[56], -1),
  v_perm_b32(v[154], v[167], v[165], s[67]),
  v_perm_b32(v[155], v[171], v[169], s[67]),
  s_nop(1),
  v_wmma_f32_16x16x16_f16(v[24:31], v[189:192], v[152:155], v[24:31]),
  ds_load_b64(v[184:185], v[138], offset1=22),
  ds_load_b64(v[186:187], v[138], offset1=23),
  s_cmp_eq_u32(s[12], s[47]),
  s_cselect_b32(s[68], s[62], s[65]),
  s_cselect_b32(s[69], s[63], 0),
  s_wait_dscnt(0x8),
  v_wmma_f32_16x16x16_f16(v[32:39], v[193:196], v[140:143], v[32:39]),
  ds_load_b128(v[205:208], v[139], offset0=32),
  s_add_co_u32(s[52], s[52], s[68]),
  s_add_co_ci_u32(s[53], s[53], s[69]),
  s_sub_co_u32(s[58], s[58], s[68]),
  v_wmma_f32_16x16x16_f16(v[40:47], v[193:196], v[144:147], v[40:47]),
  ds_load_b128(v[209:212], v[139], offset0=96),
  s_sub_co_ci_u32(s[59], s[59], s[69]),
  s_cmp_eq_u32(s[59], 0),
  s_cselect_b32(s[54], s[58], -1),
  v_wmma_f32_16x16x16_f16(v[48:55], v[193:196], v[148:151], v[48:55]),
  ds_load_b128(v[213:216], v[139], offset0=160),
  v_wmma_f32_16x16x16_f16(v[56:63], v[193:196], v[152:155], v[56:63]),
  ds_load_b128(v[217:220], v[139], offset0=224),
  v_wmma_f32_16x16x16_f16(v[64:71], v[197:200], v[140:143], v[64:71]),
  v_wmma_f32_16x16x16_f16(v[72:79], v[197:200], v[144:147], v[72:79]),
  v_wmma_f32_16x16x16_f16(v[80:87], v[197:200], v[148:151], v[80:87]),
  v_wmma_f32_16x16x16_f16(v[88:95], v[197:200], v[152:155], v[88:95]),
  v_wmma_f32_16x16x16_f16(v[96:103], v[201:204], v[140:143], v[96:103]),
  s_wait_dscnt(0x0),
  s_barrier_signal(ssrc0=RawImm(193)),
  s_barrier_wait(0xffff),
  v_wmma_f32_16x16x16_f16(v[104:111], v[201:204], v[144:147], v[104:111]),
  s_wait_loadcnt(0x7),
  ds_store_b128(addr=v[136], data0=v[222:225], offset1=0),
  buffer_load_b128(v[222:225], v[128], soffset=NULL, format=1, offen=1, rsrc=48),
  s_wait_loadcnt(0x7),
  ds_store_b128(addr=v[136], data0=v[226:229], offset1=8),
  v_wmma_f32_16x16x16_f16(v[112:119], v[201:204], v[148:151], v[112:119]),
  buffer_load_b128(v[226:229], v[129], soffset=NULL, format=1, offen=1, rsrc=48),
  s_wait_loadcnt(0x7),
  ds_store_b128(addr=v[136], data0=v[230:233], offset1=16),
  buffer_load_b128(v[230:233], v[130], soffset=NULL, format=1, offen=1, rsrc=48),
  v_wmma_f32_16x16x16_f16(v[120:127], v[201:204], v[152:155], v[120:127]),
  s_wait_loadcnt(0x7),
  ds_store_b128(addr=v[136], data0=v[234:237], offset1=24),
  buffer_load_b128(v[234:237], v[131], soffset=NULL, format=1, offen=1, rsrc=48),
  s_wait_loadcnt(0x7),
  ds_store_b128(addr=v[137], data0=v[238:241], offset1=0),
  s_wait_dscnt(0x5),
  v_perm_b32(v[140], v[174], v[172], s[66]),
  v_perm_b32(v[141], v[178], v[176], s[66]),
  v_perm_b32(v[142], v[182], v[180], s[66]),
  v_perm_b32(v[143], v[186], v[184], s[66]),
  v_perm_b32(v[144], v[174], v[172], s[67]),
  v_perm_b32(v[145], v[178], v[176], s[67]),
  v_wmma_f32_16x16x16_f16(v[0:7], v[205:208], v[140:143], v[0:7]),
  buffer_load_b128(v[238:241], v[132], soffset=NULL, format=1, offen=1, rsrc=52),
  s_wait_loadcnt(0x7),
  ds_store_b128(addr=v[137], data0=v[242:245], offset1=9),
  buffer_load_b128(v[242:245], v[133], soffset=NULL, format=1, offen=1, rsrc=52),
  v_perm_b32(v[146], v[182], v[180], s[67]),
  v_perm_b32(v[147], v[186], v[184], s[67]),
  v_perm_b32(v[148], v[175], v[173], s[66]),
  v_perm_b32(v[149], v[179], v[177], s[66]),
  v_wmma_f32_16x16x16_f16(v[8:15], v[205:208], v[144:147], v[8:15]),
  s_wait_loadcnt(0x7),
  ds_store_b128(addr=v[137], data0=v[246:249], offset1=18),
  buffer_load_b128(v[246:249], v[134], soffset=NULL, format=1, offen=1, rsrc=52),
  s_wait_loadcnt(0x7),
  ds_store_b128(addr=v[137], data0=v[250:253], offset1=27),
  v_perm_b32(v[150], v[183], v[181], s[66]),
  v_perm_b32(v[151], v[187], v[185], s[66]),
  v_perm_b32(v[152], v[175], v[173], s[67]),
  v_perm_b32(v[153], v[179], v[177], s[67]),
  v_wmma_f32_16x16x16_f16(v[16:23], v[205:208], v[148:151], v[16:23]),
  buffer_load_b128(v[250:253], v[135], soffset=NULL, format=1, offen=1, rsrc=52),
  v_perm_b32(v[154], v[183], v[181], s[67]),
  v_perm_b32(v[155], v[187], v[185], s[67]),
  s_nop(1),
  v_wmma_f32_16x16x16_f16(v[24:31], v[205:208], v[152:155], v[24:31]),
  v_wmma_f32_16x16x16_f16(v[32:39], v[209:212], v[140:143], v[32:39]),
  s_wait_dscnt(0x0),
  s_barrier_signal(ssrc0=RawImm(193)),
  s_barrier_wait(0xffff),
  v_wmma_f32_16x16x16_f16(v[40:47], v[209:212], v[144:147], v[40:47]),
  ds_load_b64(v[156:157], v[138], offset1=0),
  ds_load_b64(v[158:159], v[138], offset1=1),
  v_wmma_f32_16x16x16_f16(v[48:55], v[209:212], v[148:151], v[48:55]),
  ds_load_b64(v[160:161], v[138], offset1=2),
  ds_load_b64(v[162:163], v[138], offset1=3),
  v_wmma_f32_16x16x16_f16(v[56:63], v[209:212], v[152:155], v[56:63]),
  ds_load_b64(v[164:165], v[138], offset1=4),
  ds_load_b64(v[166:167], v[138], offset1=5),
  v_wmma_f32_16x16x16_f16(v[64:71], v[213:216], v[140:143], v[64:71]),
  ds_load_b64(v[168:169], v[138], offset1=6),
  ds_load_b64(v[170:171], v[138], offset1=7),
  v_wmma_f32_16x16x16_f16(v[72:79], v[213:216], v[144:147], v[72:79]),
  ds_load_b128(v[189:192], v[139], offset0=0),
  v_wmma_f32_16x16x16_f16(v[80:87], v[213:216], v[148:151], v[80:87]),
  ds_load_b128(v[193:196], v[139], offset0=64),
  v_wmma_f32_16x16x16_f16(v[88:95], v[213:216], v[152:155], v[88:95]),
  ds_load_b128(v[197:200], v[139], offset0=128),
  v_wmma_f32_16x16x16_f16(v[96:103], v[217:220], v[140:143], v[96:103]),
  ds_load_b128(v[201:204], v[139], offset0=192),
  v_wmma_f32_16x16x16_f16(v[104:111], v[217:220], v[144:147], v[104:111]),
  v_wmma_f32_16x16x16_f16(v[112:119], v[217:220], v[148:151], v[112:119]),
  v_wmma_f32_16x16x16_f16(v[120:127], v[217:220], v[152:155], v[120:127]),
  s_sub_co_u32(s[12], s[12], 1),
  s_cmp_eq_i32(s[12], 2),
  s_cbranch_scc0("main_loop"),
  "loop_epilogue:",
  s_wait_dscnt(0x3),
  v_perm_b32(v[140], v[158], v[156], s[66]),
  v_perm_b32(v[141], v[162], v[160], s[66]),
  v_perm_b32(v[142], v[166], v[164], s[66]),
  v_perm_b32(v[143], v[170], v[168], s[66]),
  v_perm_b32(v[144], v[158], v[156], s[67]),
  v_perm_b32(v[145], v[162], v[160], s[67]),
  v_wmma_f32_16x16x16_f16(v[0:7], v[189:192], v[140:143], v[0:7]),
  ds_load_b64(v[172:173], v[138], offset1=16),
  ds_load_b64(v[174:175], v[138], offset1=17),
  s_cmp_eq_u32(s[12], s[47]),
  s_cselect_b32(s[68], s[60], s[64]),
  s_cselect_b32(s[69], s[61], 0),
  v_perm_b32(v[146], v[166], v[164], s[67]),
  v_perm_b32(v[147], v[170], v[168], s[67]),
  v_perm_b32(v[148], v[159], v[157], s[66]),
  v_perm_b32(v[149], v[163], v[161], s[66]),
  v_wmma_f32_16x16x16_f16(v[8:15], v[189:192], v[144:147], v[8:15]),
  ds_load_b64(v[176:177], v[138], offset1=18),
  ds_load_b64(v[178:179], v[138], offset1=19),
  s_add_co_u32(s[48], s[48], s[68]),
  s_add_co_ci_u32(s[49], s[49], s[69]),
  s_sub_co_u32(s[56], s[56], s[68]),
  v_perm_b32(v[150], v[167], v[165], s[66]),
  v_perm_b32(v[151], v[171], v[169], s[66]),
  v_perm_b32(v[152], v[159], v[157], s[67]),
  v_perm_b32(v[153], v[163], v[161], s[67]),
  v_wmma_f32_16x16x16_f16(v[16:23], v[189:192], v[148:151], v[16:23]),
  ds_load_b64(v[180:181], v[138], offset1=20),
  ds_load_b64(v[182:183], v[138], offset1=21),
  s_sub_co_ci_u32(s[57], s[57], s[69]),
  s_cmp_eq_u32(s[57], 0),
  s_cselect_b32(s[50], s[56], -1),
  v_perm_b32(v[154], v[167], v[165], s[67]),
  v_perm_b32(v[155], v[171], v[169], s[67]),
  s_nop(1),
  v_wmma_f32_16x16x16_f16(v[24:31], v[189:192], v[152:155], v[24:31]),
  ds_load_b64(v[184:185], v[138], offset1=22),
  ds_load_b64(v[186:187], v[138], offset1=23),
  s_cmp_eq_u32(s[12], s[47]),
  s_cselect_b32(s[68], s[62], s[65]),
  s_cselect_b32(s[69], s[63], 0),
  s_wait_dscnt(0x8),
  v_wmma_f32_16x16x16_f16(v[32:39], v[193:196], v[140:143], v[32:39]),
  ds_load_b128(v[205:208], v[139], offset0=32),
  s_add_co_u32(s[52], s[52], s[68]),
  s_add_co_ci_u32(s[53], s[53], s[69]),
  s_sub_co_u32(s[58], s[58], s[68]),
  v_wmma_f32_16x16x16_f16(v[40:47], v[193:196], v[144:147], v[40:47]),
  ds_load_b128(v[209:212], v[139], offset0=96),
  s_sub_co_ci_u32(s[59], s[59], s[69]),
  s_cmp_eq_u32(s[59], 0),
  s_cselect_b32(s[54], s[58], -1),
  v_wmma_f32_16x16x16_f16(v[48:55], v[193:196], v[148:151], v[48:55]),
  ds_load_b128(v[213:216], v[139], offset0=160),
  v_wmma_f32_16x16x16_f16(v[56:63], v[193:196], v[152:155], v[56:63]),
  ds_load_b128(v[217:220], v[139], offset0=224),
  v_wmma_f32_16x16x16_f16(v[64:71], v[197:200], v[140:143], v[64:71]),
  v_wmma_f32_16x16x16_f16(v[72:79], v[197:200], v[144:147], v[72:79]),
  v_wmma_f32_16x16x16_f16(v[80:87], v[197:200], v[148:151], v[80:87]),
  v_wmma_f32_16x16x16_f16(v[88:95], v[197:200], v[152:155], v[88:95]),
  v_wmma_f32_16x16x16_f16(v[96:103], v[201:204], v[140:143], v[96:103]),
  s_wait_dscnt(0x0),
  s_barrier_signal(ssrc0=RawImm(193)),
  s_barrier_wait(0xffff),
  v_wmma_f32_16x16x16_f16(v[104:111], v[201:204], v[144:147], v[104:111]),
  s_wait_loadcnt(0x7),
  ds_store_b128(addr=v[136], data0=v[222:225], offset1=0),
  s_wait_loadcnt(0x6),
  ds_store_b128(addr=v[136], data0=v[226:229], offset1=8),
  v_wmma_f32_16x16x16_f16(v[112:119], v[201:204], v[148:151], v[112:119]),
  s_wait_loadcnt(0x5),
  ds_store_b128(addr=v[136], data0=v[230:233], offset1=16),
  v_wmma_f32_16x16x16_f16(v[120:127], v[201:204], v[152:155], v[120:127]),
  s_wait_loadcnt(0x4),
  ds_store_b128(addr=v[136], data0=v[234:237], offset1=24),
  s_wait_loadcnt(0x3),
  ds_store_b128(addr=v[137], data0=v[238:241], offset1=0),
  s_wait_dscnt(0x5),
  v_perm_b32(v[140], v[174], v[172], s[66]),
  v_perm_b32(v[141], v[178], v[176], s[66]),
  v_perm_b32(v[142], v[182], v[180], s[66]),
  v_perm_b32(v[143], v[186], v[184], s[66]),
  v_perm_b32(v[144], v[174], v[172], s[67]),
  v_perm_b32(v[145], v[178], v[176], s[67]),
  v_wmma_f32_16x16x16_f16(v[0:7], v[205:208], v[140:143], v[0:7]),
  s_wait_loadcnt(0x2),
  ds_store_b128(addr=v[137], data0=v[242:245], offset1=9),
  v_perm_b32(v[146], v[182], v[180], s[67]),
  v_perm_b32(v[147], v[186], v[184], s[67]),
  v_perm_b32(v[148], v[175], v[173], s[66]),
  v_perm_b32(v[149], v[179], v[177], s[66]),
  v_wmma_f32_16x16x16_f16(v[8:15], v[205:208], v[144:147], v[8:15]),
  s_wait_loadcnt(0x1),
  ds_store_b128(addr=v[137], data0=v[246:249], offset1=18),
  s_wait_loadcnt(0x0),
  ds_store_b128(addr=v[137], data0=v[250:253], offset1=27),
  v_perm_b32(v[150], v[183], v[181], s[66]),
  v_perm_b32(v[151], v[187], v[185], s[66]),
  v_perm_b32(v[152], v[175], v[173], s[67]),
  v_perm_b32(v[153], v[179], v[177], s[67]),
  v_wmma_f32_16x16x16_f16(v[16:23], v[205:208], v[148:151], v[16:23]),
  v_perm_b32(v[154], v[183], v[181], s[67]),
  v_perm_b32(v[155], v[187], v[185], s[67]),
  s_nop(1),
  v_wmma_f32_16x16x16_f16(v[24:31], v[205:208], v[152:155], v[24:31]),
  v_wmma_f32_16x16x16_f16(v[32:39], v[209:212], v[140:143], v[32:39]),
  s_wait_dscnt(0x0),
  s_barrier_signal(ssrc0=RawImm(193)),
  s_barrier_wait(0xffff),
  v_wmma_f32_16x16x16_f16(v[40:47], v[209:212], v[144:147], v[40:47]),
  ds_load_b64(v[156:157], v[138], offset1=0),
  ds_load_b64(v[158:159], v[138], offset1=1),
  v_wmma_f32_16x16x16_f16(v[48:55], v[209:212], v[148:151], v[48:55]),
  ds_load_b64(v[160:161], v[138], offset1=2),
  ds_load_b64(v[162:163], v[138], offset1=3),
  v_wmma_f32_16x16x16_f16(v[56:63], v[209:212], v[152:155], v[56:63]),
  ds_load_b64(v[164:165], v[138], offset1=4),
  ds_load_b64(v[166:167], v[138], offset1=5),
  v_wmma_f32_16x16x16_f16(v[64:71], v[213:216], v[140:143], v[64:71]),
  ds_load_b64(v[168:169], v[138], offset1=6),
  ds_load_b64(v[170:171], v[138], offset1=7),
  v_wmma_f32_16x16x16_f16(v[72:79], v[213:216], v[144:147], v[72:79]),
  ds_load_b128(v[189:192], v[139], offset0=0),
  v_wmma_f32_16x16x16_f16(v[80:87], v[213:216], v[148:151], v[80:87]),
  ds_load_b128(v[193:196], v[139], offset0=64),
  v_wmma_f32_16x16x16_f16(v[88:95], v[213:216], v[152:155], v[88:95]),
  ds_load_b128(v[197:200], v[139], offset0=128),
  v_wmma_f32_16x16x16_f16(v[96:103], v[217:220], v[140:143], v[96:103]),
  ds_load_b128(v[201:204], v[139], offset0=192),
  v_wmma_f32_16x16x16_f16(v[104:111], v[217:220], v[144:147], v[104:111]),
  v_wmma_f32_16x16x16_f16(v[112:119], v[217:220], v[148:151], v[112:119]),
  v_wmma_f32_16x16x16_f16(v[120:127], v[217:220], v[152:155], v[120:127]),
  "final_wmma:",
  s_wait_dscnt(0x3),
  v_perm_b32(v[140], v[158], v[156], s[66]),
  v_perm_b32(v[141], v[162], v[160], s[66]),
  v_perm_b32(v[142], v[166], v[164], s[66]),
  v_perm_b32(v[143], v[170], v[168], s[66]),
  v_perm_b32(v[144], v[158], v[156], s[67]),
  v_perm_b32(v[145], v[162], v[160], s[67]),
  v_wmma_f32_16x16x16_f16(v[0:7], v[189:192], v[140:143], v[0:7]),
  ds_load_b64(v[172:173], v[138], offset1=16),
  ds_load_b64(v[174:175], v[138], offset1=17),
  v_perm_b32(v[146], v[166], v[164], s[67]),
  v_perm_b32(v[147], v[170], v[168], s[67]),
  v_perm_b32(v[148], v[159], v[157], s[66]),
  v_perm_b32(v[149], v[163], v[161], s[66]),
  v_wmma_f32_16x16x16_f16(v[8:15], v[189:192], v[144:147], v[8:15]),
  ds_load_b64(v[176:177], v[138], offset1=18),
  ds_load_b64(v[178:179], v[138], offset1=19),
  v_perm_b32(v[150], v[167], v[165], s[66]),
  v_perm_b32(v[151], v[171], v[169], s[66]),
  v_perm_b32(v[152], v[159], v[157], s[67]),
  v_perm_b32(v[153], v[163], v[161], s[67]),
  v_wmma_f32_16x16x16_f16(v[16:23], v[189:192], v[148:151], v[16:23]),
  ds_load_b64(v[180:181], v[138], offset1=20),
  ds_load_b64(v[182:183], v[138], offset1=21),
  v_perm_b32(v[154], v[167], v[165], s[67]),
  v_perm_b32(v[155], v[171], v[169], s[67]),
  s_nop(1),
  v_wmma_f32_16x16x16_f16(v[24:31], v[189:192], v[152:155], v[24:31]),
  ds_load_b64(v[184:185], v[138], offset1=22),
  ds_load_b64(v[186:187], v[138], offset1=23),
  s_wait_dscnt(0x8),
  v_wmma_f32_16x16x16_f16(v[32:39], v[193:196], v[140:143], v[32:39]),
  ds_load_b128(v[205:208], v[139], offset0=32),
  v_wmma_f32_16x16x16_f16(v[40:47], v[193:196], v[144:147], v[40:47]),
  ds_load_b128(v[209:212], v[139], offset0=96),
  v_wmma_f32_16x16x16_f16(v[48:55], v[193:196], v[148:151], v[48:55]),
  ds_load_b128(v[213:216], v[139], offset0=160),
  v_wmma_f32_16x16x16_f16(v[56:63], v[193:196], v[152:155], v[56:63]),
  ds_load_b128(v[217:220], v[139], offset0=224),
  v_wmma_f32_16x16x16_f16(v[64:71], v[197:200], v[140:143], v[64:71]),
  v_wmma_f32_16x16x16_f16(v[72:79], v[197:200], v[144:147], v[72:79]),
  v_wmma_f32_16x16x16_f16(v[80:87], v[197:200], v[148:151], v[80:87]),
  v_wmma_f32_16x16x16_f16(v[88:95], v[197:200], v[152:155], v[88:95]),
  v_wmma_f32_16x16x16_f16(v[96:103], v[201:204], v[140:143], v[96:103]),
  v_wmma_f32_16x16x16_f16(v[104:111], v[201:204], v[144:147], v[104:111]),
  s_wait_dscnt(0x0),
  s_barrier_signal(ssrc0=RawImm(193)),
  s_barrier_wait(0xffff),
  v_wmma_f32_16x16x16_f16(v[112:119], v[201:204], v[148:151], v[112:119]),
  v_wmma_f32_16x16x16_f16(v[120:127], v[201:204], v[152:155], v[120:127]),
  s_wait_dscnt(0x0),
  v_perm_b32(v[140], v[174], v[172], s[66]),
  v_perm_b32(v[141], v[178], v[176], s[66]),
  v_perm_b32(v[142], v[182], v[180], s[66]),
  v_perm_b32(v[143], v[186], v[184], s[66]),
  v_perm_b32(v[144], v[174], v[172], s[67]),
  v_perm_b32(v[145], v[178], v[176], s[67]),
  v_wmma_f32_16x16x16_f16(v[0:7], v[205:208], v[140:143], v[0:7]),
  v_perm_b32(v[146], v[182], v[180], s[67]),
  v_perm_b32(v[147], v[186], v[184], s[67]),
  v_perm_b32(v[148], v[175], v[173], s[66]),
  v_perm_b32(v[149], v[179], v[177], s[66]),
  v_wmma_f32_16x16x16_f16(v[8:15], v[205:208], v[144:147], v[8:15]),
  v_perm_b32(v[150], v[183], v[181], s[66]),
  v_perm_b32(v[151], v[187], v[185], s[66]),
  v_perm_b32(v[152], v[175], v[173], s[67]),
  v_perm_b32(v[153], v[179], v[177], s[67]),
  v_wmma_f32_16x16x16_f16(v[16:23], v[205:208], v[148:151], v[16:23]),
  v_perm_b32(v[154], v[183], v[181], s[67]),
  v_perm_b32(v[155], v[187], v[185], s[67]),
  s_nop(1),
  v_wmma_f32_16x16x16_f16(v[24:31], v[205:208], v[152:155], v[24:31]),
  v_wmma_f32_16x16x16_f16(v[32:39], v[209:212], v[140:143], v[32:39]),
  v_wmma_f32_16x16x16_f16(v[40:47], v[209:212], v[144:147], v[40:47]),
  v_wmma_f32_16x16x16_f16(v[48:55], v[209:212], v[148:151], v[48:55]),
  v_wmma_f32_16x16x16_f16(v[56:63], v[209:212], v[152:155], v[56:63]),
  v_wmma_f32_16x16x16_f16(v[64:71], v[213:216], v[140:143], v[64:71]),
  v_wmma_f32_16x16x16_f16(v[72:79], v[213:216], v[144:147], v[72:79]),
  v_wmma_f32_16x16x16_f16(v[80:87], v[213:216], v[148:151], v[80:87]),
  v_wmma_f32_16x16x16_f16(v[88:95], v[213:216], v[152:155], v[88:95]),
  v_wmma_f32_16x16x16_f16(v[96:103], v[217:220], v[140:143], v[96:103]),
  v_wmma_f32_16x16x16_f16(v[104:111], v[217:220], v[144:147], v[104:111]),
  v_wmma_f32_16x16x16_f16(v[112:119], v[217:220], v[148:151], v[112:119]),
  v_wmma_f32_16x16x16_f16(v[120:127], v[217:220], v[152:155], v[120:127]),
  v_lshrrev_b32_e32(v[132], 5, v[254]),
  v_lshrrev_b32_e32(v[133], 1, v[132]),
  v_mul_lo_u32(v[133], 16, v[133]),
  v_and_b32_e32(v[129], 31, v[254]),
  v_lshrrev_b32_e32(v[129], 4, v[129]),
  v_lshlrev_b32_e32(v[129], 3, v[129]),
  v_add_lshl_u32(v[129], v[133], v[129], 2),
  v_mul_lo_u32(v[130], v[129], s[27]),
  v_mul_lo_u32(v[131], v[129], s[27]),
  v_and_b32_e32(v[128], 1, v[132]),
  v_mul_lo_u32(v[128], 16, v[128]),
  v_and_b32_e32(v[133], 15, v[254]),
  s_mul_i32(s[8], C_TILE, s[2]),
  v_add_lshl_u32(v[128], v[133], v[128], 2),
  v_add_nc_u32_e32(v[128], s[8], v[128]),
  v_add_lshl_u32(v[137], v[131], v[128], 1),
  ]
  # VGPR -> GLOBAL store
  insts += [s_wait_dscnt(0x0)]
  saddr, tmpv, vaddr = 16, 140, v[137]
  bases = (0, 32, 64, 96)
  row_pairs = ((0, 1), (2, 3), (4, 5), (6, 7))
  store_seq = [base+r for a, b in row_pairs for r in (a, b) for base in bases]
  def pack_f16(vdst, a, b): return [v_cvt_f16_f32_e64(a, a), v_cvt_f16_f32_e64(b, b), v_pack_b32_f16(vdst, a, b)]
  for i,base in enumerate(store_seq):
    if i > 0: insts += [s_add_co_u32(s[saddr], s[saddr], N << 1), s_add_co_ci_u32(s[saddr+1], s[saddr+1], 0)]
    insts += pack_f16(v[tmpv], v[base], v[base+8])
    insts += pack_f16(v[tmpv+1], v[base+16], v[base+24])
    insts += [buffer_store_b64(v[tmpv:tmpv+1], vaddr, soffset=NULL, format=1, offen=1, rsrc=saddr)]
  insts += [s_endpgm()]
  sink = UOp.sink(A, B, C, lidx, gidx, arg=KernelInfo(name="gemm"))
  src = (pathlib.Path(__file__).parent/"template.s").read_text()
  src = src.replace("INSTRUCTIONS", "\n".join([i if isinstance(i, str) else f"\t{i.disasm()}" for i in insts]))
  lib = pack_hsaco(src, "gfx1200")
  return UOp(Ops.PROGRAM, src=(sink, UOp(Ops.DEVICE, arg=dev), UOp(Ops.LINEAR, src=(*sink.src, sink)), UOp(Ops.SOURCE, arg=src), UOp(Ops.BINARY, arg=lib)), arg=())

if __name__ == "__main__":
  test_matmul(custom_gemm(N, Device.DEFAULT), dtype=dtypes.half, N=N)
